<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a><i>Data Munging with Perl </i><br/>
<hr/>
<a name=2></a><hr/>
<a name=3></a><i>Data Munging</i><br/>
<i>with Perl</i><br/>
DAVID CROSS<br/>
M A N N I N G<br/>
Greenwich<br/>
(74° w. long.)<br/>
<hr/>
<a name=4></a>For electronic information and ordering of this and other Manning books, <br/>go to www.manning.com. The publisher offers discounts on this book <br/>when ordered in quantity. For more information, please contact:<br/>
Special Sales Department<br/>Manning Publications Co.<br/>32 Lafayette Place<br/>
Fax: (203) 661-9018<br/>
Greenwich, CT 06830<br/>
email: orders@manning.com<br/>
©2001 by Manning Publications Co. All rights reserved.<br/>
No part of this publication may be reproduced, stored in a retrieval system, or transmitted, <br/>in any form or by means electronic, mechanical, photocopying, or otherwise, without <br/>prior written permission of the publisher.<br/>
Many of the designations used by manufacturers and sellers to distinguish their products <br/>are claimed as trademarks. Where those designations appear in the book, and Manning <br/>Publications was aware of a trademark claim, the designations have been printed in initial <br/>caps or all caps.<br/>
Recognizing the importance of preserving what has been written, it is Manning’s policy to have <br/>the books they publish printed on acid-free paper, and we exert our best efforts to that end.<br/>
<b>Library of Congress Cataloging-in-Publication Data<br/></b>Cross, David, 1962-<br/>
Data munging with Perl / David Cross.<br/>
p.<br/>
cm.<br/>
Includes bibliographical references and index.<br/>ISBN 1-930110-00-6 (alk. paper)<br/>1. Perl (Computer program language) 2. Data structures (Computer science) <br/>3. Data transmission systems. I. Title.<br/>
QA76.73.P22 C39 20001998<br/>
005.7'2—dc21<br/>
00-050009<br/>
CIP<br/>
Manning Publications Co.<br/>
Copyeditor: Elizabeth Martin<br/>
32 Lafayette Place<br/>
Typesetter: Dottie Marsico<br/>
Greenwich, CT 06830<br/>
Cover designer: Leslie Haimes<br/>
Printed in the United States of America<br/>
1 2 3 4 5 6 7 8 9 10 – VHG – 04  03 02 01 <br/>
<hr/>
<a name=5></a><i>contents</i><br/>
<i>contents</i><br/>
<a href="dmps.html#11"><i>foreword</i></a><br/>
<a href="dmps.html#11"><i>xi</i></a><br/>
<a href="dmps.html#13"><i>preface</i></a><br/>
<a href="dmps.html#13"><i>xiii</i></a><br/>
<a href="dmps.html#19"><i>about the cover illustration</i></a><br/>
<a href="dmps.html#19"><i>xviii</i></a><br/>
<a href="dmps.html#21">PART  I FOUNDATIONS................................................. 1</a><br/>
<a href=""><i>1  <b>Da</b></i></a><i><b>ta, data munging, and Perl 3</b></i><br/>
<a href="dmps.html#24">1.1</a><br/>
<a href="dmps.html#24">What is data munging?</a><br/>
<i>4</i><br/>
<a href="dmps.html#24"><i>Data munging processes</i></a><br/>
<a href="dmps.html#24"><i>4 </i></a>■ <a href="dmps.html#25"><i>Data recognition</i></a><br/>
<a href="dmps.html#25"><i>5 </i></a><br/>
<a href="dmps.html#26"><i>Data parsing</i></a><br/>
<a href="dmps.html#26"><i>6 </i></a>■ <a href="dmps.html#26"><i>Data filtering</i></a><br/>
<a href="dmps.html#26"><i>6 </i></a>■ <a href="dmps.html#26"><i>Data </i></a><br/>
<a href="dmps.html#26"><i>transformation</i></a><br/>
<a href="dmps.html#26"><i>6</i></a><br/>
<a href="dmps.html#27">1.2</a><br/>
<a href="dmps.html#27">Why is data munging important?</a><br/>
<i>7</i><br/>
<a href="dmps.html#27"><i>Accessing corporate data repositories</i></a><br/>
<a href="dmps.html#27"><i>7 </i></a>■ <a href="dmps.html#27"><i>Transferring </i></a><br/>
<a href="dmps.html#27"><i>data between multiple systems</i></a><br/>
<a href="dmps.html#27"><i>7 </i></a>■ <a href="dmps.html#28"><i>Real-world data </i></a><br/>
<a href="dmps.html#28"><i>munging examples</i></a><br/>
<a href="dmps.html#28"><i>8</i></a><br/>
<a href="dmps.html#29">1.3</a><br/>
<a href="dmps.html#29">Where does data come from? Where does it go?</a><br/>
<a href="dmps.html#29"><i>9</i></a><br/>
<a href="dmps.html#29"><i>Data files</i></a><br/>
<a href="dmps.html#29"><i>9 </i></a>■ <a href="dmps.html#30"><i>Databases</i></a><br/>
<a href="dmps.html#30"><i>10 </i></a>■ <a href="dmps.html#31"><i>Data pipes</i></a><br/>
<a href="dmps.html#31"><i>11 </i></a><br/>
<a href="dmps.html#31"><i>Other sources/sinks</i></a><br/>
<a href="dmps.html#31"><i>11</i></a><br/>
<a href="dmps.html#32">1.4</a><br/>
<a href="dmps.html#32">What forms does data take?</a><br/>
<a href="dmps.html#32"><i>12</i></a><br/>
<a href="dmps.html#32"><i>Unstructured data</i></a><br/>
<a href="dmps.html#32"><i>12 </i></a>■ <a href="dmps.html#33"><i>Record-oriented data</i></a><br/>
<a href="dmps.html#33"><i>13 </i></a><br/>
<a href="dmps.html#33"><i>Hierarchical data</i></a><br/>
<a href="dmps.html#33"><i>13 </i></a>■ <a href="dmps.html#33"><i>Binary data</i></a><br/>
<a href="dmps.html#33"><i>13</i></a><br/>
<a href="dmps.html#34">1.5</a><br/>
<a href="dmps.html#34">What is Perl?</a><br/>
<a href="dmps.html#34"><i>14</i></a><br/>
<a href="dmps.html#35"><i>Getting Perl</i></a><br/>
<a href="dmps.html#35"><i>15</i></a><br/>
<hr/>
<a name=6></a><b>vi</b><br/>
CONTENTS<br/>
<a href="dmps.html#36">1.6</a><br/>
<a href="dmps.html#36">Why is Perl good for data munging?</a><br/>
<a href="dmps.html#36"><i>16</i></a><br/>
<a href="dmps.html#37">1.7</a><br/>
<a href="dmps.html#37">Further information</a><br/>
<a href="dmps.html#37"><i>17</i></a><br/>
<a href="dmps.html#37">1.8</a><br/>
<a href="dmps.html#37">Summary</a><br/>
<a href="dmps.html#37"><i>17</i></a><br/>
<a href="dmps.html#38"><i>2  </i></a><i><b>General munging practices 18</b></i><br/>
<a href="dmps.html#39">2.1</a><br/>
<a href="dmps.html#39">Decouple input, munging, and output processes</a><br/>
<i>19</i><br/>
<a href="dmps.html#40">2.2</a><br/>
<a href="dmps.html#40">Design data structures carefully</a><br/>
<a href="dmps.html#40"><i>20</i></a><br/>
<a href="dmps.html#40"><i>Example: the CD file revisited</i></a><br/>
<a href="dmps.html#40"><i>20</i></a><br/>
<a href="dmps.html#45">2.3</a><br/>
<a href="dmps.html#45">Encapsulate business rules</a><br/>
<a href="dmps.html#45"><i>25</i></a><br/>
<a href="dmps.html#46"><i>Reasons to encapsulate business rules</i></a><br/>
<a href="dmps.html#46"><i>26 </i></a>■ <a href="dmps.html#46"><i>Ways to </i></a><br/>
<a href="dmps.html#46"><i>encapsulate business rules</i></a><br/>
<a href="dmps.html#46"><i>26 </i></a>■ <a href="dmps.html#47"><i>Simple module</i></a><br/>
<a href="dmps.html#47"><i>27 </i></a><br/>
<a href="dmps.html#48"><i>Object class</i></a><br/>
<a href="dmps.html#48"><i>28</i></a><br/>
<a href="dmps.html#51">2.4</a><br/>
<a href="dmps.html#51">Use UNIX “filter” model</a><br/>
<a href="dmps.html#51"><i>31</i></a><br/>
<a href="dmps.html#51"><i>Overview of the filter model</i></a><br/>
<a href="dmps.html#51"><i>31 </i></a>■ <a href="dmps.html#52"><i>Advantages of </i></a><br/>
<a href="dmps.html#52"><i>the filter model</i></a><br/>
<a href="dmps.html#52"><i>32</i></a><br/>
<a href="dmps.html#56">2.5</a><br/>
<a href="dmps.html#56">Write audit trails</a><br/>
<a href="dmps.html#56"><i>36</i></a><br/>
<a href="dmps.html#56"><i>What to write to an audit trail</i></a><br/>
<a href="dmps.html#56"><i>36 </i></a>■ <a href="dmps.html#57"><i>Sample audit </i></a><br/>
<a href="dmps.html#57"><i>trail</i></a><br/>
<a href="dmps.html#57"><i>37 </i></a>■ <a href="dmps.html#57"><i>Using the UNIX system logs</i></a><br/>
<a href="dmps.html#57"><i>37</i></a><br/>
<a href="dmps.html#58">2.6</a><br/>
<a href="dmps.html#58">Further information</a><br/>
<a href="dmps.html#58"><i>38</i></a><br/>
<a href="dmps.html#58">2.7</a><br/>
<a href="dmps.html#58">Summary</a><br/>
<a href="dmps.html#58"><i>38</i></a><br/>
<a href="dmps.html#59"><i>3  </i></a><i><b>Useful Perl idioms 39</b></i><br/>
<a href="dmps.html#60">3.1</a><br/>
<a href="dmps.html#60">Sorting</a><br/>
<a href="dmps.html#60"><i>40</i></a><br/>
<a href="dmps.html#60"><i>Simple sorts</i></a><br/>
<a href="dmps.html#60"><i>40 </i></a>■ <a href="dmps.html#61"><i>Complex sorts</i></a><br/>
<a href="dmps.html#61"><i>41 </i></a>■ <a href="dmps.html#62"><i>The Orcish </i></a><br/>
<a href="dmps.html#62"><i>Manoeuvre</i></a><br/>
<a href="dmps.html#62"><i>42 </i></a>■ <a href="dmps.html#63"><i>Schwartzian transform</i></a><br/>
<a href="dmps.html#63"><i>43</i></a><br/>
<a href="dmps.html#63"><i> T</i></a><a href="dmps.html#66"><i>he Guttman-Rosler transform</i></a><br/>
<a href="dmps.html#66"><i>46 </i></a>■ <a href="dmps.html#66"><i>Choosing a </i></a><br/>
<a href="dmps.html#66"><i>sort technique</i></a><br/>
<a href="dmps.html#66"><i>46</i></a><br/>
<a href="dmps.html#67">3.2</a><br/>
<a href="dmps.html#67">Database Interface (DBI)</a><br/>
<a href="dmps.html#67"><i>47</i></a><br/>
<a href="dmps.html#67"><i>Sample DBI program</i></a><br/>
<a href="dmps.html#67"><i>47</i></a><br/>
<a href="dmps.html#69">3.3</a><br/>
<a href="dmps.html#69">Data::Dumper</a><br/>
<a href="dmps.html#69"><i>49</i></a><br/>
<a href="dmps.html#71">3.4</a><br/>
<a href="dmps.html#71">Benchmarking</a><br/>
<a href="dmps.html#71"><i>51</i></a><br/>
<a href="dmps.html#73">3.5</a><br/>
<a href="dmps.html#73">Command line scripts</a><br/>
<a href="dmps.html#73"><i>53</i></a><br/>
<hr/>
<a name=7></a>CONTENTS<br/>
<b>vii</b><br/>
<a href="dmps.html#75">3.6</a><br/>
<a href="dmps.html#75">Further information</a><br/>
<a href="dmps.html#75"><i>55</i></a><br/>
<a href="dmps.html#76">3.7</a><br/>
<a href="dmps.html#76">Summary</a><br/>
<i>56</i><br/>
<a href="dmps.html#77"><i>4  <b>Pat</b></i></a><i><b>tern matching 57</b></i><br/>
<a href="dmps.html#78">4.1</a><br/>
<a href="dmps.html#78">String handling functions</a><br/>
<i>58</i><br/>
<a href="dmps.html#78"><i>Substrings</i></a><br/>
<a href="dmps.html#78"><i>58 </i></a>■ <a href="dmps.html#79"><i>Finding strings within strings (index </i></a><br/>
<a href="dmps.html#79"><i>and rindex)</i></a><br/>
<a href="dmps.html#79"><i>59 </i></a>■ <a href="dmps.html#80"><i>Case transformations</i></a><br/>
<a href="dmps.html#80"><i>60</i></a><br/>
<a href="dmps.html#80">4.2</a><br/>
<a href="dmps.html#80">Regular expressions</a><br/>
<a href="dmps.html#80"><i>60</i></a><br/>
<a href="dmps.html#80"><i>What are regular expressions?</i></a><br/>
<a href="dmps.html#80"><i>60 </i></a>■ <a href="dmps.html#81"><i>Regular expression </i></a><br/>
<a href="dmps.html#81"><i>syntax</i></a><br/>
<a href="dmps.html#81"><i>61 </i></a>■ <a href="dmps.html#85"><i>Using regular expressions</i></a><br/>
<a href="dmps.html#85"><i>65 </i></a>■ <a href="dmps.html#90"><i>Example: </i></a><br/>
<a href="dmps.html#90"><i>translating from English to American</i></a><br/>
<a href="dmps.html#90"><i>70 </i></a>■ <a href="dmps.html#93"><i>More </i></a><br/>
<a href="dmps.html#93"><i>examples: /etc/passwd</i></a><br/>
<a href="dmps.html#93"><i>73 </i></a>■ <a href="dmps.html#96"><i>Taking it to extremes</i></a><br/>
<a href="dmps.html#96"><i>76</i></a><br/>
<a href="dmps.html#97">4.3</a><br/>
<a href="dmps.html#97">Further information</a><br/>
<a href="dmps.html#97"><i>77</i></a><br/>
<a href="dmps.html#98">4.4</a><br/>
<a href="dmps.html#98">Summary</a><br/>
<i>78</i><br/>
<a href="dmps.html#99">PART II DATA MUNGING ............................................ 79</a><br/>
<a href="dmps.html#101"><i>5  <b>Uns</b></i></a><i><b>tructured data 81</b></i><br/>
<a href="dmps.html#102">5.1</a><br/>
<a href="dmps.html#102">ASCII text files</a><br/>
<a href="dmps.html#102"><i>82</i></a><br/>
<a href="dmps.html#102"><i>Reading the file</i></a><br/>
<a href="dmps.html#102"><i>82 </i></a>■ <a href="dmps.html#104"><i>Text transformations</i></a><br/>
<a href="dmps.html#104"><i>84</i></a><br/>
<a href="dmps.html#105"><i>Text statistics</i></a><br/>
<a href="dmps.html#105"><i>85</i></a><br/>
<a href="dmps.html#107">5.2</a><br/>
<a href="dmps.html#107">Data conversions</a><br/>
<a href="dmps.html#107"><i>87</i></a><br/>
<a href="dmps.html#107"><i>Converting the character set</i></a><br/>
<a href="dmps.html#107"><i>87 </i></a>■ <a href="dmps.html#108"><i>Converting line </i></a><br/>
<a href="dmps.html#108"><i>endings</i></a><br/>
<a href="dmps.html#108"><i>88 </i></a>■ <a href="dmps.html#110"><i>Converting number formats</i></a><br/>
<a href="dmps.html#110"><i>90</i></a><br/>
<a href="dmps.html#114">5.3</a><br/>
<a href="dmps.html#114">Further information</a><br/>
<a href="dmps.html#114"><i>94</i></a><br/>
<a href="dmps.html#115">5.4</a><br/>
<a href="dmps.html#115">Summary</a><br/>
<i>95</i><br/>
<a href="dmps.html#116"><i>6  <b>R</b></i></a><i><b>ecord-oriented data 96</b></i><br/>
<a href="dmps.html#117">6.1</a><br/>
<a href="dmps.html#117">Simple record-oriented data</a><br/>
<a href="dmps.html#117"><i>97</i></a><br/>
<a href="dmps.html#117"><i>Reading simple record-oriented data</i></a><br/>
<a href="dmps.html#117"><i>97 </i></a>■ <a href="dmps.html#120"><i>Processing </i></a><br/>
<a href="dmps.html#120"><i>simple record-oriented data</i></a><br/>
<a href="dmps.html#120"><i>100 </i></a>■ <a href="dmps.html#122"><i>Writing simple </i></a><br/>
<a href="dmps.html#122"><i>record-oriented data</i></a><br/>
<a href="dmps.html#122"><i>102 </i></a>■ <a href="dmps.html#125"><i>Caching data</i></a><br/>
<a href="dmps.html#125"><i>105</i></a><br/>
<hr/>
<a name=8></a><b>viii</b><br/>
CONTENTS<br/>
<a href="dmps.html#128">6.2</a><br/>
<a href="dmps.html#128">Comma-separated files</a><br/>
<a href="dmps.html#128"><i>10</i></a><i>8</i><br/>
<a href="dmps.html#128"><i>Anatomy of CSV data</i></a><br/>
<a href="dmps.html#128"><i>108 </i></a>■ <a href="dmps.html#129"><i>Text::CSV_XS</i></a><br/>
<a href="dmps.html#129"><i>109</i></a><br/>
<a href="dmps.html#130">6.3</a><br/>
<a href="dmps.html#130">Complex records</a><br/>
<a href="dmps.html#130"><i>11</i></a><i>0</i><br/>
<a href="dmps.html#131"><i>Example: a different CD file</i></a><br/>
<a href="dmps.html#131"><i>111</i></a><br/>
<a href="dmps.html#133"><i>Special values for $/</i></a><br/>
<a href="dmps.html#133"><i>113</i></a><br/>
<a href="dmps.html#134">6.4</a><br/>
<a href="dmps.html#134">Special problems with date fields</a><br/>
<a href="dmps.html#134"><i>114</i></a><br/>
<a href="dmps.html#134"><i>Built-in Perl date functions</i></a><br/>
<a href="dmps.html#134"><i>114 </i></a><br/>
<a href="dmps.html#140"><i>Date::Calc</i></a><br/>
<a href="dmps.html#140"><i>120 </i></a>■ <a href="dmps.html#141"><i>Date::Manip</i></a><br/>
<a href="dmps.html#141"><i>121</i></a><br/>
<a href="dmps.html#142"><i>Choosing between date modules</i></a><br/>
<a href="dmps.html#142"><i>122</i></a><br/>
<a href="dmps.html#143">6.5</a><br/>
<a href="dmps.html#143">Extended example: web access logs</a><br/>
<a href="dmps.html#143"><i>123</i></a><br/>
<a href="dmps.html#146">6.6</a><br/>
<a href="dmps.html#146">Further information</a><br/>
<a href="dmps.html#146"><i>12</i></a><i>6</i><br/>
<a href="dmps.html#146">6.7</a><br/>
<a href="dmps.html#146">Summary</a><br/>
<a href="dmps.html#146"><i>126</i></a><br/>
<a href="dmps.html#147"><i>7  </i></a><i><b>Fixed-width and binary data 127</b></i><br/>
<a href="dmps.html#148">7.1</a><br/>
<a href="dmps.html#148">Fixed-width data</a><br/>
<a href="dmps.html#148"><i>12</i></a><i>8</i><br/>
<a href="dmps.html#148"><i>Reading fixed-width data</i></a><br/>
<a href="dmps.html#148"><i>128 </i></a>■ <a href="dmps.html#155"><i>Writing </i></a><br/>
<a href="dmps.html#155"><i>fixed-width data</i></a><br/>
<a href="dmps.html#155"><i>135</i></a><br/>
<a href="dmps.html#159">7.2</a><br/>
<a href="dmps.html#159">Binary data</a><br/>
<a href="dmps.html#159"><i>13</i></a><i>9</i><br/>
<a href="dmps.html#160"><i>Reading PNG files</i></a><br/>
<a href="dmps.html#160"><i>140 </i></a>■ <a href="dmps.html#163"><i>Reading and writing </i></a><br/>
<a href="dmps.html#163"><i>MP3 files</i></a><br/>
<a href="dmps.html#163"><i>143</i></a><br/>
<a href="dmps.html#164">7.3</a><br/>
<a href="dmps.html#164">Further information</a><br/>
<a href="dmps.html#164"><i>14</i></a><i>4</i><br/>
<a href="dmps.html#165">7.4</a><br/>
<a href="dmps.html#165">Summary</a><br/>
<a href="dmps.html#165"><i>145</i></a><br/>
<a href="dmps.html#167">PART III SIMPLE DATA PARSING.................................. 147</a><br/>
<a href="dmps.html#169"><i>8  </i></a><i><b>Complex data formats 149</b></i><br/>
<a href="dmps.html#170">8.1</a><br/>
<a href="dmps.html#170">Complex data files</a><br/>
<a href="dmps.html#170"><i>15</i></a><i>0</i><br/>
<a href="dmps.html#170"><i>Example: metadata in the CD file</i></a><br/>
<a href="dmps.html#170"><i>150 </i></a>■ <a href="dmps.html#172"><i>Example: </i></a><br/>
<a href="dmps.html#172"><i>reading the expanded CD file</i></a><br/>
<a href="dmps.html#172"><i>152</i></a><br/>
<a href="dmps.html#174">8.2</a><br/>
<a href="dmps.html#174">How not to parse HTML</a><br/>
<a href="dmps.html#174"><i>15</i></a><i>4</i><br/>
<a href="dmps.html#174"><i>Removing tags from HTML</i></a><br/>
<a href="dmps.html#174"><i>154 </i></a>■ <a href="dmps.html#177"><i>Limitations of </i></a><br/>
<a href="dmps.html#177"><i>regular expressions</i></a><br/>
<a href="dmps.html#177"><i>157</i></a><br/>
<hr/>
<a name=9></a>CONTENTS<br/>
<b>ix</b><br/>
<a href="dmps.html#178">8.3</a><br/>
<a href="dmps.html#178">Parsers</a><br/>
<a href="dmps.html#178"><i>15</i></a><i>8</i><br/>
<a href="dmps.html#178"><i>An introduction to parsers</i></a><br/>
<a href="dmps.html#178"><i>158 </i></a>■ <a href="dmps.html#181"><i>Parsers in Perl</i></a><br/>
<a href="dmps.html#181"><i>161</i></a><br/>
<a href="dmps.html#182">8.4</a><br/>
<a href="dmps.html#182">Further information</a><br/>
<a href="dmps.html#182"><i>16</i></a><i>2</i><br/>
<a href="dmps.html#182">8.5</a><br/>
<a href="dmps.html#182">Summary</a><br/>
<i>162</i><br/>
<a href="dmps.html#183"><i>9  <b>HTM</b></i></a><i><b>L 163</b></i><br/>
<a href="dmps.html#184">9.1</a><br/>
<a href="dmps.html#184">Extracting HTML data from the World Wide Web</a><br/>
<i>164</i><br/>
<a href="dmps.html#185">9.2</a><br/>
<a href="dmps.html#185">Parsing HTML</a><br/>
<a href="dmps.html#185"><i>16</i></a><i>5</i><br/>
<a href="dmps.html#185"><i>Example: simple HTML parsing</i></a><br/>
<a href="dmps.html#185"><i>165</i></a><br/>
<a href="dmps.html#187">9.3</a><br/>
<a href="dmps.html#187">Prebuilt HTML parsers</a><br/>
<a href="dmps.html#187"><i>16</i></a><i>7</i><br/>
<a href="dmps.html#187"><i>HTML::LinkExtor</i></a><br/>
<a href="dmps.html#187"><i>167 </i></a>■ <a href="dmps.html#189"><i>HTML::TokeParser</i></a><br/>
<a href="dmps.html#189"><i>169</i></a><br/>
<a href="dmps.html#191"><i>HTML::TreeBuilder and HTML::Element</i></a><br/>
<a href="dmps.html#191"><i>171</i></a><br/>
<a href="dmps.html#192">9.4</a><br/>
<a href="dmps.html#192">Extended example: getting weather forecasts</a><br/>
<i>172</i><br/>
<a href="dmps.html#194">9.5</a><br/>
<a href="dmps.html#194">Further information</a><br/>
<a href="dmps.html#194"><i>17</i></a><i>4</i><br/>
<a href="dmps.html#194">9.6</a><br/>
<a href="dmps.html#194">Summary</a><br/>
<i>174</i><br/>
<a href="dmps.html#195"><i>10 </i></a><a href="dmps.html#196"><i> </i></a><i><b>XML 175</b></i><br/>
<a href="dmps.html#196">10.1</a><br/>
<a href="dmps.html#196">XML overview</a><br/>
<i>176</i><br/>
<a href="dmps.html#196"><i>What’s wrong with HTML?</i></a><br/>
<a href="dmps.html#196"><i>176 </i></a>■ <a href="dmps.html#196"><i>What is XML?</i></a><br/>
<a href="dmps.html#196"><i>176</i></a><br/>
<a href="dmps.html#198">10.2</a><br/>
<a href="dmps.html#198">Parsing XML with XML::Parser</a><br/>
<a href="dmps.html#198"><i>178</i></a><br/>
<a href="dmps.html#198"><i>Example: parsing weather.xml</i></a><br/>
<a href="dmps.html#198"><i>178 </i></a>■ <a href="dmps.html#199"><i>Using </i></a><br/>
<a href="dmps.html#199"><i>XML::Parser</i></a><br/>
<a href="dmps.html#199"><i>179 </i></a>■ <a href="dmps.html#201"><i>Other XML::Parser styles</i></a><br/>
<a href="dmps.html#201"><i>181</i></a><br/>
<a href="dmps.html#208"><i>XML::Parser handlers</i></a><br/>
<a href="dmps.html#208"><i>188</i></a><br/>
<a href="dmps.html#211">10.3</a><br/>
<a href="dmps.html#211">XML::DOM</a><br/>
<a href="dmps.html#211"><i>191</i></a><br/>
<a href="dmps.html#211"><i>Example: parsing XML using XML::DOM</i></a><br/>
<a href="dmps.html#211"><i>191</i></a><br/>
<a href="dmps.html#213">10.4</a><br/>
<a href="dmps.html#213">Specialized parsers—XML::RSS</a><br/>
<i>193</i><br/>
<a href="dmps.html#213"><i>What is RSS?</i></a><br/>
<a href="dmps.html#213"><i>193 </i></a>■ <a href="dmps.html#213"><i>A sample RSS file</i></a><br/>
<a href="dmps.html#213"><i>193</i></a><br/>
<a href="dmps.html#215"><i>Example: creating an RSS file with XML::RSS</i></a><br/>
<a href="dmps.html#215"><i>195</i></a><br/>
<a href="dmps.html#216"><i>Example: parsing an RSS file with XML::RSS</i></a><br/>
<a href="dmps.html#216"><i>196</i></a><br/>
<a href="dmps.html#217">10.5</a><br/>
<a href="dmps.html#217">Producing different document formats</a><br/>
<i>197</i><br/>
<a href="dmps.html#217"><i>Sample XML input file</i></a><br/>
<a href="dmps.html#217"><i>197 </i></a>■ <a href="dmps.html#218"><i>XML document </i></a><br/>
<a href="dmps.html#218"><i>transformation script</i></a><br/>
<a href="dmps.html#218"><i>198 </i></a>■ <a href="dmps.html#225"><i>Us</i></a><a href="dmps.html#177"><i>ing the XML </i></a><br/>
<a href="dmps.html#177"><i>document transformation script</i></a><br/>
<a href="dmps.html#177"><i>205</i></a><br/>
<hr/>
<a name=10></a><b>x</b><br/>
CONTENTS<br/>
<a href="dmps.html#228">10.6</a><br/>
<a href="dmps.html#228">Further information</a><br/>
<a href="dmps.html#228"><i>20</i></a><i>8</i><br/>
<a href="dmps.html#228">10.7</a><br/>
<a href="dmps.html#228">Summary</a><br/>
<a href="dmps.html#228"><i>208</i></a><br/>
<a href="dmps.html#230"><i>11  </i></a><i><b>Building your own parsers 209</b></i><br/>
<a href="dmps.html#230">11.1</a><br/>
<a href="dmps.html#230">Introduction to Parse::RecDescent</a><br/>
<a href="dmps.html#230"><i>21</i></a><i>0</i><br/>
<a href="dmps.html#230"><i>Example: parsing simple English sentences</i></a><br/>
<a href="dmps.html#230"><i>210</i></a><br/>
<a href="dmps.html#232">11.2</a><br/>
<a href="dmps.html#232">Returning parsed data</a><br/>
<i>212</i><br/>
<a href="dmps.html#232"><i>Example: parsing a Windows INI file</i></a><br/>
<a href="dmps.html#232"><i>212</i></a><br/>
<a href="dmps.html#233"><i>Understanding the INI file grammar</i></a><br/>
<a href="dmps.html#233"><i>213</i></a><br/>
<a href="dmps.html#234"><i>Parser actions and the @item array</i></a><br/>
<a href="dmps.html#234"><i>214</i></a><br/>
<a href="dmps.html#234"><i>Example: displaying the contents of @item</i></a><br/>
<a href="dmps.html#234"><i>214</i></a><br/>
<a href="dmps.html#236"><i>Returning a data structure</i></a><br/>
<a href="dmps.html#236"><i>216</i></a><br/>
<a href="dmps.html#237">11.3</a><br/>
<a href="dmps.html#237">Another example: the CD data file</a><br/>
<a href="dmps.html#237"><i>21</i></a><i>7</i><br/>
<a href="dmps.html#238"><i> Understanding the CD grammar</i></a><br/>
<a href="dmps.html#238"><i>218 </i></a>■ <a href="dmps.html#239"><i>Testing </i></a><br/>
<a href="dmps.html#239"><i>the CD file grammar</i></a><br/>
<a href="dmps.html#239"><i>219 </i></a>■ <a href="dmps.html#240"><i>Adding parser actions</i></a><br/>
<a href="dmps.html#240"><i>220</i></a><br/>
<a href="dmps.html#243">11.4</a><br/>
<a href="dmps.html#243">Other features of Parse::RecDescent</a><br/>
<a href="dmps.html#243"><i>22</i></a><i>3</i><br/>
<a href="dmps.html#244">11.5</a><br/>
<a href="dmps.html#244">Further information</a><br/>
<a href="dmps.html#244"><i>22</i></a><i>4</i><br/>
<a href="dmps.html#244">11.6</a><br/>
<a href="dmps.html#244">Summary</a><br/>
<a href="dmps.html#244"><i>224</i></a><br/>
<a href="dmps.html#245">PART IV THE BIG PICTURE ........................................ 225</a><br/>
<a href="dmps.html#248"><i>12  </i></a><i><b>Looking back—and ahead 227</b></i><br/>
<a href="dmps.html#248">12.1</a><br/>
<a href="dmps.html#248">The usefulness of things</a><br/>
<a href="dmps.html#248"><i>22</i></a><i>8</i><br/>
<a href="dmps.html#248"><i>The usefulness of data munging</i></a><br/>
<a href="dmps.html#248"><i>228 </i></a>■ <a href="dmps.html#248"><i>The usefulness of </i></a><br/>
<a href="dmps.html#248"><i>Perl</i></a><br/>
<a href="dmps.html#248"><i>228 </i></a>■ <a href="dmps.html#249"><i>The usefulness of the Perl community</i></a><br/>
<a href="dmps.html#249"><i>229</i></a><br/>
<a href="dmps.html#249">12.2</a><br/>
<a href="dmps.html#249">Things to know</a><br/>
<a href="dmps.html#249"><i>229</i></a><br/>
<a href="dmps.html#249"><i>Know your data</i></a><br/>
<a href="dmps.html#249"><i>229 </i></a>■ <a href="dmps.html#250"><i>Know your tools</i></a><br/>
<a href="dmps.html#250"><i>230</i></a><br/>
<a href="dmps.html#250"><i>Know where to go for more information</i></a><br/>
<a href="dmps.html#250"><i>230</i></a><br/>
<a href="dmps.html#252"><i>appendix A Modules reference</i></a><br/>
<a href="dmps.html#252"><i>232</i></a><br/>
<a href="dmps.html#274"><i>appendix B Essential Perl</i></a><br/>
<a href="dmps.html#274"><i>254</i></a><br/>
<a href="dmps.html#293"><i>index</i></a><br/>
<a href="dmps.html#293"><i>273</i></a><br/>
<hr/>
<a name=11></a><i>foreword</i><br/>
<i>foreword</i><br/>
Perl is something of a weekend warrior. Outside of business hours you’ll find it<br/>indulging in all kinds of extreme sports: writing haiku; driving GUIs; reviving Lisp,<br/>Prolog, Forth, Latin, and other dead languages; playing psychologist; shovelling<br/>MUDs; inflecting English; controlling neural nets; bringing you the weather; play-<br/>ing with Lego; even running quantum computations. <br/>
 But that’s not its day job.<br/> Nine-to-five it earns its keep far more prosaically: storing information in data-<br/>
bases, extracting it from files, reorganizing rows and columns, converting to and<br/>from bizarre formats, summarizing documents, tracking data in real time, creating<br/>statistics, doing back-up and recovery, merging and splitting data streams, logging<br/>and checkpointing computations. <br/>
 In other words, munging data. It’s a dirty job, but <i>someone</i> has to do it. <br/> If that someone is you, you’re definitely holding the right book. In the follow-<br/>
ing pages, Dave will show you dozens of useful ways to get those everyday data<br/>manipulation chores done better, faster, and more reliably. Whether you deal with<br/>fixed-format data, or binary, or SQL databases, or CSV, or HTML/XML, or some<br/>bizarre proprietary format that was obviously made up on a drunken bet, there’s<br/>help right here.<br/>
 Perl is so good for the extreme stuff, that we sometimes forget how powerful it is<br/>
for mundane data manipulation as well. As this book so ably demonstrates, in addi-<br/>tion to the hundreds of esoteric tools it offers, our favourite Swiss Army Chainsaw<br/>also sports a set of simple blades that are ideal for slicing and dicing ordinary data.<br/>
<a href="dmps.html#293"> Now <i>that’s</i> a knife! </a><br/>
 DAMIAN CONWAY<br/>
<hr/>
<a name=12></a><hr/>
<a name=13></a><i>preface</i><br/>
<i>preface</i><br/>
Over the last five years there has been an explosion of interest in Perl. This is largely<br/>because of the huge boost that Perl received when it was adopted as the de facto<br/>language for creating content on the World Wide Web. Perl’s powerful text manip-<br/>ulation facilities made it an obvious choice for writing Common Gateway Interface<br/>(CGI) scripts. In the wake of the web’s popularity, Perl has become one of the hot-<br/>test programming languages currently in use.<br/>
 Unfortunately, a side effect of this association with CGI programming has been<br/>
the popular misconception that this is Perl’s sole function. Some people even<br/>believe that Perl was designed for use in CGI programming. This is clearly wrong as<br/>Perl was, in fact, written long before the design of the CGI protocol. <br/>
 This book, then, is not about writing CGI scripts, but about another of the<br/>
computing tasks for which Perl is particularly well suited—data munging.<br/>
 Data munging encompasses all of those boring, everyday tasks to which most<br/>
programmers devote a good deal of their time—the tasks of converting data from<br/>one format into another. This comes close to being a definitive statement of what<br/>programming is: taking input data, processing (or “munging”) it, and producing<br/>output data. This is what most programmers do most of the time.<br/>
 Perl is particularly good at these kinds of tasks. It helps programmers write data<br/>
conversion programs quickly. In fact, the same characteristics that make Perl ideal<br/>for CGI programming also make it ideal for data munging. (CGI programs are<br/>really data munging programs in flashy disguise.)<br/>
 In keeping with the Perl community slogan, “There’s more than one way to do<br/>
it,” this book examines a number of ways of dealing with various types of data.<br/>Hopefully, this book will provide some new “ways to do it” that will make your<br/>programming life more productive and more enjoyable. <br/>
<hr/>
<a name=14></a><b>xiv</b><br/>
PREFACE<br/>
 Another Perl community slogan is, “Perl makes easy jobs easy and hard jobs pos-<br/>
sible.” It is my hope that by the time you have reached the end of this book, you<br/>will see that “Perl makes fun jobs fun and boring jobs bearable.”<br/>
<i><b>Intended audience</b></i><br/>
This book is aimed primarily at programmers who munge data as a regular part of<br/>their job and who want to write more efficient data-munging code. I will discuss<br/>techniques for data munging, introducing new techniques, as well as novel uses for<br/>familiar methods. While some approaches can be applied using any language, I use<br/>Perl here to demonstrate the ease of applying these techniques in this versatile lan-<br/>guage. In this way I hope to persuade data mungers that Perl is a flexible and vital<br/>tool for their day-to-day work.<br/>
 Throughout the book, I assume a rudimentary knowledge of Perl on the part of<br/>
the reader. Anyone who has read and understood an introductory Perl text should<br/>have no problem following the code here, but for the benefit of readers brand new<br/>to Perl, I’ve included both my suggestions for Perl primers (see chapter 1) as well as<br/>a brief introduction to Perl (see appendix B).<br/>
<i><b>About this book</b></i><br/>
The book begins by addressing introductory and general topics, before gradually<br/>exploring more complex types of data munging.<br/>
 PART I sets the scene for the rest of the book.<br/>  <i>Chapter 1</i> introduces data munging and Perl. I discuss why Perl is particularly<br/>
well suited to data munging and survey the types of data that you might meet,<br/>along with the mechanisms for receiving and sending data.<br/>
  <i>Chapter 2</i> contains general methods that can be used to make data munging<br/>
programs more efficient. A particularly important part of this chapter is the discus-<br/>sion of the UNIX filter model for program input and output.<br/>
  <i>Chapter 3</i> discusses a number of Perl idioms that will be useful across a number<br/>
of different data munging tasks, including sorting data and accessing databases.<br/>
 <i>Chapter 4</i> introduces Perl’s pattern-matching facilities, a fundamental part of<br/>
many data munging programs.<br/>
 PART II begins our survey of data formats by looking at unstructured and<br/>
record-structured data.<br/>
<hr/>
<a name=15></a>PREFACE<br/>
<b>xv</b><br/>
 <i>Chapter 5</i> surveys unstructured data. We concentrate on processing free text and<br/>
producing statistics from a text file. We also go over a couple of techniques for con-<br/>verting numbers between formats.<br/>
 <i>Chapter 6</i> considers record-oriented data. We look at reading and writing data<br/>
one record at a time and consider the best ways to split records into individual<br/>fields. In this chapter, we also take a closer glance at one common record-oriented<br/>file format: comma-separated values (CSV) files, view more complex record types,<br/>and examine Perl’s data handling facilities.<br/>
 <i>Chapter 7</i> discusses fixed-width and binary data. We compare several techniques<br/>
for splitting apart fixed-width records and for writing results into a fixed-width for-<br/>mat. Then, using the example of a couple of popular binary file formats, we exam-<br/>ine binary data. <br/>
 PART III moves beyond the limits of the simple data formats into the realms of<br/>
hierarchical data structures and parsers.<br/>
 <i>Chapter 8</i> investigates the limitations of the data formats that we have seen pre-<br/>
viously and suggests good reasons for wanting more complex formats. We then see<br/>how the methods we have used so far start to break down on more complex data<br/>like HTML. We also take a brief look at an introduction to parsing theory.<br/>
 <i>Chapter 9</i> explores how to extract useful information from documents marked<br/>
up with HTML. We cover a number of HTML parsing tools available for Perl and<br/>discuss their suitability to particular tasks.<br/>
 <i>Chapter 10</i> discusses XML. First, we consider the limitations of HTML and the<br/>
advantages of XML. Then, we look at XML parsers available for use with Perl.<br/>
 <i>Chapter 11</i> demonstrates how to write parsers for your own data structures<br/>
using a parser-building tool available for Perl.<br/>
 PART IV concludes our tour with a brief review as well as suggestions for fur-<br/>
ther study.<br/>
 <i>Appendix A</i> is a guide to many of the Perl modules covered in the book. <br/> <i>Appendix B</i> provides a rudimentary introduction to Perl.<br/>
<i><b>Typographical conventions</b></i><br/>
The following conventions are used in the book:<br/>
■<br/>
Technical terms are introduced in an <i>italic font</i>.<br/>
■<br/>
The names of functions, files, and modules appear in a fixed-width font.<br/>
<hr/>
<a name=16></a><b>xvi</b><br/>
PREFACE<br/>
■<br/>
All code examples are also in a fixed-width font.<br/>
■<br/>
Program output is in a <b>bold fixed-width font</b>.<br/>
The following conventions are followed in diagrams of data structures:<br/>
■<br/>
An array is shown as a rectangle. Each row within the rect-<br/>
0<br/>
element zero<br/>
angle represents one element of the array. The element<br/>
1<br/>
element one<br/>
index is shown on the left of the row, and the element<br/>value is shown on the right of the row.<br/>
■<br/>
A hash is shown as a rounded rectangle. Each row within<br/>
key1<br/>
value one<br/>
the rectangle represents a key/value pair. The key is shown<br/>
key2<br/>
value two<br/>
on the left of the row, and the value is shown on the right<br/>of the row.<br/>
■<br/>
A reference is shown as a black disk with<br/>
key<br/>
arrayref<br/>
0<br/>
element zero<br/>
1<br/>
element one<br/>
an arrow pointing to the referenced vari-<br/>able. The type of the reference appears to<br/>the left of the disk.<br/>
<i><b>Source code downloads</b></i><br/>
All source code for the examples presented in this book is available to purchasers<br/>from the Manning web site. The URL www.manning.com/cross/ includes a link to<br/>the source code files.<br/>
<i><b>Author Online</b></i><br/>
Purchase of <i>Data Munging with Perl</i> includes free access to a private Web forum run<br/>by Manning Publications where you can make comments about the book, ask tech-<br/>nical questions, and receive help from the author and from other users. To access<br/>the forum and subscribe to it, point your web browser to www.manning.com/<br/>cross/. This page provides information on how to get on the forum once you are<br/>registered, what kind of help is available, and the rules of conduct on the forum.<br/>
 Manning’s commitment to our readers is to provide a venue where a meaning-<br/>
ful dialog between individual readers and between readers and the author can take<br/>place. It is not a commitment to any specific amount of participation on the part of<br/>the author, whose contribution to the AO remains voluntary (and unpaid). We<br/>suggest you try asking the author some challenging questions lest his interest stray! <br/>
<hr/>
<a name=17></a>PREFACE<br/>
<b>xvii</b><br/>
 The Author Online forum and the archives of previous discussions will be acces-<br/>
sible from the publisher’s website as long as the book is in print.<br/>
<i><b>Acknowledgments</b></i><br/>
My heartfelt thanks to the people who have made this book possible (and, who, for<br/>reasons I’ll never understand, don’t insist on having their names appear on the cover).<br/>
 Larry Wall designed and wrote Perl, and without him this book would have<br/>
been very short.<br/>
 Marjan Bace and his staff at Manning must have wondered at times if they<br/>
would ever get a finished book out of me. I’d like to specifically mention Ted<br/>Kennedy for organizing the review process; Mary Piergies for steering the manu-<br/>script through production; Syd Brown for answering my technical questions;<br/>Sharon Mullins and Lianna Wlasiuk for editing; Dottie Marsico for typesetting the<br/>manuscript and turning my original diagrams into something understandable; and<br/>Elizabeth Martin for copyediting.<br/>
 I was lucky enough to have a number of the brightest minds in the Perl commu-<br/>
nity review my manuscript. Without these people the book would have been riddled<br/>with errors, so I owe a great debt of thanks to Adam Turoff, David Adler, Greg<br/>McCarroll, D.J. Adams, Leon Brocard, Andrew Johnson, Mike Stok, Richard<br/>Wherry, Andy Jones, Sterling Hughes, David Cantrell, Jo Walsh, John Wiegley, Eric<br/>Winter, and George Entenman.<br/>
 Other Perl people were involved (either knowingly or unknowingly) in conver-<br/>
sations that inspired sections of the book. Many members of the London Perl Mon-<br/>gers mailing list have contributed in some way, as have inhabitants of the Perl<br/>Monks Monastery. I’d particularly like to thank Robin Houston, Marcel Grünauer,<br/>Richard Clamp, Rob Partington, and Ann Barcomb.<br/>
 Thank you to Sean Burke for correcting many technical inaccuracies and also<br/>
improving my prose considerably.<br/>
 Many thanks to Damian Conway for reading through the manuscript at the last<br/>
minute and writing the foreword.<br/>
 A project of this size can’t be undertaken without substantial support from<br/>
friends and family. I must thank Jules and Crispin Leyser and John and Anna Molo-<br/>ney for ensuring that I took enough time off from the book to enjoy myself drink-<br/>ing beer and playing poker or Perudo.<br/>
 Thank you, Jordan, for not complaining too much when I was too busy to fix<br/>
your computer.<br/>
<hr/>
<a name=18></a><b>xviii</b><br/>
PREFACE<br/>
 And lastly, thanks and love to Gill without whose support, encouragement, and<br/>
love I would never have got to the end of this. I know that at times over the last<br/>year she must have wondered if she still had a husband, but I can only apologize<br/>(again) and promise that she’ll see much more of me now that the book is finished.<br/>
<hr/>
<a name=19></a><i>about the cover illustration</i><br/>
The important-looking man on the cover of <i>Data Munging with Perl</i> is a Turkish<br/>First Secretary of State. While the exact meaning of his title is for us shrouded in<br/>historical fog, there is no doubt that we are facing a man of prestige and power. The<br/>illustration is taken from a Spanish compendium of regional dress customs first pub-<br/>lished in Madrid in 1799. The book’s title page informs us:<br/>
 Coleccion general de los Trages que usan actualmente todas las Nacionas del<br/>
Mundo desubierto, dibujados y grabados con la mayor exactitud por R.M.V.A.R.<br/>Obra muy util y en special para los que tienen la del viajero universal<br/>
 Which we loosely translate as:<br/>
 General Collection of Costumes currently used in the Nations of the Known<br/>
World, designed and printed with great exactitude by R.M.V.A.R. This work is<br/>very useful especially for those who hold themselves to be universal travelers<br/>
 Although nothing is known of the designers, engravers and artists who colored<br/>
this illustration by hand, the “exactitude” of their execution is evident in this draw-<br/>ing. The figure on the cover is a “Res Efendi,” a Turkish government official which<br/>the Madrid editor renders as “Primer Secretario di Estado.” The Res Efendi is just<br/>one of a colorful variety of figures in this collection which reminds us vividly of how<br/>distant and isolated from each other the world’s towns and regions were just 200<br/>years ago. Dress codes have changed since then and the diversity by region, so rich<br/>at the time, has faded away. It is now often hard to tell the inhabitant of one conti-<br/>nent from another. Perhaps we have traded a cultural and visual diversity for a more<br/>varied personal life—certainly a more varied and interesting world of technology.<br/>
 At a time when it can be hard to tell one computer book from another, Manning<br/>
celebrates the inventiveness and initiative of the computer business with book cov-<br/>ers based on the rich diversity of regional life of two centuries ago—brought back<br/>to life by the picture from this collection.<br/>
<hr/>
<a name=20></a><hr/>
<a name=21></a><i>Part I</i><br/>
<i>Foundations</i><br/>
In which our heroes learn a great deal about the background of the<br/>
data munging beast in all its forms and habitats. Fortunately, they are<br/>also told of the great power of the mystical Perl which can be used to<br/>tame the savage beast. <br/>
Our heroes are then taught a number of techniques for fighting the<br/>
beast <i>without</i> using the Perl. These techniques are useful when fighting<br/>with any weapon, and once learned, can be combined with the power of<br/>the Perl to make them even more effective.<br/>
Later, our heroes are introduced to additional techniques for using<br/>
the Perl—all of which prove useful as their journey continues.<br/>
<hr/>
<a name=22></a><hr/>
<a name=23></a><img class="yflip" src="dmp-23_1.jpg"/><br/>
<i>1</i><br/>
<i>Data, data munging,</i><br/>
<i>and Perl</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
The process of munging data<br/>
■<br/>
Sources and sinks of data<br/>
■<br/>
Forms data takes<br/>
■<br/>
Perl and why it is perfect for data munging<br/>
<i>3</i><br/>
<hr/>
<a name=24></a><b>4</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
<i><b>1.1</b></i><br/>
<i><b>What is data munging?</b></i><br/>
<b>munge</b> (muhnj) vt. <b>1.</b> [derogatory] To imperfectly transform information. <b>2.</b> A com-<br/>
prehensive rewrite of a routine, a data structure, or the whole program. <b>3.</b> To mod-<br/>ify data in some way the speaker doesn’t need to go into right now or cannot<br/>describe succinctly (compare mumble). <br/>
The Jargon File &lt;http://www.tuxedo.org/~esr/jargon/html/entry/munge.html&gt;<br/>
Data munging is all about taking data that is in one format and converting it into<br/>
another. You will often hear the term being used when the speaker doesn’t really<br/>know exactly what needs to be done to the data. <br/>
“We’ll take the data that’s exported by this system, munge it around a bit, and<br/>
import it into that system.”<br/>
When you think about it, this is a fundamental part of what many (if not most)<br/>
computer systems do all day. Examples of data munging include:<br/>
■<br/>
The payroll process that takes your pay rate and the hours you work and cre-<br/>ates a monthly payslip<br/>
■<br/>
The process that iterates across census returns to produce statistics about<br/>the population<br/>
■<br/>
A process that examines a database of sports scores and produces a league table<br/>
■<br/>
A publisher who needs to convert manuscripts between many different text formats<br/>
<i><b>1.1.1</b></i><br/>
<i><b>Data munging processes</b></i><br/>
More specifically, data munging consists of a number of processes that are applied to<br/>an initial data set to convert it into a different, but related data set. These processes will<br/>fall into a number of categories: recognition, parsing, filtering, and transformation.<br/>
<i><b>Example data: the CD file<br/></b></i>To discuss these processes, let’s assume that we have a text file containing a descrip-<br/>tion of my CD collection. For each CD, we’ll list the artist, title, recording label,<br/>and year of release. Additionally the file will contain information on the date on<br/>which it was generated and the number of records in the file. Figure 1.1 shows what<br/>this file looks like with the various parts labeled.<br/>
Each row of data in the file (i.e., the information about one CD) is called a data<br/>
<i>record</i>. Each individual item of data (e.g., the CD title or year of release) is called a<br/>data <i>field</i>. In addition to records and fields, the data file might contain additional<br/>information that is held in headers or footers. In this example the header contains a<br/>
<hr/>
<a name=25></a><i><b>What is data munging?</b></i><br/>
<b>5</b><br/>
Dave's Record Collection<br/>
<b>Data header</b><br/>
16 Sep 1999<br/>
Artist<br/>
Title<br/>
Label<br/>
Released<br/>
Bragg, Billy<br/>
Worker's Playtime<br/>
Cooking Vinyl<br/>
1987<br/>
Bragg, Billy<br/>
Mermaid Avenue<br/>
EMI<br/>
1998<br/>
<b>One data record</b><br/>
Black, Mary<br/>
The Holy Ground<br/>
Grapevine<br/>
1993<br/>
Black, Mary<br/>
Circus<br/>
Grapevine<br/>
1996<br/>
Bowie, David<br/>
Hunky Dory<br/>
RCA<br/>
1971<br/>
Bowie, David<br/>
Earthling<br/>
EMI<br/>
1997<br/>
<b>Data footer</b><br/>
<b>One data field</b><br/>
6 Records<br/>
<b>Figure 1.1</b><br/>
<b>Sample data file</b><br/>
description of the data, followed by a header row which describes the meaning of<br/>each individual data field. The footer contains the number of records in the file. This<br/>can be useful to ensure that we have processed (or even received) the whole file.<br/>
We will return to this example throughout the book to demonstrate data mung-<br/>
ing techniques.<br/>
<i><b>1.1.2</b></i><br/>
<i><b>Data recognition</b></i><br/>
You won’t be able to do very much with this data unless you can recognize what<br/>data you have. Data recognition is about examining your source data and working<br/>out which parts of the data are of interest to you. More specifically, it is about a<br/>computer program examining your source data and comparing what it finds against<br/>pre-defined patterns which allow it to determine which parts of the data represent<br/>the data items that are of interest.<br/>
In our CD example there is a lot of data and the format varies within different<br/>
parts of the file. Depending on what we need to do with the data, the header and<br/>footer lines may be of no interest to us. On the other hand, if we just want to report<br/>that on Sept. 16, 1999 I owned six CDs, then all the data we are interested in is in<br/>the header and footer records and we don’t need to examine the actual data records<br/>in any detail.<br/>
An important part of recognizing data is realizing what <i>context</i> the data is found<br/>
in. For example, data items that are in header and footer records will have to be<br/>processed completely differently from data items which are in the body of the data.<br/>
It is therefore very important to understand what our input data looks like and<br/>
what we need to do with it.<br/>
<hr/>
<a name=26></a><b>6</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
<i><b>1.1.3</b></i><br/>
<i><b>Data parsing</b></i><br/>
Having recognized your data you need to be able to do something with it. Data<br/>parsing is about taking your source data and storing it in data structures that make<br/>it easier for you to carry out the rest of the required processes.<br/>
If we are parsing our CD file, we will presumably be storing details of each CD in<br/>
a data structure. Each CD may well be an element in a list structure and perhaps the<br/>header and footer information will be in other variables. Parsing will be the process<br/>that takes the text file and puts the useful data into variables that are accessible from<br/>within our program.<br/>
As with data recognition, it is far easier to parse data if you know what you are<br/>
going to do with it, as this will affect the kinds of data structures that you use.<br/>
In practice, many data munging programs are written so that the data recogni-<br/>
tion and data parsing phases are combined.<br/>
<i><b>1.1.4</b></i><br/>
<i><b>Data filtering</b></i><br/>
It is quite possible that your source data contains too much information. You will<br/>therefore have to reduce the amount of data in the data set. This can be achieved in<br/>a number of ways.<br/>
■<br/>
<i>You can reduce the number of records returned.</i> For example, you could list<br/>only CDs by David Bowie or only CDs that were released in the 1990s.<br/>
■<br/>
<i>You can reduce the number of fields returned.</i> For example, you could list only<br/>the artist, title, and year of release of all of the CDs.<br/>
■<br/>
<i>You can summarize the data in a variety of ways.</i> For example, you could list<br/>only the total number of CDs for each artist or list the number of CDs<br/>released in a certain year.<br/>
■<br/>
<i>You can perform a combination of these processes.</i> For example, you could list<br/>the number of CDs by Billy Bragg.<br/>
<i><b>1.1.5</b></i><br/>
<i><b>Data transformation</b></i><br/>
Having recognized, parsed, and filtered our data, it is very likely that we need to<br/>transform it before we have finished with it. This transformation can take a variety<br/>of forms.<br/>
■<br/>
<i>Changing the value of a data field</i>—For example, a customer number needs<br/>to be converted to a different identifier in order for the data to be used in a<br/>different system.<br/>
<hr/>
<a name=27></a><i><b>Why is data munging important?</b></i><br/>
<b>7</b><br/>
■<br/>
<i>Changing the format of the data record</i>—For example, in the input record, the<br/>fields were separated by commas, but in the output record they need to be<br/>separated by tab characters.<br/>
■<br/>
<i>Combining data fields</i>—In our CD file example, perhaps we want to make the<br/>name of the artist more accessible by taking the “surname, forename” format<br/>that we have and converting it to “forename surname.”<br/>
<i><b>1.2</b></i><br/>
<i><b>Why is data munging important?</b></i><br/>
As I mentioned previously, data munging is at the heart of what most computer sys-<br/>tems do. Just about any computer task can be seen as a number of data munging<br/>tasks. Twenty years ago, before everyone had a PC on a desk, the computing<br/>department of a company would have been known as the Data Processing depart-<br/>ment as that was their role—they processed data. Now, of course, we all deal with<br/>an Information Systems or Information Technology department and the job has<br/>more to do with keeping our PCs working than actually doing any data processing.<br/>All that has happened, however, is that the data processing is now being carried out<br/>by everyone, rather than a small group of computer programmers and operators.<br/>
<i><b>1.2.1</b></i><br/>
<i><b>Accessing corporate data repositories</b></i><br/>
Large computer systems still exist. Not many larger companies run their payroll sys-<br/>tem on a PC and most companies will have at least one database system which con-<br/>tains details of clients, products, suppliers, and employees. A common task for many<br/>office workers is to input data into these corporate data repositories or to extract<br/>data from them. Often the data to be loaded onto the system comes in the form of<br/>a spreadsheet or a comma-separated text file. Often the data extracted will go into<br/>another spreadsheet where it will be turned into tables of data or graphs.<br/>
<i><b>1.2.2</b></i><br/>
<i><b>Transferring data between multiple systems</b></i><br/>
It is obviously convenient for any organization if its data is held in one format in<br/>one place. Every time you duplicate a data item, you increase the likelihood that the<br/>two copies can get out of step with each other. As part of any database design<br/>project, the designers will go through a process known as normalization which<br/>ensures that data is held in the most efficient way possible.<br/>
It is equally obvious that if data is held in only one format, then it will not be in<br/>
the most appropriate format for all of the systems that need to access that data.<br/>While this format may not be particularly convenient for any individual system, it<br/>should be chosen to allow maximum flexibility and ease of processing to simplify<br/>conversion into other formats. In order to be useful to all of the people who want<br/>
<hr/>
<a name=28></a><b>8</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
to make use of the data, it will need to be transformed in various ways as it moves<br/>from one system to the next.<br/>
This is where data munging comes in. It lives in the interstices between compu-<br/>
ter systems, ensuring that data produced by one system can be used by another.<br/>
<i><b>1.2.3</b></i><br/>
<i><b>Real-world data munging examples</b></i><br/>
Let’s look at a couple of simple examples where data munging can be used. These<br/>are simplified accounts of tasks that I carried out for large investment banks in the<br/>city of London.<br/>
<i><b>Loading multiple data formats into a single database<br/></b></i>In the first of these examples, a bank was looking to purchase some company<br/>accounting data to drive its equities research department. In any large bank the<br/>equity research department is full of people who build complex financial models of<br/>company performance in order to try to predict future performance, and hence<br/>share price. They can then recommend shares to their clients who buy them and<br/>(hopefully) get a lot richer in the process.<br/>
This particular bank needed more data to use in its existing database of company<br/>
accounting data. There are many companies that supply this data electronically and<br/>a short list of three suppliers had been drawn up and a sample data set had been<br/>received from each. My task was to load these three data sets, in turn, onto the<br/>existing database.<br/>
The three sets of data came in different formats. I therefore decided to design a<br/>
canonical file format and write a Perl script that would load that format onto the<br/>database. I then wrote three other Perl scripts (one for each input file) which read<br/>the different input files and wrote a file in my standard format. In this case I was<br/>reading from a number of sources and writing to one place.<br/>
<i><b>Sharing data using a standard data format<br/></b></i>In the second example I was working on a trading system which needed to send<br/>details of trades to various other systems. Once more, the data was stored in a rela-<br/>tional database. In this case the bank had made all interaction between systems<br/>much easier by designing an XML file format1 for data interchange. Therefore, all<br/>we needed to do was to extract our data, create the necessary XML file, and send it<br/>on to the systems that required it. By defining a standard data format, the bank<br/>
1 The definition of an XML file format is known as a Document Type Definition (DTD), but we’ll get to<br/>
that in chapter 10.<br/>
<hr/>
<a name=29></a><i><b>Where does data come from? Where does it go?</b></i><br/>
<b>9</b><br/>
ensured that all of its systems would only need to read or write one type of file,<br/>thereby saving a large amount of development time.<br/>
<i><b>1.3</b></i><br/>
<i><b>Where does data come from? Where does it go?</b></i><br/>
As we saw in the previous section, the point of data munging is to take data in one<br/>format, carry out various transformations on it, and write it out in another format.<br/>Let’s take a closer look at where the data might come from and where it might go.<br/>
First a bit of terminology. The place that you receive data from is known as your<br/>
<i>data source</i>. The place where you send data to is known as your <i>data sink</i>. <br/>
Sources and sinks can take a number of different forms. Some of the most com-<br/>
mon ones that you will come across are:<br/>
■<br/>
Data files<br/>
■<br/>
Databases<br/>
■<br/>
Data pipes<br/>
Let’s look at these data sources and sinks in more detail.<br/>
<i><b>1.3.1</b></i><br/>
<i><b>Data files</b></i><br/>
Probably the most common way to transfer data between systems is in a file. One<br/>application writes a file. This file is then transferred to a place where your data<br/>munging process can pick it up. Your process opens the file, reads in the data, and<br/>writes a new file containing the transformed data. This new file is then used as the<br/>input to another application elsewhere.<br/>
Data files are used because they represent the lowest common denominator<br/>
between computer systems. Just about every computer system has the concept of a<br/>disk file. The exact format of the file will vary from system to system (even a plain<br/>ASCII text file has slightly different representations under UNIX and Windows) but<br/>handling that is, after all, part of the job of the data munger.<br/>
<i><b>File transfer methods<br/></b></i>Transferring files between different systems is also something that is usually very<br/>easy to achieve. Many computer systems implement a version of the <i>File Transfer<br/>Protocol</i> (FTP) which can be used to copy files between two systems that are con-<br/>nected by a network. A more sophisticated system is the <i>Network File System</i> (NFS)<br/>protocol, in which file systems from one computer can be viewed as apparently local<br/>files systems on another computer. Other common methods of transferring files are<br/>by using removable media (CD-ROMs, floppy disks, or tapes) or even as a MIME<br/>attachment to an email message.<br/>
<hr/>
<a name=30></a><b>10</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
<i><b>Ensuring that file transfers are complete<br/></b></i>One difficulty to overcome with file transfer is the problem of knowing if a file is<br/>complete. You may have a process that sits on one system, monitoring a file system<br/>where your source file will be written by another process. Under most operating<br/>systems the file will appear as soon as the source process begins to write it. Your<br/>process shouldn’t start to read the file until it has all been transferred. In some<br/>cases, people write complex systems which monitor the size of the file and trigger<br/>the reading process only once the file has stopped growing. Another common solu-<br/>tion is for the writing process to write another small flag file once the main file is<br/>complete and for the reading process to check for the existence of this flag file. In<br/>most cases a much simpler solution is also the best—simply write the file under a<br/>different name and only rename it to the expected name once it is complete.<br/>
Data files are most useful when there are discrete sets of data that you want to<br/>
process in one chunk. This might be a summary of banking transactions sent to an<br/>accounting system at the end of the day. In a situation where a constant flow of data<br/>is required, one of the other methods discussed below might be more appropriate.<br/>
<i><b>1.3.2</b></i><br/>
<i><b>Databases</b></i><br/>
Databases are becoming almost as ubiquitous as data files. Of course, the term<br/>“database” means vastly differing things to different people. Some people who are<br/>used to a Windows environment might think of dBase or some similar nonrelational<br/>database system. UNIX users might think of a set of DBM files. Hopefully, most<br/>people will think of a relational database management system (RDBMS), whether it<br/>is a single-user product like Microsoft Access or Sybase Adaptive Server Anywhere,<br/>or a full multi-user product such as Oracle or Sybase Adaptive Server Enterprise.<br/>
<i><b>Imposing structure on data<br/></b></i>Databases have advantages over data files in that they impose structure on your<br/>data. A database designer will have defined a <i>database schema</i>, which defines the<br/>shape and type of all of your data objects. It will define, for example, exactly which<br/>data items are stored for each customer in the database, which ones are optional and<br/>which ones are mandatory. Many database systems also allow you to define relation-<br/>ships between data objects (for example, “each order must contain a customer iden-<br/>tifier which must relate to an existing customer”). Modern databases also contain<br/>executable code which can define some of your business logic (for example, “when<br/>the status of an order is changed to ‘delivered,’ automatically create an invoice<br/>object relating to that order”).<br/>
Of course, all of these benefits come at a price. Manipulating data within a data-<br/>
base is potentially slower than equivalent operations on data files. You may also<br/>
<hr/>
<a name=31></a><i><b>Where does data come from? Where does it go?</b></i><br/>
<b>11</b><br/>
need to invest in new hardware as some larger database systems like to have their<br/>own CPU (or CPUs) to run on. Nevertheless, most organizations are prepared to<br/>pay this price for the extra flexibility that they get from a database.<br/>
<i><b>Communicating with databases<br/></b></i>Most modern databases use a dialect of Structured Query Language (SQL) for all of<br/>their data manipulation. It is therefore very likely that if your data source or sink is an<br/>RDBMS that you will be communicating with it using SQL. Each vendor’s RDBMS<br/>has its own proprietary interface to get SQL queries into the database and data back<br/>into your program, but Perl now has a vendor-independent database interface (called<br/>DBI) which makes it much easier to switch processing between different databases.2<br/>
<i><b>1.3.3</b></i><br/>
<i><b>Data pipes</b></i><br/>
If you need to constantly monitor data that is being produced by a system and<br/>transform it so it can be used by another system (perhaps a system that is monitor-<br/>ing a real-time stock prices feed), then you should look at using a data pipe. In this<br/>system an application writes directly to the standard input of your program. Your<br/>program needs to read data from its input, deal with it (by munging it and writing it<br/>somewhere), and then go back to read more input. You can also create a data pipe<br/>(or continue an existing one) by writing your munged data to your standard out-<br/>put, hoping that the next link in the pipe will pick it up from there.<br/>
We will look at this concept in more detail when discussing the UNIX “filter”<br/>
model in chapter 2.<br/>
<i><b>1.3.4</b></i><br/>
<i><b>Other sources/sinks</b></i><br/>
There are a number of other types of sources and sinks. Here, briefly, are a few<br/>more that you might come across. In each of these examples we talk about receiving<br/>data from a source, but the concepts apply equally well to sending data to a sink.<br/>
■<br/>
<i>Named Pipe</i>—This is a feature of many UNIX-like operating systems. One<br/>process prepares to write data to a named pipe which, to other processes,<br/>looks like a file. The writing process waits until another process tries to read<br/>from the file. At that point it writes a chunk of data to the named pipe, which<br/>the reading process sees as the contents of the file. This is useful if the reading<br/>process has been written to expect a file, but you want to write constantly<br/>changing data.<br/>
2 As long as you don’t make any use of vendor-specific features.<br/>
<hr/>
<a name=32></a><b>12</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
■<br/>
<i>TCP/IP Socket</i>—This is a good way to send a stream of data between two<br/>computers that are on the same network.3 The two systems define a TCP/IP<br/>port number through which they will communicate. The data munging pro-<br/>cess then sets itself up as a TCP/IP server and listens for connections on the<br/>right port. When the source has data to send, it instigates a connection on the<br/>port. Some kind of (application-defined) handshaking then takes place, fol-<br/>lowed by the source sending the data across to the waiting server.<br/>
■<br/>
<i>HTTP </i>4—This method is becoming more common. If both programs have<br/>access to the Internet, they can be on opposite sides of the world and can still<br/>talk to each other. The source simply writes the data to a file somewhere on<br/>the publicly accessible Internet. The data munging program uses HTTP to<br/>send a request for the file to the source’s web server and, in response, the web<br/>server sends the file. The file could be an HTML file, but it could just as easily<br/>be in any other format. HTTP also has some basic authentication facilities<br/>built into it, so it is feasible to protect files to which you don’t want the pub-<br/>lic to have access.<br/>
<i><b>1.4</b></i><br/>
<i><b>What forms does data take?</b></i><br/>
Data comes in many different formats. We will be examining many formats in<br/>more detail later in the book, but for now we’ll take a brief survey of the most pop-<br/>ular ones.<br/>
<i><b>1.4.1</b></i><br/>
<i><b>Unstructured data</b></i><br/>
While there is a great deal of unstructured data in the world, it is unlikely that you<br/>will come across very much of it, because the job of data munging is to convert data<br/>from one structure to another. It is very difficult for a computer program to impose<br/>structure on data that isn’t already structured in some way. Of course, one common<br/>data munging task is to take data with no apparent structure and bring out the<br/>structure that was hiding deep within it.<br/>
The best example of unstructured data is plain text. Other than separating text<br/>
into individual lines and words and producing statistics, it is difficult to do much<br/>useful work with this kind of data.<br/>
3 Using the term “network” in a very wide sense. Most Internet protocols are based on TCP/IP so that<br/>
while your modem is dialed into your Internet Service Provider, your PC is on the same network as the<br/>web server that you are downloading MP3s from.<br/>
4 Strictly speaking, HTTP is just another protocol running on top of TCP/IP, but it is important enough<br/>
to justify discussing it separately.<br/>
<hr/>
<a name=33></a><i><b>What forms does data take?</b></i><br/>
<b>13</b><br/>
Nonetheless, we will examine unstructured data in chapter 5. This is largely<br/>
because it will give us the chance to discuss some general mechanisms, such as read-<br/>ing and writing files, before moving on to better structured data.<br/>
<i><b>1.4.2</b></i><br/>
<i><b>Record-oriented data</b></i><br/>
Most of the simple data that you will come across will be record-oriented. That is,<br/>the data source will consist of a number of records, each of which can be processed<br/>separately from its siblings. Records can be separated from each other in a number<br/>of ways. The most common way is for each line in a text file to represent one<br/>record,5 but it is also possible that a blank line or a well-defined series of characters<br/>separates records.<br/>
Within each record, there will probably be fields, which represent the various<br/>
data items of the record. These will also be denoted in several different ways. There<br/>may well be a particular character between different fields (often a comma or a tab),<br/>but it is also possible that a record will be padded with spaces or zeroes to ensure<br/>that it is always a given number of characters in width.<br/>
We will look at record-oriented data in chapter 6.<br/>
<i><b>1.4.3</b></i><br/>
<i><b>Hierarchical data</b></i><br/>
This is an area that will be growing in importance in the coming years. The best<br/>example of hierarchical data is the <i>Standardized General Mark-up Language<br/></i>(SGML), and its two better known offspring, the <i>Hypertext Mark-up Language<br/></i>(HTML) and the <i>Extensible Mark-up Language</i> (XML). In these systems, each data<br/>item is surrounded by tags which denote its position in the hierarchy of the data. A<br/>data item is contained by its parent and contains its own children.6 At this point,<br/>the record-at-a-time processing methods that we will have been using on simpler<br/>data types no longer work and we will be forced to find more powerful tools.<br/>
We will look at hierarchical data (specifically HTML and XML) in chapters 9<br/>
and 10.<br/>
<i><b>1.4.4</b></i><br/>
<i><b>Binary data</b></i><br/>
Finally, there is binary data. This is data that you cannot successfully use without<br/>software which has been specially designed to handle it. Without having access to an<br/>explanation of the structure of a binary data file, it is very difficult to make any sense<br/>
5 There is, of course, potential for confusion over exactly what constitutes a line, but we’ll discuss that in<br/>
more detail later.<br/>
6 This family metaphor can, of course, be taken further. Two nodes which have the same parent are known<br/>
as <i>sibling</i> nodes, although I’ve never yet heard two nodes with the same grandparents described as <i>cousins</i>.<br/>
<hr/>
<a name=34></a><b>14</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
of it. We will take a look at some publicly available binary file formats and see how<br/>to get some meaningful data out of them.<br/>
We will look at binary data in chapter 7.<br/>
<i><b>1.5</b></i><br/>
<i><b>What is Perl?</b></i><br/>
Perl is a computer programming language that has been in use since 1987. It was<br/>initially developed for use on the UNIX operating system, but it has since been<br/>ported to more operating systems than just about any other programming language<br/>(with the possible exception of C).<br/>
Perl was written by Larry Wall to solve a particular problem, but instead of writ-<br/>
ing something that would just solve the question at hand, Wall wrote a general tool<br/>that he could use to solve other problems later.<br/>
What he came up with was just about the most useful data processing tool that<br/>
anyone has created.<br/>
What makes Perl different from many other computer languages is that Wall has<br/>
a background in linguistics and brought a lot of this knowledge to bear in the<br/>design of Perl’s syntax. This means that a lot of the time you can say things in a<br/>more natural way in Perl and the code will mean what you expect it to mean.<br/>
For example, most programming languages have an if statement which you can<br/>
use to write something like this:<br/>
if (condition) {<br/>
do_something();<br/>
}<br/>
but what happens if you want to do some special processing only if the condition is<br/>false? Of course you can often write something like:<br/>
if (not condition) {<br/>
do_something()<br/>
}<br/>
but it’s already starting to look a bit unwieldy. In Perl you can write:<br/>
unless (condition) {<br/>
do_something()<br/>
}<br/>
which reads far more like English. In fact you can even write:<br/>
do_something() unless condition;<br/>
which is about as close to English as a programming language ever gets.<br/>
<hr/>
<a name=35></a><i><b>What is Perl?</b></i><br/>
<b>15</b><br/>
A Perl programmer once explained to me the moment when he realized that Perl<br/>
and he were made for each other was when he wrote some pseudocode which<br/>described a possible solution to a problem and accidentally ran it through the Perl<br/>interpreter. It ran correctly the first time.<br/>
As another example of how Perl makes it easier to write code that is easier to<br/>
read, consider opening a file. This is something that just about any kind of program<br/>has to do at some point. This is a point in a program where error checking is very<br/>important, and in many languages you will see large amounts of code surrounding a<br/>file open statement. Code to open a file in C looks like this:<br/>
if ((f = fopen(&#34;file.txt&#34;, &#34;r&#34;)) == NULL) {<br/>
perror(&#34;file.txt&#34;);<br/>
exit(0);<br/>
}<br/>
whereas in Perl you can write it like this:<br/>
open(FILE, 'file.txt') or die &#34;Can't open file.txt: $!&#34;;<br/>
This opens a file and assigns it to the file handle FILE which you can later use to<br/>read data from the file. It also checks for errors and, if anything goes wrong, it kills<br/>the program with an error message explaining exactly what went wrong. And, as a<br/>bonus, once more it almost reads like English.<br/>
Perl is not for everyone. Some people enjoy the verbosity of some other lan-<br/>
guages or the rigid syntax of others. Those who do make an effort to understand<br/>Perl typically become much more effective programmers.<br/>
Perl is not for every task. Many speed-critical routines are better written in C or<br/>
assembly language. In Perl, however, it is possible to split these sections into separate<br/>modules so that the majority of the program can still be written in Perl if desired.<br/>
<i><b>1.5.1</b></i><br/>
<i><b>Getting Perl</b></i><br/>
One of the advantages of Perl is that it is free.7 The source code for Perl is available<br/>for download from a number of web sites. The definitive site to get the Perl source<br/>code (and, indeed, for all of your other Perl needs) is www.perl.com, but the Perl<br/>source is mirrored at sites all over the world. You can find the nearest one to you<br/>listed on the main site. Once you have the source code, it comes with simple instruc-<br/>tions on how to build and install it. You’ll need a C compiler and a make utility.8<br/>
7 Free as in both the “free speech” and “free beer” meanings of the word. For a longer discussion of the<br/>
advantages of these, please visit the Free Software Foundation at www.fsf.org.<br/>
8 If you don’t have these, then you can get copies of the excellent gcc and GNU make from the Free Soft-<br/>
ware Foundation.<br/>
<hr/>
<a name=36></a><b>16</b><br/>
CHAPTER <br/>
<i><b>Data, data munging, and Perl</b></i><br/>
Downloading source code and compiling your own tools is a common procedure<br/>
on UNIX systems. Many Windows developers, however, are more used to installing<br/>prepackaged software. This is not a problem, as they can get a prebuilt binary called<br/>ActivePerl from ActiveState at www.activestate.com. As with other versions of Perl,<br/>this distribution is free.<br/>
<i><b>1.6</b></i><br/>
<i><b>Why is Perl good for data munging?</b></i><br/>
Perl has a number of advantages that make it particularly useful as a data munging<br/>language. Let’s take a look at a few of them.<br/>
■<br/>
<i>Perl is interpreted</i>—Actually Perl isn’t really interpreted, but it looks as<br/>though it is to the programmer. There is no separate compilation phase that<br/>the programmer needs to run before executing a Perl program. This makes<br/>the development of a Perl program very quick as it frees the programmer<br/>from the edit-compile-test-debug cycle, which is typical of program develop-<br/>ment in languages like C and C++.<br/>
■<br/>
<i>Perl is compiled</i><b>—</b>What actually happens is that a Perl program is compiled<br/>automatically each time it is run. This gives a slight performance hit when the<br/>program first starts up, but means that once the program is running you<br/>don’t get any of the performance problems that you would from a purely<br/>interpreted language.<br/>
■<br/>
<i>Perl has powerful data recognition and transformation features</i><b>—</b>A lot of data<br/>munging consists of recognizing particular parts of the input data and then<br/>transforming them. In Perl this is often achieved by using regular expressions.<br/>We will look at regular expressions in some detail later in the book, but at this<br/>point it suffices to point out that Perl’s regular expression support is second<br/>to none.<br/>
■<br/>
<i>Perl supports arbitrarily complex data structures</i><b>—</b>When munging data, you<br/>will usually want to build up internal data structures to store the data in<br/>interim forms before writing it to the output file. Some programming lan-<br/>guages impose limits on the complexity of internal data structures. Since the<br/>introduction of Perl 5, Perl has had no such constraints.<br/>
■<br/>
<i>Perl encourages code reuse</i><b>—</b>You will often be munging similar sorts of data in<br/>similar ways. It makes sense to build a library of reusable code to make writ-<br/>ing new programs easier. Perl has a very powerful system for creating mod-<br/>ules of code that can be slotted into other scripts very easily. In fact, there is a<br/>global repository of reusable Perl modules available across the Internet at<br/>www.cpan.org. CPAN stands for the Comprehensive Perl Archive Network. If<br/>
<hr/>
<a name=37></a><i><b>Summary</b></i><br/>
<b>17</b><br/>
someone else has previously solved your particular problem then you will find<br/>a solution there. If you are the first person to address a particular problem,<br/>once you’ve solved it, why not submit the solution to the CPAN. That way<br/>everyone benefits.<br/>
■<br/>
<i>Perl is fun</i><b>—</b>I know this is a very subjective opinion, but the fact remains that<br/>I have seen jaded C programmers become fired up with enthusiasm for their<br/>jobs once they’ve been introduced to Perl. I’m not going to try to explain it,<br/>I’m just going to suggest that you give it a try.<br/>
<i><b>1.7</b></i><br/>
<i><b>Further information</b></i><br/>
The best place to get up-to-date information about Perl is the Perl home page at<br/>www.perl.com.<br/>
Appendix B contains a brief overview of the Perl language, but if you want to<br/>
learn Perl you should look at one of the many Perl tutorial books. If you are a non-<br/>programmer then <i>Elements of Programming with Perl</i> by Andrew Johnson (Man-<br/>ning) would be a good choice. Programmers looking to learn a new language should<br/>look at <i>Learning Perl (2nd edition)</i> by Randal Schwartz and Tom Christiansen<br/>(O’Reilly) or <i>Perl: The Programmer’s Companion</i> by Nigel Chapman (Wiley).<br/>
The definitive Perl reference book is <i>Programming Perl (3rd edition)</i> by Larry<br/>
Wall, Tom Christiansen and Jon Orwant (O’Reilly).<br/>
Perl itself comes with a huge amount of documentation. Once you have<br/>
installed Perl, you can type perldoc perl at your command line to get a list of the<br/>available documents.<br/>
<i><b>1.8</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
Data munging is the process of taking data from one system (a data source)<br/>and converting it so that it is suitable for use by a different system (a data sink).<br/>
■<br/>
Data munging consists of four stages—data recognition, parsing, filtering,<br/>and transformation.<br/>
■<br/>
Data can come from (and be written to) a large number of different types of<br/>sources and sinks.<br/>
■<br/>
Data itself can take a large number of forms, text or binary, unstructured or<br/>structured, record oriented or hierarchical.<br/>
■<br/>
Perl is a language which is very well suited for the whole range of data mung-<br/>ing jobs.<br/>
<hr/>
<a name=38></a><img class="yflip" src="dmp-38_1.jpg"/><br/>
<i>2</i><br/>
<i>General munging</i><br/>
<i>practices</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Processes for munging data<br/>
■<br/>
Data structure designs<br/>
■<br/>
Encapsulating business rules<br/>
■<br/>
The UNIX filter model<br/>
■<br/>
Writing audit trails <br/>
<i>18</i><br/>
<hr/>
<a name=39></a><i><b>Decouple input, munging, and output processes</b></i><br/>
<b>19</b><br/>
When munging data there are a number of general principles which will be useful<br/>across a large number of different tasks. In this chapter we will take a look at some<br/>of these techniques.<br/>
<i><b>2.1</b></i><br/>
<i><b>Decouple input, munging, and output processes</b></i><br/>
When written in pseudocode, most data munging tasks will look very similar. At the<br/>highest level, the pseudocode will look something like this: <br/>
Read input data<br/>
Munge data<br/>
Write output data<br/>
Obviously, each of these three subtasks will need to be broken down into greater<br/>detail before any real code can be written; however, looking at the problem from<br/>this high level can demonstrate some useful general principles about data munging.<br/>
 Suppose that we are combining data from several systems into one database. In<br/>
this case our different data sources may well provide us with data in very different<br/>formats, but they all need to be converted into the same format to be passed on to<br/>our data sink. Our lives will be made much easier if we can write one output routine<br/>that handles writing the output from all of our data inputs. In order for this to be<br/>possible, the data structures in which we store our data just before we call the com-<br/>bined output routines will need to be in the same format. This means that the data<br/>munging routines need to leave the data in the same format, no matter which of the<br/>data sinks we are dealing with. One easy way to ensure this is to use the same data<br/>munging routines for each of our data sources. In order for this to be possible, the<br/>data structures that are output from the various data input routines must be in the<br/>same format. It may be tempting to try to take this a step further and reuse our<br/>input routines, but as our data sources can be in completely different formats, this is<br/>not likely to be possible. As figures 2.1 and 2.2 show, instead of writing three<br/>
Data<br/>
Data<br/>
Data<br/>
Data<br/>
Source<br/>
Input<br/>
Munge<br/>
Output<br/>
A<br/>
A<br/>
A<br/>
A<br/>
Data<br/>
Sink<br/>
Data<br/>
Data<br/>
Data<br/>
Data<br/>
Source<br/>
Input<br/>
Munge<br/>
Output<br/>
B<br/>
B<br/>
B<br/>
B<br/>
<b>Figure 2.1</b><br/>
<b>Separate munging and output processes</b><br/>
<hr/>
<a name=40></a><b>20</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
Data<br/>
Data<br/>
Source<br/>
Input<br/>
A<br/>
A<br/>
Data<br/>
Data<br/>
Data<br/>
Munge<br/>
Output<br/>
Sink<br/>
Data<br/>
Data<br/>
Source<br/>
Input<br/>
B<br/>
B<br/>
<b>Figure 2.2</b><br/>
<b>Combined munging and output processes</b><br/>
routines for each data source, we now need only write an input routine for each<br/>source with common munging and output routines.<br/>
 A very similar argument can be made if we are taking data from one source and<br/>
writing it to a number of different data sinks. In this case, only the data output<br/>routines need to vary from sink to sink and the input and munging routines can<br/>be shared.<br/>
 There is another advantage to this decoupling of the various stages of the task. If<br/>
we later need to read data from the same data source, or write data to the same data<br/>sink for another task, we already have code that will do the reading or writing for us.<br/>Later in this chapter we will look at some ways that Perl helps us to encapsulate these<br/>routines in reusable code libraries.<br/>
<i><b>2.2</b></i><br/>
<i><b>Design data structures carefully</b></i><br/>
Probably the most important way that you can make your data munging code (or,<br/>indeed, any code) more efficient is to design the intermediate data structures care-<br/>fully. As always in software design, there are compromises to be made, but in this<br/>section we will look at some of the factors that you should consider.<br/>
<i><b>2.2.1</b></i><br/>
<i><b>Example: the CD file revisited</b></i><br/>
As an example, let’s return to the list of compact disks that we discussed in<br/>chapter 1. We’ll assume that we have a tab-separated text file where the columns are<br/>artist, title, record label, and year of release. Before considering what internal data<br/>structures we will use, we need to know what sort of output data we will be creat-<br/>ing. Suppose that we needed to create a list of years, together with the number of<br/>CDs released in that year.<br/>
<hr/>
<a name=41></a><i><b>Design data structures carefully</b></i><br/>
<b>21</b><br/>
<i><b>Solution 1: simple hash<br/></b></i>The immediately obvious solution is to use a hash in which the keys are years and<br/>the values are the numbers of CDs. In this case, there will be no need for a separate<br/>data munging process, as all of the required munging will be carried out in the<br/>input routine. We might create a first draft script something like this:<br/>
my %years;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my $year = (split /\t/)[3];<br/>
$years{$year}++;<br/>
}<br/>
foreach (sort keys %years) {<br/>
print &#34;In $_, $years{$_} CDs were released.\n&#34;;<br/>
}<br/>
This provides a solution to our problem in a reasonably<br/>
1971<br/>
1<br/>
efficient manner. The data structure that we build is very<br/>
1987<br/>
1<br/>
simple and is shown in figure 2.3. <br/>
1993<br/>
1<br/>
1996<br/>
1<br/>
<i><b>Solution 2: adding flexibility</b></i><br/>
1997<br/>
1<br/>
But how often are requirements as fixed as these?1 Sup-<br/>
1998<br/>
1<br/>
pose later someone decides that, instead of having a list of<br/>the number of CDs released, they also need a list of the<br/>
<b>Figure 2.3</b><br/>
<b>Initial data </b><br/>
actual CDs. In this case, we will need to go back and<br/>
<b>structure design</b><br/>
rewrite our script completely to something like this:<br/>
my %years;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my ($artist, $title, $label, $year) = split /\t/;<br/>
my $rec = {artist =&gt; $artist,<br/>
title<br/>
=&gt; $title,<br/>
label<br/>
=&gt; $label};<br/>
push @ {$year{$year}}, $rec;<br/>
}<br/>
foreach my $year (sort keys %years) {<br/>
my $count = scalar @{$years{$year}};<br/>
print &#34;In $year, $count CDs were released.\n&#34;;<br/>
print “They were:\n”;<br/>
print map { &#34;$_-&gt;{title} by $_-&gt;{artist}\n&#34; } @{$years{$year}};<br/>
}<br/>
1 There are, of course, many times when the requirements won’t change—because this is a one-off data load<br/>
process or you are proving a concept or building a prototype.<br/>
<hr/>
<a name=42></a><b>22</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
As you can see, this change has entailed an almost complete rewrite of the script. In<br/>the new version, we still have a hash where the keys are the years, but each value is<br/>now a reference to an array. Each element of this array is a reference to a hash which<br/>contains the artist, title, and label of the CD. The output section has also grown<br/>more complex as it needs to extract more information from the hash.<br/>
 Notice that the hash stores the CD’s label even though we don’t use it in the<br/>
output from the script. Although the label isn’t required in our current version, it is<br/>quite possible that it will become necessary to add it to the output at some point in<br/>the future. If this happens we will no longer need to make any changes to the input<br/>section of our script as we already have the data available in our hash. This is, in<br/>itself, an important data munging principle—if you’re reading in a data item, you<br/>may as well store it in your data structure. This can be described more succinctly as<br/>“Don’t throw anything away.” This improved data structure is shown in figure 2.4.<br/>
1971<br/>
arrayref<br/>
0<br/>
hashref<br/>
artist<br/>
David Bowie<br/>
1987<br/>
arrayref<br/>
title<br/>
Hunky Dory<br/>
1993<br/>
arrayref<br/>
label<br/>
RCA<br/>
1996<br/>
arrayref<br/>
1997<br/>
arrayref<br/>
1998<br/>
arrayref<br/>
<b>Figure 2.4</b><br/>
<b>Improved data structure design</b><br/>
<i><b>Solution 3: separating parsing from munging<br/></b></i>What happens, however, if the requirements change completely so that we now<br/>need to display counts by artist for a different report? Our current script is of no use<br/>at all. There is no part of it that is reusable to help us achieve our new goals. Per-<br/>haps we need to rethink our strategy from the start.<br/>
 In all of the scripts above we were not following the advice of the previous sec-<br/>
tion. We were trying to do too much in the input section and left ourselves nothing<br/>to do in the data munging section. Perhaps if we went back to a more decoupled<br/>approach, we would have more success.<br/>
 This leaves us contemplating our original question again—what structure would<br/>
offer the best way to represent our data inside the program? Let’s take another look<br/>at the data. What we have is a list of records, each of which has a well-defined set of<br/>attributes. We could use either a hash or an array to model our list of records and we<br/>have the same choices to model each individual record. In this case we will use an<br/>
<hr/>
<a name=43></a><i><b>Design data structures carefully</b></i><br/>
<b>23</b><br/>
array of hashes2 to model our data. A good argument could be made for just about<br/>any other combination of arrays and hashes, but the representation that I have cho-<br/>sen seems more natural to me. Our input routine will therefore look like this:<br/>
my @CDs;<br/>
sub input {<br/>
my @attrs = qw(artist title label year);<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my %rec;<br/>
@rec{@attrs} = split /\t/;<br/>
push @CDs, \%rec;<br/>
}<br/>
}<br/>
This third and final data structure is shown in figure 2.5.<br/>
0<br/>
hashref<br/>
artist<br/>
David Bowie<br/>
1<br/>
hashref<br/>
title<br/>
Hunky Dory<br/>
2<br/>
hashref<br/>
label<br/>
RCA<br/>
3<br/>
hashref<br/>
year<br/>
1971<br/>
4<br/>
hashref<br/>
<b>Figure 2.5</b><br/>
5<br/>
hashref<br/>
<b>Final data structure</b><br/>
<i><b>More examples: using our flexible data structure<br/></b></i>Based on this data structure, we can then write any number of data munging rou-<br/>tines to produce specific output reports. For example, to produce our original list of<br/>the CDs released in a year we would write a routine like this:<br/>
sub count_cds_by_year {<br/>
my %years;<br/>
foreach (@CDs) {<br/>
$years{$_-&gt;{year}}++;<br/>
}<br/>
return \%years;<br/>
}<br/>
This routine returns a reference to a hash which is identical in structure to our orig-<br/>inal hash and can therefore be printed out using code identical to the output section<br/>of our original script.<br/>
2 Or, more accurately, an array of references to hashes.<br/>
<hr/>
<a name=44></a><b>24</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
 To produce a list of the number of CDs released by each artist we can write a<br/>
similar routine like this:<br/>
sub count_cds_by_artist {<br/>
my %artists;<br/>
foreach (@CDs) {<br/>
$artists{$_-&gt;{artist}}++;<br/>
}<br/>
return \%artists;<br/>
}<br/>
In fact these two routines are so similar, that it is possible to write a generic version<br/>which handles both of these cases (along with the cases where you want to count<br/>CDs by label or even by title).<br/>
sub count_cds_by_attr {<br/>
my $attr = shift;<br/>
my %counts;<br/>
foreach (@CDs) {<br/>
$counts{$_-&gt;{$attr}}++;<br/>
}<br/>
return \%counts;<br/>
}<br/>
A complete program to produce counts of CDs by any attribute which is passed in<br/>on the command line would look like this:<br/>
#!/usr/bin/perl -w<br/>
use strict;<br/>
my @CDs;<br/>
sub input {<br/>
my @attrs = qw(artist title label year);<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my %rec;<br/>
@rec{@attrs} = split /\t/;<br/>
push @CDs, \%rec;<br/>
}<br/>
}<br/>
sub count_cds_by_attr {<br/>
my $attr = shift;<br/>
my %counts;<br/>
foreach (@CDs) {<br/>
$counts{$_-&gt;{$attr}}++;<br/>
<hr/>
<a name=45></a><i><b>Encapsulate business rules</b></i><br/>
<b>25</b><br/>
}<br/>
return \%counts;<br/>
}<br/>
sub output {<br/>
my $counts = shift;<br/>
foreach (sort keys %{$counts}) {<br/>
print &#34;$_: $counts-&gt;{$_}\n&#34;;<br/>
}<br/>
}<br/>
my $attr = shift;<br/>
input();<br/>
my $counts = count_cds_by_attr($attr);<br/>
output($counts);<br/>
And, assuming that the program file is called count_cds.pl and you have the CD list<br/>in a file called cd.txt, it would be called like this:<br/>
count_cds.pl year &lt; cds.txt &gt; cds_by_year.txt<br/>
count_cds.pl label &lt; cds.txt &gt; cds_by_label.txt<br/>
count_cds.pl artist &lt; cds.txt &gt; cds_by_artist.txt<br/>
count_cds.pl title &lt; cds.txt &gt; cds_by_title.txt<br/>
In most cases you will have to make similar decisions when designing data structures.<br/>A data structure that is designed for one job will, in general, be simpler than one that<br/>is designed to be more flexible. It is up to you to decide whether it is worth taking<br/>the extra effort to make the design more flexible. (A hint—it usually is!)<br/>
<i><b>2.3</b></i><br/>
<i><b>Encapsulate business rules</b></i><br/>
Much of the logic in your data munging programs will be modeling what might be<br/>described as “business rules.” These are the rules about what particular data items<br/>mean, what their valid sets of values are, and how they relate to other values in the<br/>same or other records.3 Examples of these three types of business rules are:<br/>
■<br/>
Customer number is a unique identifier for a customer.<br/>
■<br/>
Customer number is always in the format CUS-XXXXX, where XXXXX is a<br/>unique integer.<br/>
■<br/>
Each customer record must be linked to a valid salesperson record.<br/>
3 I’ve described these constraints as “business rules,” as I think that’s easier to remember than something<br/>
like “domain specific constraints.” Of course, what you’re encoding might well have nothing to do<br/>with “business.”<br/>
<hr/>
<a name=46></a><b>26</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
 In any system where these data items are used, the business rules must always<br/>
hold true. No matter what your program does to a customer record, the customer<br/>number must remain unique and in the given format, and the customer must be<br/>linked to a valid salesperson record. Nothing that you do to a customer record is<br/>allowed to leave the data in a state that breaks any of these rules.<br/>
<i><b>2.3.1</b></i><br/>
<i><b>Reasons to encapsulate business rules</b></i><br/>
In a real-world system, there will probably be many other programs that are access-<br/>ing the same data items for their own purposes. Each of these other programs will<br/>have to abide by exactly the same set of business rules for each customer record that<br/>it accesses. Therefore each of these programs will have logic within it that encodes<br/>these rules. This can lead to a couple of problems:<br/>
■<br/>
It is possible that not every programmer who writes these programs has<br/>exactly the same understanding of the rules. Therefore, each program may<br/>have subtly different interpretations of the rules.<br/>
■<br/>
At some point in the future these rules may be changed. When this happens,<br/>the same changes in logic will need to be made to each of the programs that<br/>use the existing business rules. This may be a large job, and the more times<br/>the changes have to be made, the higher the chance that errors will creep in.<br/>
<i><b>2.3.2</b></i><br/>
<i><b>Ways to encapsulate business rules</b></i><br/>
The most common solution to both of these problems is to write code that models<br/>the business rules in one place and to reuse that code in each program that needs to<br/>use the rules. Most programming languages have a facility that allows code to be<br/>reused across many programs, and Perl has a particularly powerful implementation<br/>of this functionality.<br/>
 In Perl you would create a module that contains the business rules for a particu-<br/>
lar type of business record (say, a customer) and include this module in any other<br/>Perl programs that needed to understand the business rules that control the use of<br/>customer records. In fact, Perl gives you a couple of ways to implement this func-<br/>tionality. If your rules are relatively simple you can write a module that contains<br/>functions called things like get_next_custno or save_cust_record which get<br/>called at relevant points in your programs. For a more robust solution, you should<br/>consider writing a Perl object to implement your customer record. Let’s look at<br/>examples of both of these approaches.<br/>
<hr/>
<a name=47></a><i><b>Encapsulate business rules</b></i><br/>
<b>27</b><br/>
<i><b>2.3.3</b></i><br/>
<i><b>Simple module</b></i><br/>
Assume that we want to model the three business rules mentioned at the start of<br/>this section. We will write a module called Customer_Rules.pm that will contain<br/>the two functions get_next_cust_no and save_cust_record which we sug-<br/>gested above. The following example omits some of the lower level functions.<br/>
package Customer_Rules;<br/>
use strict;<br/>
use Carp;<br/>
use vars qw(@EXPORT @ISA);<br/>
@EXPORT = qw(get_next_cust_no save_cust_record);<br/>
@ISA = qw(Exporter);<br/>
require Exporter;<br/>
sub get_next_cust_no {<br/>
my $prev_cust = get_max_cust_no()<br/>
|| croak &#34;Can't allocate new customer reference.\n&#34;;<br/>
my ($prev_no) = $prev_cust =~ /(\d+)/;<br/>
$prev_no++;<br/>
return &#34;CUS-$prev_no&#34;;<br/>
}<br/>
sub save_cust_record {<br/>
my $cust = shift;<br/>
$cust-&gt;{cust_no} ||= get_next_cust_no();<br/>
is_valid_sales_ref($cust-&gt;{salesperson})<br/>
|| croak &#34;Invalid salesperson ref: $cust-&gt;{salesperson}.&#34;;<br/>
write_sales_record($cust);<br/>
}<br/>
<i><b>How Customer_Rules.pm works<br/></b></i>In this example we have encapsulated our business rules in functions which, in turn,<br/>make use of other lower level functions. These lower level functions haven’t been<br/>shown, as they would contain implementation-specific details which would only<br/>cloud the picture.<br/>
 In the get_next_cust_no function we begin by getting the customer number of<br/>
the most recently created customer record. This might be stored in a database table<br/>or in a text file or in some other format. In all of these cases there will need to be<br/>some kind of transaction-level locking to ensure that no other process gets the same<br/>value for the previous customer number. This would potentially lead to nonunique<br/>customer numbers in the system, which would break one of our business rules.<br/>
<hr/>
<a name=48></a><b>28</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
 Having retrieved the previous customer number we simply extract the integer<br/>
portion, increment it, and return it with the string CUS- prepended to it.<br/>
 In the save_cust_record function, we assume that the customer record is<br/>
stored internally in some complex data structure and that we are passed a reference<br/>to that structure. The first thing that we do is to ensure that we have a customer<br/>number in the record. We then check that the $cust-&gt;{salesperson} value rep-<br/>resents a valid salesperson in our system. Again, the list of valid salespeople could be<br/>stored in a number of different forms. It may be possible that more data is required<br/>in order to validate the salesperson code. For example, a salesperson may only deal<br/>with customers in a certain region. In this case the region in which the customer is<br/>based will also need to be passed into the is_valid_sales_ref function.<br/>
 Eventually, we get a true or false value back from is_valid_sales_ref and can<br/>
proceed appropriately. If the salesperson is valid, we can write the customer record to<br/>whatever storage medium we are using; otherwise, we alert the user to the error. In a<br/>real-world system many other similar checks would probably need to be carried out.<br/>
<i><b>Using Customer_Rules.pm<br/></b></i>Having produced this module, we can make it available to all programmers who are<br/>writing applications by putting it into a project-wide library directory. To make use<br/>of these functions, a programmer only needs to include the line:<br/>
use Customer_Rules;<br/>
in a program. The program will now have access to the get_next_cust_no and<br/>save_cust_record functions. Therefore, we can ensure that every program has<br/>the same interpretation of the business rules and, perhaps more importantly, if the<br/>business rules change, we only need to change this module in order to change them<br/>in each program.<br/>
<i><b>2.3.4</b></i><br/>
<i><b>Object class</b></i><br/>
While the module of the previous section is useful, it still has a number of problems;<br/>not the least of which is the fact that the structure of the customer record is defined<br/>elsewhere in the application. If the module is reused in a number of applications,<br/>then each application will define its own customer record and it is possible that the<br/>definitions will become out of step with each other. The solution to this problem is<br/>to create an object class.<br/>
 An object defines both the structure of a data record and all of the methods used<br/>
to operate on the record. It makes the code far easier to reuse and maintain. A full<br/>discussion of the advantages of object-oriented programming (OOP) is beyond the<br/>scope of this book, but two very good places to get the full story are the <i>perltoot<br/></i>manual page and Damian Conway’s <i>Object Oriented Perl</i> (Manning).<br/>
<hr/>
<a name=49></a><i><b>Encapsulate business rules</b></i><br/>
<b>29</b><br/>
 Let’s examine a cut-down customer object which is implemented in a module<br/>
called Customer.pm.<br/>
package Customer;<br/>
use strict;<br/>
sub new {<br/>
my $thing = shift;<br/>
my $self = {};<br/>
bless $self, ref($thing) || $thing;<br/>
$self-&gt;init(@_);<br/>
return $self;<br/>
}<br/>
sub init {<br/>
my $self = shift;<br/>
# Extract various interesting things from<br/>
# @_ and use them to create a data structure<br/>
# that represents a customer.<br/>
}<br/>
sub validate {<br/>
my $self = shift;<br/>
# Call a number of methods, each of which validates<br/>
# one data item in the customer record.<br/>
return $self-&gt;is_valid_sales_ref<br/>
&amp;&amp; $self-&gt;is_valid_other_attr<br/>
&amp;&amp; $self-&gt;is_valid_another_attr;<br/>
}<br/>
sub save {<br/>
my $self = shift;<br/>
if ($self-&gt;validate) {<br/>
$self-&gt;{cust_no} ||= $self-&gt;get_next_cust_no;<br/>
return $self-&gt;write;<br/>
} else {<br/>
return;<br/>
}<br/>
}<br/>
# Various other object methods are omitted here, for example<br/>
# code to retrieve a customer object from the database or<br/>
# write a customer object to the database.<br/>
1; # Because all modules should return a true value.<br/>
The advantage that this method has over the previous example is that in addition to<br/>modeling the business rules that apply to a customer record, it defines a standard<br/>
<hr/>
<a name=50></a><b>30</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
data structure to store customer data and a well defined set of actions that can be<br/>performed on a customer record. The slight downside is that incorporating this<br/>module into a program will take a little more work than simply using the functions<br/>defined in our previous module.<br/>
<i><b>Example: using Customer.pm<br/></b></i>As an example of using this module, let’s look at a simple script for creating a cus-<br/>tomer record. We’ll prompt the user for the information that we require.<br/>
use Customer;<br/>
my $cust = Customer-&gt;new;<br/>
print 'Enter new customer name: ';<br/>
my $name = &lt;STDIN&gt;;<br/>
$cust-&gt;name($name);<br/>
print 'Enter customer address: ';<br/>
my $addr = &lt;STDIN&gt;;<br/>
$cust-&gt;address($addr);<br/>
print 'Enter salesperson code: ';<br/>
my $sp_code = &lt;STDIN&gt;;<br/>
$cust-&gt;salesperson($sp_code);<br/>
# Write code similar to that above to get any other<br/>
# required data from the user.<br/>
if ($cust-&gt;save) {<br/>
print &#34;New customer saved successfully.\n&#34;;<br/>
print &#34;New customer code is &#34;, $cust-&gt;code, &#34;\n&#34;;<br/>
} else {<br/>
print &#34;Error saving new customer.\n&#34;;<br/>
}<br/>
In this case we create an empty customer object by calling the Customer-&gt;new<br/>method without any parameters. We then fill in the various data items in our cus-<br/>tomer object with data input by the user. Notice that we assume that each customer<br/>attribute has an access method which can be used to set or get the attribute value.4<br/>
4 This is a common practice. For example, the name method counts the number of parameters that have<br/>
been sent. If it has received a new value then it sets the customer’s name to that value; if not, it just returns<br/>the previous value.<br/>
An alternative practice is to have two separate methods called get_name and set_name. Which approach<br/>
you use is a matter of personal preference. In either case, it is generally accepted that using access methods<br/>is better than accessing the attributes directly.<br/>
<hr/>
<a name=51></a><i><b>Use UNIX “filter” model</b></i><br/>
<b>31</b><br/>
 Having filled in all of the required data, we called $cust-&gt;save to save our<br/>
new record. If the save is successful, the code attribute will have been filled in and<br/>we can display the new customer’s code to the user by way of the $cust-&gt;code<br/>attribute access method.<br/>
 If, on the other hand, we wanted to access an existing customer record, we would<br/>
pass the customer to the Customer-&gt;new method (e.g., Customer-&gt;new(id =&gt;<br/>'CUS-00123')) and the init method would populate our object with the cus-<br/>tomer’s data. We could then either use this data in some way or alternatively alter it<br/>and use the save method to write the changed record back to the database.<br/>
<i><b>2.4</b></i><br/>
<i><b>Use UNIX “filter” model</b></i><br/>
UNIX filter programs give us a very good example to follow when it comes to building<br/>a number of small, reusable utilities each of which is designed to carry out one task.<br/>
<i><b>2.4.1</b></i><br/>
<i><b>Overview of the filter model</b></i><br/>
Many operating systems, principally UNIX and its variants, support a feature called<br/>I/O redirection. This feature is also supported in Microsoft Windows, although as<br/>it is a command line feature, it is not used as much as it is in UNIX. I/O redirection<br/>gives the user great flexibility over where a program gets its input and sends its<br/>output. This is achieved by treating all program input and output as file input and<br/>output. The operating system opens two special file handles called STDIN and<br/>STDOUT, which, by default, are attached to the user’s keyboard and monitor.5 This<br/>means that anything typed by the user on the keyboard appears to the program to<br/>be read from STDIN and anything that the program writes to STDOUT appears on<br/>the user’s monitor.<br/>
 For example, if a user runs the UNIX command<br/>
ls<br/>
then a list of files in the current directory will be written to STDOUT and will appear<br/>on the user’s monitor.<br/>
 There are, however a number of special character strings that can be used to<br/>
redirect these special files. For example, if our user runs the command<br/>
ls &gt; files.txt<br/>
then anything that would have been written to STDOUT is, instead, written to the file<br/>files.txt. Similarly, STDIN can be redirected using the &lt; character. For example,<br/>
5 In practice there is also a third file handle called STDERR which is a special output file to which error mes-<br/>
sages are written, but this file can be safely ignored for the purposes of this discussion.<br/>
<hr/>
<a name=52></a><b>32</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
sort &lt; files.txt<br/>
would sort our previously created file in lexical order (since we haven’t redirected<br/>the output, it will go to the user’s monitor).<br/>
 Another, more powerful, concept is I/O pipes. This is where the output of one<br/>
process is connected directly to the input of another. This is achieved using the |<br/>character. For example, if our user runs the command<br/>
ls | sort<br/>
then anything written to the STDOUT of the ls command (i.e., the list of files in the<br/>current directory) is written directly to the STDIN of the sort command. The sort<br/>command processes the data that appears on its STDIN, sorts that data, and writes<br/>the sorted data to its STDOUT. The STDOUT for the sort command has not been<br/>redirected and therefore the sorted list of files appears on the user’s monitor. <br/>
 A summary of the character strings used in basic I/O redirection is given in<br/>
table 2.1. More complex features are available in some operating systems, but the<br/>characters listed are available in all versions of UNIX and Windows.<br/>
Table 2.1<br/>
Common I/O redirection<br/>
String<br/>
Usage<br/>
Description<br/>
&gt;<br/>
cmd &gt; file<br/>
Runs cmd and writes the output to file, overwriting whatever <br/>was in file.<br/>
&gt;&gt;<br/>
cmd &gt;&gt; file<br/>
Runs cmd and appends the output to the end of file.<br/>
&lt;<br/>
cmd &lt; file<br/>
Runs cmd, taking input from file.<br/>
|<br/>
cmd1 | cmd2<br/>
Runs cmd1 and passes any output as input to cmd2<br/>
<i><b>2.4.2</b></i><br/>
<i><b>Advantages of the filter model</b></i><br/>
The filter model is a very useful concept and is fundamental to the way that UNIX<br/>works. It means that UNIX can supply a large number of small, simple utilities, each<br/>of which do one task and do it well. Many complex tasks can be carried out by<br/>plugging a number of these utilities together. For example, if we needed to list all<br/>of the files in a directory with a name containing the string “proj01” and wanted<br/>them sorted in alphabetical order, we could use a combination of ls, sort, and<br/>
6<br/>
grep  like this:<br/>
ls –1 | grep proj01 | sort<br/>
6 Which takes a text string as an argument and writes to STDOUT only input lines that contain that text.<br/>
<hr/>
<a name=53></a><i><b>Use UNIX “filter” model</b></i><br/>
<b>33</b><br/>
Most UNIX utilities are written to support this mode of usage. They are known as<br/><i>filters</i> as they read their input from STDIN, filter the data in a particular way, and<br/>write what is left to STDOUT.<br/>
 This is a concept that we can make good use of in our data munging programs.<br/>
If we write our programs so that they make no assumptions about the files that they<br/>are reading and writing (or, indeed, whether they are even reading from and writing<br/>to files) then we will have written a useful generic tool, which can be used in a num-<br/>ber of different circumstances. <br/>
<i><b>Example: I/O independence<br/></b></i>Suppose, for example, that we had written a program called data_munger which<br/>munged data from one system into data suitable for use in another. Originally, we<br/>might take data from a file and write our output to another. It might be tempting<br/>to write a program that is called with two arguments which are the names of the<br/>input and output files. The program would then be called like this:<br/>
data_munger input.dat output.dat<br/>
Within the script we would open the files and read from the input, munge the data,<br/>and then write to the output file. In Perl, the program might look something like:<br/>
#!/usr/bin/perl –w<br/>
use strict;<br/>
my ($input, $output) = @ARGV;<br/>
open(IN, $input) || die &#34;Can’t open $input for reading: $!&#34;;<br/>
open(OUT, &#34;&gt;$output&#34;) || die &#34;Can’t open $output for writing: $!&#34;;<br/>
while (&lt;IN&gt;) {<br/>
print OUT munge_data($_);<br/>
}<br/>
close(IN) || die &#34;Can't close $input: $!&#34;;<br/>
close(OUT) || die &#34;Can't close $output: $!&#34;;<br/>
This will certainly work well for as long as we receive our input data in a file and are<br/>expected to write our output data to another file. Perhaps at some point in the<br/>future, the programmers responsible for our data source will announce that they<br/>have written a new program called data_writer, which we should now use to<br/>extract data from their system. This program will write the extracted data to its<br/>STDOUT. At the same time the programmers responsible for our data sink announce<br/>a new program called data_reader, which we should use to load data into their<br/>system and which reads the data to be loaded from STDIN.<br/>
<hr/>
<a name=54></a><b>34</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
 In order to use our program unchanged we will need to write some extra pieces<br/>
of code in the script which drives our program. Our program will need to be called<br/>with code like this:<br/>
data_writer &gt; input.dat<br/>
data_munger input.dat output.dat<br/>
data_reader &lt; output.dat<br/>
This is already looking a little kludgy, but imagine if we had to make these changes<br/>across a large number of systems. Perhaps there is a better way to write the origi-<br/>nal program.<br/>
 If we had assumed that the program reads from STDIN and writes to STDOUT, the<br/>
program actually gets simpler and more flexible. The rewritten program looks like this:<br/>
#!/usr/bin/perl –w<br/>
while (&lt;STDIN&gt;) {<br/>
print munge_data($_);<br/>
}<br/>
Note that we no longer have to open the input and output files explicitly, as Perl<br/>arranges for STDIN and STDOUT to be opened for us. Also, the default file handle to<br/>which the print function writes is STDOUT; therefore, we no longer need to pass a<br/>file handle to print. This script is therefore much simpler than our original one.<br/>
 When we’re dealing with input and output data files, our program is called<br/>
like this:<br/>
data_munger &lt; input.dat &gt; output.dat<br/>
and once the other systems want us to use their data_writer and data_reader<br/>programs, we can call our program like this:<br/>
data_writer | data_munger | data_reader<br/>
and everything will work exactly the same without any changes to our program. As<br/>a bonus, if we have to cope with the introduction of data_writer before<br/>data_reader or vice versa, we can easily call our program like this:<br/>
data_writer | data_munger &gt; output.dat<br/>
or this:<br/>
data_munger &lt; input.dat | data_reader<br/>
and everything will still work as expected.<br/>
 Rather than using the STDIN file handle, Perl allows you to make your program<br/>
even more flexible with no more work, by reading input from the null file handle<br/>like this:<br/>
<hr/>
<a name=55></a><i><b>Use UNIX “filter” model</b></i><br/>
<b>35</b><br/>
#!/usr/bin/perl –w<br/>
while (&lt;&gt;) {<br/>
print munged_data($_);<br/>
}<br/>
In this case, Perl will give your program each line of every file that is listed on your<br/>command line. If there are no files on the command line, it reads from STDIN. This<br/>is exactly how most UNIX filter programs work. If we rewrote our data_munger<br/>program using this method we could call it in the following ways:<br/>
data_munger input.dat &gt; output.dat<br/>
data_munger input.dat | data reader<br/>
in addition to the methods listed previously.<br/>
<i><b>Example: I/O chaining<br/></b></i>Another advantage of the filter model is that it makes it easier to add new functional-<br/>ity into your processing chain without having to change existing code. Suppose that<br/>a system is sending you product data. You are loading this data into the database that<br/>drives your company’s web site. You receive the data in a file called products.dat<br/>and have written a script called load_products. This script reads the data from<br/>STDIN, performs various data munging processes, and finally loads the data into the<br/>database. The command that you run to load the file looks like this:<br/>
load_products &lt; products.dat<br/>
What happens when the department that produces products.dat announces that<br/>because of a reorganization of their database they will be changing the format of<br/>your input file? For example, perhaps they will no longer identify each product with<br/>a unique integer, but with an alphanumeric code. Your first option would be to<br/>rewrite load_products to handle the new data format, but do you really want to<br/>destabilize a script that has worked very well for a long time? Using the UNIX filter<br/>model, you don’t have to. You can write a new script called translate_products<br/>which reads the new file format, translates the new product code to the product<br/>identifiers that you are expecting, and writes the records in the original format to<br/>STDOUT. Your existing load_products script can then read records in the format<br/>that it accepts from STDIN and can process them in exactly the same way that it<br/>always has. The command line would look like this:<br/>
translate_products &lt; products.dat | load_products<br/>
This method of working is known as <i>chain extension</i> and can be very useful in a<br/>number of areas.<br/>
<hr/>
<a name=56></a><b>36</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
 In general, the UNIX filter model is very powerful and often actually simplifies<br/>
the program that you are writing, as well as making your programs more flexible.<br/>You should therefore consider using it as often as possible.<br/>
<i><b>2.5</b></i><br/>
<i><b>Write audit trails</b></i><br/>
When transforming data it is often useful to keep a detailed audit trail of what you<br/>have done. This is particularly true when the end users of the transformed data<br/>question the results of your transformation. It is very helpful to be able to trace<br/>through the audit log and work out exactly where each data item has come from.<br/>Generally, problems in the output data can have only one of two sources, either<br/>errors in the input data or errors in the transformation program. It will make your<br/>life much easier if you can quickly work out where the problem has arisen.<br/>
<i><b>2.5.1</b></i><br/>
<i><b>What to write to an audit trail</b></i><br/>
At different points in the life of a program, different levels of auditing will be appro-<br/>priate. While the program is being developed and tested it is common practice to<br/>have a much more detailed audit trail than when it is being used day to day in a pro-<br/>duction environment. For this reason, it is often useful to write auditing code that<br/>allows you to generate different levels of output depending on the value of a vari-<br/>able that defines the audit level. This variable might be read from an environment<br/>variable like this:<br/>
my $audit_level = $ENV{AUDIT_LEVEL} || 0;<br/>
In this example we set the value of $audit_level from the environment variable<br/>AUDIT_LEVEL. If this level is not set then we default to 0, the minimum level. Later<br/>in the script we can write code like:<br/>
print LOG 'Starting processing at ', scalar localtime, &#34;\n&#34;<br/>
if $audit_level &gt; 0;<br/>
to print audit information to the previously opened file handle, LOG.<br/>
 Standards for audit trails will typically vary from company to company, but some<br/>
things that you might consider auditing are:<br/>
■<br/>
start and end times of the process<br/>
■<br/>
source and sink parameters (filenames, database connection parameters, etc.)<br/>
■<br/>
ID of every record processed<br/>
■<br/>
results of each data translation<br/>
■<br/>
final count of records processed<br/>
<hr/>
<a name=57></a><i><b>Write audit trails</b></i><br/>
<b>37</b><br/>
<i><b>2.5.2</b></i><br/>
<i><b>Sample audit trail</b></i><br/>
A useful audit trail for a data munging process that takes data from a file and either<br/>creates or updates database records might look like this:<br/>
<b>Process: daily_upd started at 00:30:00 25 Mar 2000</b><br/>
<b>Data source: /data/input/daily.dat</b><br/>
<b>Data sink: database customer on server DATA_SERVER (using id 'maint')</b><br/>
<b>Input record: D:CUS-00123</b><br/>
<b>Action: Delete</b><br/>
<b>Translation: CUS-00123 = database id 2364</b><br/>
<b>Record 2364 deleted successfully</b><br/>
<b>Input record: U:CUS-00124:Jones &amp; Co| [etc …]</b><br/>
<b>Action: Update</b><br/>
<b>Translation: CUS-00124 = database id 2365</b><br/>
<b>Record 2365 updated successfully</b><br/>
<b>Input record: I:CUS-01000:Magnum Solutions Ltd| [etc …]</b><br/>
<b>Action: Insert</b><br/>
<b>Integrity Check: CUS-01000 does not exist on database</b><br/>
<b>Record 3159 inserted successfully</b><br/>
<b>[many lines omitted]</b><br/>
<b>End of file on data source</b><br/>
<b>1037 records processed (60 ins, 964 upd, 13 del)</b><br/>
<b>Process: daily_upd complete at 00:43:14 25 Mar 2000</b><br/>
<i><b>2.5.3</b></i><br/>
<i><b>Using the UNIX system logs</b></i><br/>
Sometimes you will want to log your audit trail to the UNIX system log. This is a<br/>centralized process in which the administrator of a UNIX system can control where<br/>the log information for various processes is written. To access the system log from<br/>Perl, use the Sys::Syslog module. This module contains four functions called<br/>openlog, closelog, setlogmask, and syslog which closely mirror the function-<br/>ality of the UNIX functions with the same names. For more details on these func-<br/>tions, see the Sys::Syslog module’s documentation and your UNIX manual. Here<br/>is an example of their use:<br/>
use Sys::Syslog;<br/>
openlog('data_munger.pl', 'cons', 'user');<br/>
# then later in the program<br/>
syslog('info', 'Process started');<br/>
# then later again<br/>
closelog();<br/>
Notice that as the system logger automatically timestamps all messages, we don’t<br/>need to print the start time in our log message.<br/>
<hr/>
<a name=58></a><b>38</b><br/>
CHAPTER <br/>
<i><b>General munging practices</b></i><br/>
<i><b>2.6</b></i><br/>
<i><b>Further information</b></i><br/>
For more information on writing objects in Perl see <i>Object Oriented Perl</i> by Damian<br/>Conway (Manning).<br/>
 For more information about the UNIX filter model and other UNIX program-<br/>
ming tricks see <i>The UNIX Programming Environment</i> by Brian Kernigan and Rob<br/>Pike (Prentice Hall) or <i>UNIX Power Tools</i> by Jerry Peek, Tim O’Reilly, and Mike<br/>Loukides (O’Reilly).<br/>
 For more general programming advice see <i>The Practice of Programming</i> by<br/>
Brian Kernigan and Rob Pike (Addison-Wesley) and <i>Programming Pearls</i> by Jon<br/>Bentley (Addison-Wesley).<br/>
<i><b>2.7</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
Decoupling the various stages of your program can cut down on the code<br/>that you have to write by making code more reusable.<br/>
■<br/>
Designing data structures carefully will make your programs more flexible.<br/>
■<br/>
Write modules or objects to encapsulate your business rules.<br/>
■<br/>
The UNIX filter model can make your programs I/O independent.<br/>
■<br/>
Always write audit logs.<br/>
<hr/>
<a name=59></a><img class="yflip" src="dmp-59_1.jpg"/><br/>
<i>3</i><br/>
<i>Useful Perl idioms</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Simple and complex sorts<br/>
■<br/>
The Orcish manoeuvre and the Schwartzian <br/>and Guttman-Rosler transforms <br/>
■<br/>
Database Interface and database <br/>driver modules<br/>
■<br/>
Benchmarking<br/>
■<br/>
Command line scripts <br/>
<i>39</i><br/>
<hr/>
<a name=60></a><b>40</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
There are a number of Perl idioms that will be useful in many data munging pro-<br/>grams. Rather than introduce them in the text when they are first met, we will dis-<br/>cuss them all here. <br/>
<i><b>3.1</b></i><br/>
<i><b>Sorting</b></i><br/>
Sorting is one of the most common tasks that you will carry out when data mung-<br/>ing. As you would expect, Perl makes sorting very easy for you, but there are a few<br/>niceties that we’ll come to later in this section. <br/>
<i><b>3.1.1</b></i><br/>
<i><b>Simple sorts</b></i><br/>
Perl has a built-in sort function which will handle simple sorts very easily. The syn-<br/>tax for the sort function is as follows:<br/>
@out = sort @in;<br/>
This takes the elements of the list @in, sorts them lexically, and returns them in<br/>array @out. This is the simplest scenario. Normally you will want something more<br/>complex, so sort takes another argument which allows you to define the sort that<br/>you want to perform. This argument is either the name of a subroutine or a block of<br/>Perl code (enclosed in braces). For example, to sort data numerically1 you would<br/>write code like this:<br/>
@out = sort numerically @in;<br/>
and a subroutine called numerically which would look like this:<br/>
sub numerically {<br/>
return $a &lt;=&gt; $b;<br/>
}<br/>
There are a couple of things to notice in this subroutine. First, there are two special<br/>variables, $a and $b, which are used in the subroutine. Each time Perl calls the sub-<br/>routine, these variables are set to two of the values in the source array. Your subrou-<br/>tine should compare these two values and return a value that indicates which of the<br/>elements should come first in the sorted list. You should return –1 if $a comes<br/>before $b, 1 if $b comes before $a, and 0 if they are the same. The other thing to<br/>notice is the &lt;=&gt; operator which takes two values and returns –1, 0, or 1, depend-<br/>ing on which value is numerically larger. This function, therefore, compares the two<br/>values and returns the values required by sort. If you wanted to sort the list in<br/>
1  Rather than lexically, where 100 comes before 2.<br/>
<hr/>
<a name=61></a><i><b>Sorting</b></i><br/>
<b>41</b><br/>
descending numerical order, you would simply have to reverse the order of the<br/>comparison of $a and $b like so:<br/>
sub desc_numerically {<br/>
return $b &lt;=&gt; $a;<br/>
}<br/>
Another way of handling this is to sort the data in ascending order and reverse the<br/>list using Perl’s built-in reverse function like this:<br/>
@out = reverse sort numerically @in;<br/>
There is also another operator, cmp, which returns the same values but orders the<br/>elements lexically. The original default sort is therefore equivalent to:<br/>
@out = sort lexically @in;<br/>
sub lexically {<br/>
return $a cmp $b;<br/>
}<br/>
<i><b>3.1.2</b></i><br/>
<i><b>Complex sorts</b></i><br/>
Sorts as simple as the ones we’ve discussed so far are generally not written using the<br/>subroutine syntax that we have used above. In these cases, the block syntax is used.<br/>In the block syntax, Perl code is placed between the sort function and the input<br/>list. This code must still work on $a and $b and must obey the same rules about<br/>what it returns. The sorts that we have discussed above can therefore be rewritten<br/>like this:<br/>
@out = sort { $a &lt;=&gt; $b } @in;<br/>
@out = sort { $b &lt;=&gt; $a } @in; # or @out = reverse sort { $a &lt;=&gt; $b } @in<br/>
@out = sort { $a cmp $b } @in;<br/>
The subroutine syntax can, however, be used to produce quite complex sort crite-<br/>ria. Imagine that you have an array of hashes where each hash has two keys, fore-<br/>name and surname, and you want to sort the list like a telephone book (i.e.,<br/>surname first and then forename). You could write code like this:<br/>
my @out = sort namesort @in;<br/>
sub namesort {<br/>
return $a-&gt;{surname} cmp $b-&gt;{surname}<br/>
|| $a-&gt;{forename} cmp $b-&gt;{forename};<br/>
}<br/>
Note that we make good use of the “short circuit” functionality of the Perl || oper-<br/>ator. Only if the surnames are the same and the first comparison returns 0 is the sec-<br/>ond comparison evaluated.<br/>
<hr/>
<a name=62></a><b>42</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
We can, of course, mix numeric comparisons with lexical comparisons and even<br/>
reverse the order on some comparisons. If our hash also contains a key for age, the<br/>following code will resolve two identical names by putting the older person first.<br/>
my @out = sort namesort @in;<br/>
sub namesort {<br/>
return $a-&gt;{surname} cmp $b-&gt;{surname}<br/>
|| $a-&gt;{forename} cmp $b-&gt;{forename}<br/>
|| $b-&gt;{age} &lt;=&gt; $a-&gt;{age};<br/>
}<br/>
This default sort mechanism is implemented using a Quicksort algorithm. In this<br/>type of sort, each element of the list is compared with at least one other element in<br/>order to determine the correct sequence. This is an efficient method if each com-<br/>parison is relatively cheap; however, there are circumstances where you are sorting<br/>on a value which is calculated from the element. In these situations, recalculating<br/>the value each time can have a detrimental effect on performance. There are a<br/>number of methods available to minimize this effect and we will now discuss some<br/>of the best ones.<br/>
<i><b>3.1.3</b></i><br/>
<i><b>The Orcish Manoeuvre</b></i><br/>
One simple way to minimize the effect of calculating the sort value multiple times is<br/>to cache the results of each calculation so that we only have to carry out each calcu-<br/>lation once. This is the basis of the <i>Orcish Manoeuvre</i> (a pun on “or cache”) devised<br/>by Joseph Hall. In this method, the results of previous calculations are stored in a<br/>hash. The basic code would look like this:<br/>
my %key_cache;<br/>
my @out = sort orcish @in;<br/>
sub orcish {<br/>
return ($key_cache{$a} ||= get_sort_key($a))<br/>
&lt;=&gt; ($key_cache{$b} ||= get_sort_key($b));<br/>
}<br/>
sub get_sort_key {<br/>
# Code that takes the list element and returns<br/>
# the part that you want to sort on<br/>
}<br/>
There is a lot going on here so it’s worth looking at it in some detail.<br/>
The hash %key_cache is used to store the precalculated sort keys.<br/>The function orcish carries out the sort, but for each element, before calculat-<br/>
ing the sort key, it checks to see if the key has already been calculated, in which case<br/>
<hr/>
<a name=63></a><i><b>Sorting</b></i><br/>
<b>43</b><br/>
it will be stored in %key_cache. It makes use of Perl’s ||= operator to make the<br/>code more streamlined. The code <br/>
$key_cache{$a} ||= get_sort_key($a)<br/>
can be expanded to<br/>
$key_cache{$a} = $key_cache{$a} || get_sort_key($a)<br/>
The net effect of this code is that if $key_cache{$a} doesn’t already exist then<br/>get_sort_key is called to calculate it and the result is stored in $key_cache{$a}.<br/>The same procedure is carried out for $b and the two results are then compared<br/>using &lt;=&gt; (this could just as easily be cmp if you need a lexical comparison).<br/>
Depending on how expensive your get_sort_key function is, this method can<br/>
greatly increase your performance in sorting large lists.<br/>
<i><b>3.1.4</b></i><br/>
<i><b>Schwartzian transform</b></i><br/>
Another way of avoiding recalculating the sort keys a number of times is to use the<br/>Schwartzian transform. This was named after Randal L. Schwartz, a well-known mem-<br/>ber of the Perl community and author of a number of Perl books, who was the first per-<br/>son to post a message using this technique to the comp.lang.perl.misc newsgroup.<br/>
In the Schwartzian transform we precalculate all of the sort keys before we begin<br/>
the actual sort.<br/>
As an example, let’s go back to our list of CDs. If you remember, we finally<br/>
decided that we would read the data file into an array of hashes, where each hash<br/>contained the details of each CD. Figure 3.1 is a slightly simplified diagram of the<br/>@CDs array (each hash has only two fields). <br/>
0<br/>
hashref<br/>
year<br/>
1972<br/>
1<br/>
hashref<br/>
title<br/>
Ziggy Stardust<br/>
year<br/>
1971<br/>
title<br/>
Hunky Dory<br/>
<b>Figure 3.1<br/>The unsorted array of CD hashes</b><br/>
Suppose that now we want to produce a list of CDs arranged in order of release<br/>
date. The naïve way to write this using sort would be like this:<br/>
my @CDs_sorted_by_year = sort { $a-&gt;{year} &lt;=&gt; $b-&gt;{year} } @CDs;<br/>
We could then iterate across the sorted array and print out whatever fields of the<br/>hash were of interest to us.<br/>
<hr/>
<a name=64></a><b>44</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
As you can see, to get to the sort key (the release date) we have to go through a<br/>
hash reference to get to that hash itself. Hash lookup is a reasonably expensive oper-<br/>ation in Perl and we’d be better off if we could avoid having to look up each ele-<br/>ment a number of times.<br/>
Let’s introduce an intermediate array. Each element of the array will be a refer-<br/>
ence to a two-element array. The first element will be the year and the second ele-<br/>ment will be a reference to the original hash. We can create this list very easily<br/>using map.<br/>
my @CD_and_year = map { [$_-&gt;{year}, $_] } @CDs;<br/>
Figure 3.2 shows what this new array would look like.<br/>
0<br/>
arrayref<br/>
0<br/>
1972<br/>
1<br/>
arrayref<br/>
year<br/>
1972<br/>
1 hashref<br/>
title<br/>
Ziggy Stardust<br/>
0<br/>
1971<br/>
1 hashref<br/>
year<br/>
1971<br/>
title<br/>
Hunky Dory<br/>
<b>Figure 3.2</b><br/>
<b>@CD_and_year contains references to a two element array</b><br/>
The year field in each hash has been extracted only once, which will save us a lot of<br/>
time. We can now sort our new array on the first element of the array. Array lookup is<br/>much faster than hash lookup. The code to carry out this sort looks like this:<br/>
my @sorted_CD_and_year = sort { $a-&gt;[0] &lt;=&gt; $b-&gt;[0] } @CD_and_year;<br/>
Figure 3.3 shows this new array.<br/>
0<br/>
arrayref<br/>
0<br/>
1971<br/>
1<br/>
arrayref<br/>
year<br/>
1971<br/>
1 hashref<br/>
title<br/>
Hunky Dory<br/>
0<br/>
1972<br/>
1 hashref<br/>
year<br/>
1972<br/>
title<br/>
Ziggy Stardust<br/>
<b>Figure 3.3</b><br/>
<b>@sorted_CD_and_year is @CD_and_year sorted by the first </b><br/>
<b>element of the array</b><br/>
<hr/>
<a name=65></a><i><b>Sorting</b></i><br/>
<b>45</b><br/>
Now in @sorted_CD_and_year we have an array of references to arrays. The<br/>
important thing, however, is that the array is ordered by year. In fact, we only need<br/>the second element of each of these arrays, because that is a reference to our origi-<br/>nal hash. Using map it is simple to strip out the parts that we need.<br/>
my @CDs_sorted_by_year = map { $_-&gt;[1] } @sorted_CD_and_year;<br/>
Figure 3.4 shows what this array would look like.<br/>
0<br/>
hashref<br/>
year<br/>
1971<br/>
1<br/>
hashref<br/>
title<br/>
Hunky Dory<br/>
<b>Figure 3.4</b><br/>
year<br/>
1972<br/>
<b>@CDs_sorted_by_year contains </b><br/>
title<br/>
Ziggy Stardust<br/>
<b>just the hash references from <br/>@sorted_CD_and_year</b><br/>
Let’s put those three stages together.<br/>
my @CD_and_year = map { [$_, $_-&gt;{year}] } @CDs;<br/>
my @sorted_CD_and_year = sort { $a-&gt;[1] &lt;=&gt; $b-&gt;[1] } @CD_and_year;<br/>
my @CDs_sorted_by_year = map { $_-&gt;[0] } @sorted_CD_and_year;<br/>
That, in a nutshell, is the Schwartzian transform—a sort surrounded by two maps.<br/>There is one more piece of tidying up that we can do. As each of the maps and the<br/>sort take an array as input and return an array we can chain all of these transforma-<br/>tions together in one statement and lose both of the intermediate arrays.<br/>
my @CDs_sorted_by_year = map { $_-&gt;[0] }<br/>
sort { $a-&gt;[1] &lt;=&gt; $b-&gt;[1] }<br/>
map { [$_, $_-&gt;{year}] } @CDs;<br/>
If this doesn’t look quite like what we had before, try tracing it through in reverse.<br/>Our original array (@CDs) is passed in at the bottom. It goes through the map that<br/>dereferences the hash, then the sort, and finally the last map.<br/>
The chaining together of multiple list processing functions, where the output of<br/>
the first map becomes the input to the sort and so on, is very similar to the I/O<br/>pipes that we saw when looking at the UNIX filter model earlier.<br/>
The Schwartzian transform can be used anywhere that you want to sort a list of<br/>
data structures by one of the data values contained within it, but that’s not all it can<br/>do. Here’s a three-line script that prints out our CD file (read in through STDIN),<br/>sorted by the recording label.<br/>
print map { $_-&gt;[0] }<br/>
sort { $a-&gt;[1] cmp $b-&gt;[1] }<br/>
map { [$_, (split /\t/)[2]] } &lt;STDIN&gt;;<br/>
<hr/>
<a name=66></a><b>46</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
<i><b>3.1.5</b></i><br/>
<i><b>The Guttman-Rosler transform</b></i><br/>
At the 1999 Perl Conference, Uri Guttman and Larry Rosler presented a paper on<br/>sorting with Perl. It covered all of the techniques discussed so far and went a step<br/>further, by introducing the concept of the <i>packed-default</i> sort. They started from<br/>two premises:<br/>
1<br/>
Eliminating any hash or array dereferencing would speed up the sort.<br/>
2<br/>
The default lexical sort (without any sort subroutine or block) is the fastest.<br/>
The resulting method is an interesting variation on the Schwartzian transform.<br/>
Instead of transforming each element of the list into a two element list (the sort<br/>key and the original data) and sorting on the first element of this list, Guttman and<br/>Rosler suggest converting each element of the original list into a string with the<br/>sort key at the beginning and the original element at the end. A list containing<br/>these strings can then be sorted lexically and the original data is extracted from the<br/>sorted list.<br/>
The example that they use in their paper is that of sorting IP addresses. First they<br/>
convert each element to a string in which each part of the IP address is converted<br/>(using pack) to the character represented by that value in ASCII. This four-character<br/>string has the original data appended to the end:<br/>
my @strings = map { pack('C4', /(\d+)\.(\d+)\.(\d+)\.(\d+)/) . $_ } @IPs;<br/>
then the strings are lexically sorted using the default sort mechanism<br/>
my @sorted_strings = sort @strings<br/>
and finally the original data is extracted.<br/>
my @sorted @IPs = map { substr($_, 4) } @sorted_strings;<br/>
Rewriting this to make it look more like the Schwartzian transform, we get this:<br/>
my @sorted_IPs = map { substr($_, 4) }<br/>
sort<br/>
map { pack('C4', /(\d+)\.(\d+)\.(\d+)\.(\d+)/) . $_ } @IPs;<br/>
This type of sort needs a bit more thought than the other methods that we have<br/>considered in order to create a suitable string for sorting; however, it can pay great<br/>dividends in the amount of performance improvement that you can see.<br/>
<i><b>3.1.6</b></i><br/>
<i><b>Choosing a sort technique</b></i><br/>
If you are having performance problems with a program that contains a complex<br/>sort, then it is quite possible that using one of the techniques from this section will<br/>speed up the script. It is, however, possible that your script could get slower. Each of<br/>
<hr/>
<a name=67></a><i><b>Database Interface (DBI)</b></i><br/>
<b>47</b><br/>
the techniques will improve the actual sort time, but they all have an overhead which<br/>means that your sort will need to be quite large before you see any improvement. <br/>
When selecting a sort technique to use, it is important that you use the bench-<br/>
marking methods, discussed in section 3.4, to work out which technique is most<br/>appropriate. Of course, if your script is only going to run once, then spending half a<br/>day benchmarking sorts for the purpose of shaving five seconds off the runtime isn’t<br/>much of a gain. <br/>
This section has only really started to discuss the subject of sorting in Perl. If<br/>
you’d like to know more, Guttman and Rosler’s paper is a very good place to start.<br/>You can find it online at http://www.hpl.hp.com/personal/Larry_Rosler/sort/.<br/>
<i><b>3.2</b></i><br/>
<i><b>Database Interface (DBI)</b></i><br/>
As discussed in chapter 1, a common source or sink for data is a database. For<br/>many years Perl has had mechanisms that enable it to talk to various database sys-<br/>tems. For example, if you wanted to exchange data with an Oracle database you<br/>would use oraperl and if you had to communicate with a Sybase database you<br/>would use sybperl. Modules were also available to talk to many other popular<br/>database systems.<br/>
Most of these database access modules were a thin Perl wrapper around the pro-<br/>
gramming APIs that were already provided by the database vendors. The mecha-<br/>nisms for talking to the various databases were all doing largely the same thing, but<br/>they were doing it in completely incompatible ways.<br/>
This has all changed in recent years with the introduction of the generic Perl<br/>
Database Interface (DBI) module. This module was designed and written by Tim<br/>Bunce (the author and maintainer of oraperl). It allows a program to connect to<br/>any of the supported database systems and read and write data using exactly the same<br/>syntax. The only change required to connect to a different database system is to<br/>change one string that is passed to the DBI connect function. It does this by using<br/>different database driver (DBD) modules. These are all named DBD::&lt;db_name&gt;.<br/>You will need to obtain the DBD module for whichever database you are using sepa-<br/>rately from the main DBI module. <br/>
<i><b>3.2.1</b></i><br/>
<i><b>Sample DBI program</b></i><br/>
A sample DBI program to read data from a database would look like this:<br/>
1: #!/usr/local/bin/perl –w<br/>
2:<br/>
3: use strict;<br/>
4: use DBI;<br/>
5:<br/>
<hr/>
<a name=68></a><b>48</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
6: my $user = 'dave';<br/>
7: my $pass = 'secret';<br/>
8: my $dbh = DBI-&gt;connect('dbi:mysql:testdb', $user, $pass,<br/>
9:<br/>
{RaiseError =&gt; 1})<br/>
10:<br/>
|| die &#34;Connect failed: $DBI::errstr&#34;;<br/>
11:<br/>
12: my $sth = $dbh-&gt;prepare('select col1, col2, col3 from my_table')<br/>
13:<br/>
14: $sth-&gt;execute;<br/>
15:<br/>
16: my @row;<br/>
17: while (@row = $sth-&gt;fetchrow_array) {<br/>
18:<br/>
print join(&#34;\t&#34;, @row), &#34;\n&#34;;<br/>
19: }<br/>
20:<br/>
21: $sth-&gt;finish;<br/>
22: $dbh-&gt;disconnect;<br/>
While this is a very simple DBI program, it demonstrates a number of important<br/>DBI concepts and it is worth examining line by line.<br/>
Line 1 points to the Perl interpreter. Notice the use of the -w flag.<br/>Line 3 switches on the strict pragma.<br/>Line 4 brings in the DBI.pm module. This allows us to use the DBI functions.<br/>Lines 6 and 7 define a username and password that we will use to connect to the<br/>
database. Obviously, in a real program you probably wouldn’t want to have a pass-<br/>word written in a script in plain text.<br/>
Line 8 connects us to the database. In this case we are connecting to a database<br/>
running MySQL. This free database program is very popular for web systems. This is<br/>the only line that would need to change if we were connecting to a different data-<br/>base system. The connect function takes a number of parameters which can vary<br/>depending on the database to which you are connecting. The first parameter is a<br/>connection string. This changes its precise meaning for different databases, but it is<br/>always a colon-separated string. The first part is the string dbi and the second part is<br/>always the name of the database system2 that we are connecting to. In this case the<br/>string mysql tells DBI that we will be talking to a MySQL database, and it should<br/>therefore load the DBD::mysql module. The third section of the connection string<br/>in this case is the particular database that we want to connect to. Many database sys-<br/>tems (including MySQL) can store many different databases on the same database<br/>server. In this case we want to connect to a database called testdb. The second and<br/>third parameters are valid usernames and passwords for connecting to this database.<br/>
2 Or, more accurately, the name of the DBD module that we are using to connect to the database.<br/>
<hr/>
<a name=69></a><i><b>Data::Dumper</b></i><br/>
<b>49</b><br/>
The fourth parameter to DBI-&gt;connect is a reference to a hash containing various<br/>configuration options. In this example we switch on the RaiseError option, which<br/>will automatically generate a fatal run-time error if a database error occurs.<br/>
The DBI-&gt;connect function returns a database handle, which can then be used<br/>
to access other DBI functions. If there is an error, the function returns undef. In<br/>the sample program we check for this and, if there is a problem, the program dies<br/>after printing the value of the variable $DBI::errstr which contains the most<br/>recent database error message.<br/>
Line 12 prepares an SQL statement for execution against the database. It does<br/>
this by calling the DBI function prepare. This function returns a statement handle<br/>which can be used to access another set of DBI functions—those that deal with exe-<br/>cuting queries on the database and reading and writing data. This handle is unde-<br/>fined if there is an error preparing the statement.<br/>
Line 14 executes the statement and dies if there is an error.<br/>Line 16 defines an array variable which will hold each row of data returned from<br/>
the database in turn.<br/>
Lines 17 to 19 define a loop which receives each row from the database query and<br/>
prints it out. On line 17 we call fetchrow_array which returns a list containing<br/>one element for each of the columns in the next row of the result set. When the<br/>result set has all been returned, the next call to fetchrow_array will return the<br/>value undef. <br/>
Line 18 prints out the current row with a tab character between each element.<br/>Lines 21 and 22 call functions that reclaim the memory used for the database<br/>
and statement handles. This memory will be reclaimed automatically when the vari-<br/>ables go out of scope, but it is tidier to clean up yourself.<br/>
This has been a very quick overview of using the DBI. There are a number of<br/>
other functions and the most useful ones are listed in appendix A. More detailed<br/>documentation comes with the DBI module and your chosen DBD modules.<br/>
<i><b>3.3</b></i><br/>
<i><b>Data::Dumper</b></i><br/>
As your data structures get more and more complex it will become more and more<br/>useful to have an easy way to see what they look like. A very convenient way to do<br/>this is by using the Data::Dumper module which comes as a standard part of the<br/>Perl distribution. Data::Dumper takes one or more variables and produces a<br/>“stringified” version of the data contained in the variables. <br/>
We’ll see many examples of Data::Dumper throughout the book but, as an<br/>
example, let’s use it to get a dump of the CD data structure that we built in the pre-<br/>vious chapter. The data structure was built up using code like this:<br/>
<hr/>
<a name=70></a><b>50</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
my @CDs;<br/>
my @attrs = qw(artist title label year);<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my %rec;<br/>
@rec{@attrs} = split /\t/;<br/>
push @CDs, \%rec;<br/>
}<br/>
In order to use Data::Dumper we just need to add a use Data::Dumper statement<br/>and a call to the Dumper function like this:<br/>
use Data::Dumper;<br/>
my @CDs;<br/>
my @attrs = qw(artist title label year);<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my %rec;<br/>
@rec{@attrs} = split /\t/;<br/>
push @CDs, \%rec;<br/>
}<br/>
print Dumper(\@CDs);<br/>
Running this program using our CD files as input produces the following output:<br/>
<b>$VAR1 = [</b><br/>
<b>{</b><br/>
<b>'artist' =&gt; 'Bragg, Billy',</b><br/>
<b>'title' =&gt; 'Workers\' Playtime',</b><br/>
<b>'year' =&gt; '1987',</b><br/>
<b>'label' =&gt; 'Cooking Vinyl'</b><br/>
<b>},</b><br/>
<b>{</b><br/>
<b>'artist' =&gt; 'Bragg, Billy',</b><br/>
<b>'title' =&gt; 'Mermaid Avenue',</b><br/>
<b>'year' =&gt; '1998',</b><br/>
<b>'label' =&gt; 'EMI'</b><br/>
<b>},</b><br/>
<b>{</b><br/>
<b>'artist' =&gt; 'Black, Mary',</b><br/>
<b>'title' =&gt; 'The Holy Ground',</b><br/>
<b>'year' =&gt; '1993',</b><br/>
<b>'label' =&gt; 'Grapevine'</b><br/>
<b>},</b><br/>
<b>{</b><br/>
<b>'artist' =&gt; 'Black, Mary',</b><br/>
<b>'title' =&gt; 'Circus',</b><br/>
<b>'year' =&gt; '1996',</b><br/>
<b>'label' =&gt; 'Grapevine'</b><br/>
<b>},</b><br/>
<hr/>
<a name=71></a><i><b>Benchmarking</b></i><br/>
<b>51</b><br/>
<b>{</b><br/>
<b>'artist' =&gt; 'Bowie, David',</b><br/>
<b>'title' =&gt; 'Hunky Dory',</b><br/>
<b>'year' =&gt; '1971',</b><br/>
<b>'label' =&gt; 'RCA'</b><br/>
<b>},</b><br/>
<b>{</b><br/>
<b>'artist' =&gt; 'Bowie, David',</b><br/>
<b>'title' =&gt; 'Earthling',</b><br/>
<b>'year' =&gt; '1998',</b><br/>
<b>'label' =&gt; 'EMI'</b><br/>
<b>}</b><br/>
<b>];</b><br/>
This is a very understandable representation of our data structure.<br/>
Notice that we passed a reference to our array rather than the array itself. This is<br/>
because Dumper expects a list of variables as arguments so, if we had passed an array, it<br/>would have processed each element of the array individually and produced output for<br/>each of them. By passing a reference we forced it to treat our array as a single object.<br/>
<i><b>3.4</b></i><br/>
<i><b>Benchmarking</b></i><br/>
When choosing between various ways to implement a task in Perl, it will often be<br/>useful to know which option is the quickest. Perl provides a module called Bench-<br/>mark that makes it easy to get this data. This module contains a number of func-<br/>tions (see the documentation for details) but the most useful for comparing the<br/>performance of different pieces of code is called timethese. This function takes a<br/>number of pieces of code, runs them each a number of times, and returns the time<br/>that each piece of code took to run. You should, therefore, break your options<br/>down into separate functions which all do the same thing in different ways and pass<br/>these functions to timethese. For example, there are four ways to put the value of<br/>a variable into the middle of a fixed string. You can interpolate the variable directly<br/>within the string <br/>
$str = &#34;The value is $x (or thereabouts)&#34;;<br/>
or join a list of values <br/>
$str = join '', 'The value is ', $x, ' (or thereabouts)';<br/>
or concatenate the values <br/>
$s = 'The value is ' . $x . ' (or thereabouts)';<br/>
or, finally, use sprintf.<br/>
<hr/>
<a name=72></a><b>52</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
$str = sprintf 'The value is %s (or thereabouts)', $x;<br/>
In order to calculate which of these methods is the fastest, you would write a script<br/>like this: <br/>
#!/usr/bin/perl -w<br/>
use strict;<br/>
use Benchmark qw(timethese);<br/>
my $x = 'x' x 100;<br/>
sub using_concat {<br/>
my $str = 'x is ' . $x . ' (or thereabouts)';<br/>
}<br/>
sub using_join {<br/>
my $str = join '', 'x is ', $x, ' (or thereabouts)';<br/>
}<br/>
sub using_interp {<br/>
my $str = &#34;x is $x (or thereabouts)&#34;;<br/>
}<br/>
sub using_sprintf {<br/>
my $str = sprintf(&#34;x is %s (or thereabouts)&#34;, $x);<br/>
}<br/>
timethese (1E6, {<br/>
'concat'<br/>
=&gt; \&amp;using_concat,<br/>
'join'<br/>
=&gt; \&amp;using_join,<br/>
'interp'<br/>
=&gt; \&amp;using_interp,<br/>
'sprintf' =&gt; \&amp;using_sprintf,<br/>
});<br/>
On my current computer,3 running this script gives the following output: <br/>
<b>Benchmark: timing 1000000 iterations of concat, interp, join, sprintf …</b><br/>
<b>concat: 8 wallclock secs ( 7.36 usr + 0.00 sys = 7.36 CPU) @ 135869.57/s (n=1000000)</b><br/>
<b>interp:</b><br/>
<b>8 wallclock secs ( 6.92 usr + -0.00 sys =</b><br/>
<b>6.92 CPU) @ 144508.67/s (n=1000000)</b><br/>
<b>join: 9 wallclock secs ( 8.38 usr + 0.03 sys = 8.41 CPU) @ 118906.06/s (n=1000000)</b><br/>
<b>sprintf: 12 wallclock secs (11.14 usr +</b><br/>
<b>0.02 sys = 11.16 CPU) @ 89605.73/s</b><br/>
<b>(n=1000000)</b><br/>
What does this mean? Looking at the script, we can see that we call the function<br/>timethese, passing it an integer followed by a reference to a hash. The integer is the<br/>number of times that you want the tests to be run. The hash contains details of the<br/>code that you want tested. The keys to the hash are unique names for each of the<br/>subroutines and the values are references to the functions themselves. timethese<br/>will run each of your functions the given number of times and will print out the<br/>
3 A rather old 200 MHz P6 with 64 MB of RAM, running Microsoft Windows 98 and ActivePerl build 521.<br/>
<hr/>
<a name=73></a><i><b>Command line scripts</b></i><br/>
<b>53</b><br/>
results. As you can see from the results we get above, our functions fall into three<br/>sets. Both concat and interp took about 8 seconds of CPU time to run 1,000,000<br/>times; join was a little longer at 9 seconds; and sprintf came in at 12 seconds of<br/>CPU time. <br/>
You can then use these figures to help you decide which version of the code to<br/>
use in your application.<br/>
<i><b>3.5</b></i><br/>
<i><b>Command line scripts</b></i><br/>
Often data munging scripts are written to carry out one-off tasks. Perhaps you have<br/>been given a data file which you need to clean up before loading it into a database.<br/>While you can, of course, write a complete Perl script to carry out this munging,<br/>Perl supplies a set of command line options which make it easy to carry out this<br/>kind of task from the command line. This approach can often be more efficient.<br/>
The basic option for command line processing is -e. The text following this<br/>
option is treated as Perl code and is passed through to the Perl interpreter. You can<br/>therefore write scripts like:<br/>
perl -e 'print &#34;Hello world\n&#34;'<br/>
You can pass as many -e options as you want to Perl and they will be run in the<br/>order that they appear on the command line. You can also combine many state-<br/>ments in one -e string by separating them with a semicolon.<br/>
If the code that you want to run needs a module that you would usually include<br/>
with a use statement, you can use the -M option to load the module. For example,<br/>this makes it easy to find the version of any module that is installed on your system4<br/>using code like this:<br/>
perl -MCGI -e 'print $CGI::VERSION'<br/>
These single-line scripts can sometimes be useful, but there is a whole set of more<br/>powerful options to write file processing scripts. The first of these is -n, which adds<br/>a loop around your code which looks like this:<br/>
LINE:<br/>
while (&lt;&gt;) {<br/>
# Your -e code goes here<br/>
}<br/>
This can be used, for example, to write a simple grep-like script such as:<br/>
perl -ne 'print if /search text/' file.txt<br/>
4 Providing that the module uses the standard practice of defining a $VERSION variable.<br/>
<hr/>
<a name=74></a><b>54</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
which will print any lines in file.txt that contain the string “search text”. Notice<br/>the presence of the LINE label which allows you to write code using next LINE.<br/>
If you are transforming data in the file and want to print a result for every line,<br/>
then you should use the -p option which prints the contents of $_ at the end of<br/>each iteration of the while loop. The code it generates looks like this:<br/>
LINE:<br/>
while (&lt;&gt;) {<br/>
# Your -e code goes here<br/>
} continue {<br/>
print<br/>
}<br/>
As an example of using this option, imagine that you wanted to collapse multiple<br/>zeroes in a record to just one. You could write code like this:<br/>
perl -pe 's/0+/0/g' input.txt &gt; output.txt<br/>
With the examples we’ve seen so far, the output from the script is written to STDOUT<br/>(that is why we redirected STDOUT to another file in the last example). There is<br/>another option, -i, which allows us to process a file in place and optionally create a<br/>backup containing the previous version of the file. The -i takes a text string which<br/>will be the extension added to the backup of the file, so we can rewrite our previous<br/>example as:<br/>
perl -i.bak -pe 's/0+/0/g' input.txt<br/>
This option will leave the changed data in input.txt and the original data in<br/>input.txt.bak. If you don’t give -i an extension then no backup is made (so<br/>you’d better be pretty confident that you know what you’re doing!).<br/>
There are a number of other options that can make your life even easier. Using<br/>
-a turns on autosplit, which in turn splits each input row into @F. By default,<br/>autosplit splits the string on any white space, but you can change the split character<br/>using -F. Therefore, in order to print out the set of user names from /etc/passwd<br/>you can use code like this:<br/>
perl -a -F':' -ne 'print &#34;$F[0]\n&#34;' &lt; /etc/passwd<br/>
The –l option switches on line-end processing. This automatically does a chomp on<br/>each line when used with -n or -p. You can also give it an optional octal number<br/>which will change the value of the output record separator ($\).5 This value is<br/>
5 Special variables like $\ are covered in more detail in chapter 6.<br/>
<hr/>
<a name=75></a><i><b>Further information</b></i><br/>
<b>55</b><br/>
appended to the end of each output line. Without the octal number, $\ is set to the<br/>same value as the input record separator ($/). The default value for this is a newline.<br/>You can change the value of $/ using the -0 (that’s dash-zero, not dash-oh) option.<br/>
What this means is that in order to have newlines automatically removed from<br/>
your input lines and automatically added back to your output line, just use –l. For<br/>instance, the previous /etc/passwd example could be rewritten as:<br/>
perl -a -F':' -nle 'print $F[0]' &lt; /etc/passwd<br/>
For more information about these command line options see the perlrun manual<br/>page which is installed when you install Perl.<br/>
<i><b>3.6</b></i><br/>
<i><b>Further information</b></i><br/>
More discussion of the Schwartzian transform, the Orcish Manoeuvre, and other<br/>Perl tricks can be found in <i>Effective Perl Programming </i>by Joseph Hall with Randal<br/>Schwartz (Addison-Wesley) and <i>The Perl Cookbook</i> by Tom Christiansen and<br/>Nathan Torkington (O’Reilly).<br/>
The more academic side of sorting in Perl is discussed in <i>Mastering Algorithms</i><br/>
<i>with Perl</i> by Jon Orwant, Jarkko Hietaniemi, and John Macdonald (O’Reilly).<br/>
More information about benchmarking can be found in the documentation for<br/>
the Benchmark.pm module.<br/>
Further information about the DBI and DBD modules can be found in <i>Program-</i><br/>
<i>ming the Perl DBI</i> by Tim Bunce and Alligator Descartes (O’Reilly) and in the<br/>documentation that is installed along with the modules. When you have installed<br/>the DBI module you can read the documentation by typing<br/>
perldoc DBI<br/>
at your command line. Similarly you can read the documentation for any installed<br/>DBD module by typing <br/>
perldoc DBD::&lt;name&gt;<br/>
at your command line. You should replace &lt;name&gt; with the name of the DBD mod-<br/>ule that you have installed, for example “Sybase” or “mysql”.<br/>
<hr/>
<a name=76></a><b>56</b><br/>
CHAPTER <br/>
<i><b>Useful Perl idioms</b></i><br/>
<i><b>3.7</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
Sorting can be very simple in Perl, but for more complex sorts there are a<br/>number of methods which can make the sort more efficient.<br/>
■<br/>
Database access in Perl is very easy using the DBI.<br/>
■<br/>
Data::Dumper is very useful for seeing what your internal data structures<br/>look like.<br/>
■<br/>
Benchmarking is very important, but can be quite tricky to do correctly.<br/>
■<br/>
Command line scripts can be surprisingly powerful.<br/>
<hr/>
<a name=77></a><img class="yflip" src="dmp-77_1.jpg"/><br/>
<i>Patter 4</i><br/>
<i>n matching</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
String handling functions<br/>
■<br/>
Functions for case transformation<br/>
■<br/>
Regular expressions—what they are and how <br/>to use them<br/>
■<br/>
Taking regular expressions to extremes <br/>
<i>57</i><br/>
<hr/>
<a name=78></a><b>58</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
A lot of data munging involves the use of pattern matching. In fact, it’s probably<br/>fair to say that the vast majority of data munging uses pattern matching in one way<br/>or another. Most pattern matching in Perl is carried out using regular expressions.1<br/>It is therefore very important that you understand how to use them. In this chapter<br/>we take an overview of regular expressions in Perl and how they can be used in data<br/>munging, but we start with a brief look at a couple of methods for pattern matching<br/>that don’t involve regular expressions.  <br/>
<i><b>4.1</b></i><br/>
<i><b>String handling functions</b></i><br/>
Perl has a number of functions for handling strings and these are often far simpler<br/>to use and more efficient than the regular expression-based methods that we will<br/>discuss later. When considering how to solve a particular problem, it is always worth<br/>seeing if you can use a simpler method before going straight for a solution using<br/>regular expressions.<br/>
<i><b>4.1.1</b></i><br/>
<i><b>Substrings</b></i><br/>
If you want to extract a particular portion of a string then you can use the substr<br/>function. This function takes two mandatory parameters: a string to work on and<br/>the offset to start at, and two optional parameters: the length of the required<br/>substring and another string to replace it with. If the third parameter is omitted,<br/>then the substring will include all characters in the source string from the given off-<br/>set to the end. The offset of the first character in the source string is 0.2 If the offset<br/>is negative then it counts from the end of the string. Here are a few simple examples:<br/>
my $string = 'Alas poor Yorick. I knew him Horatio.';<br/>
my $sub1 = substr($string, 0, 4);<br/>
# $sub1 contains 'Alas'<br/>
my $sub2 = substr($string, 10, 6);<br/>
# $sub2 contains 'Yorick'<br/>
my $sub3 = substr($string, 29);<br/>
# $sub3 contains 'Horatio.'<br/>
my $sub4 = substr($string, -12, 3);<br/>
# $sub4 contains 'him'<br/>
Many programming languages have a function that produces substrings in a similar<br/>manner, but the clever thing about Perl’s substr function is that the result of the<br/>operation can act as an lvalue. That is, you can assign values to it, like this:<br/>
my $string = 'Alas poor Yorick. I knew him Horatio.';<br/>
substr($string, 10, 6) = 'Robert';<br/>
substr($string, 29) = 'as Bob';<br/>
print $string;<br/>
1 In fact, it’s often suggested that regular expressions in Perl are overused.<br/>2 Or, more accurately, it is the value of the special $[ variable, but as that is initially set to zero and there is<br/>
really no good reason to change it, your strings should always start from position zero.<br/>
<hr/>
<a name=79></a><i><b>String handling functions</b></i><br/>
<b>59</b><br/>
which will produce the output:<br/>
<b>Alas poor Robert. I knew him as Bob</b><br/>
Notice the second assignment in this example which demonstrates that the sub-<br/>string and the text that you are replacing it with do not have to be the same length.<br/>Perl will take care of any necessary manipulation of the strings. You can even do<br/>something like this:<br/>
my $short = 'Short string';<br/>
my $long<br/>
= 'Very, very, very, very long';<br/>
substr($short, 0, 5) = $long;<br/>
which will leave $short containing the text “Very, very, very, very long string”.<br/>
<i><b>4.1.2</b></i><br/>
<i><b>Finding strings within strings (index and rindex)</b></i><br/>
Two more functions that are useful for this kind of text manipulation are index and<br/>rindex. These functions do very similar things—index finds the first occurrence of<br/>a string in another string and rindex finds the last occurrence. Both functions<br/>return an integer indicating the position3 in the source string where the given sub-<br/>string begins, and both take an optional third parameter which is the position where<br/>the search should start. Here are some simple examples:<br/>
my $string = 'To be or not to be.';<br/>
my $pos1 = index($string, 'be');<br/>
# $pos1 is 3<br/>
my $pos2 = rindex($string, 'be');<br/>
# $pos2 is 16<br/>
my $pos3 = index($string, 'be', 5);<br/>
# $pos3 is 16<br/>
my $pos4 = index($string, 'not');<br/>
# $pos4 is 9<br/>
my $pos5 = rindex($string, 'not');<br/>
# $pos5 is 9<br/>
It’s worth noting that $pos3 is 16 because we don’t start looking until position 5;<br/>and $pos4 and $pos5 are equal because there is only one instance of the string<br/>'not' in our source string.<br/>
It is, of course, possible to use these three functions in combination to carry out<br/>
more complex tasks. For example, if you had a string and wanted to extract the<br/>middle portion that was contained between square brackets ([ and ]), you could do<br/>something like this:<br/>
my $string = 'Text with an [important bit] in brackets';<br/>
my $start = index($string, '[');<br/>
my $end = rindex($string, ']');<br/>
my $keep = substr($string, $start+1, $end-$start-1);<br/>
3 Again, the positions start from 0—or the value of $[.<br/>
<hr/>
<a name=80></a><b>60</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
although in this case, the regular expression solution would probably be more eas-<br/>ily understood.<br/>
<i><b>4.1.3</b></i><br/>
<i><b>Case transformations</b></i><br/>
Another common requirement is to alter the case of a text string, either to change<br/>the string to all upper case, all lower case, or some combination. Perl has functions<br/>to handle all of these eventualities. The functions are uc (to convert a whole string<br/>to upper case), ucfirst (to convert the first character of a string to upper case), lc<br/>(to convert a whole string to lower case), and lcfirst (to convert the first charac-<br/>ter of a string to lower case).<br/>
There are a couple of traps that seem to catch unwary programmers who use<br/>
these functions. The first of these is with the ucfirst and lcfirst functions. It is<br/>important to note that they do exactly what they say and affect only the first charac-<br/>ter in the given string. I have seen code like this:<br/>
$string = ucfirst 'UPPER';<br/>
# This doesn’t work<br/>
where the programmer expects to end up with the string 'Upper'. The correct<br/>code to achieve this is:<br/>
$string = ucfirst lc 'UPPER';<br/>
The second trap for the unwary is that these functions will respect your local lan-<br/>guage character set, but to make use of that, you need to switch on Perl’s locale<br/>support by including the line use locale in your program.<br/>
<i><b>4.2</b></i><br/>
<i><b>Regular expressions</b></i><br/>
In this section we take a closer look at regular expressions. This is one of Perl’s most<br/>powerful tools for data munging, but it is also a feature that many people have diffi-<br/>culty understanding.<br/>
<i><b>4.2.1</b></i><br/>
<i><b>What are regular expressions?</b></i><br/>
“Regular expression” is a very formal computer science sounding term for some-<br/>thing that would probably scare people a great deal less if we simply called it “pat-<br/>tern matching,” because that is basically what we are talking about.<br/>
If you have some data and you want to know whether or not certain strings are<br/>
present within the data set, then you need to construct a regular expression that<br/>describes the data that you are looking for and see whether it matches your data.<br/>Exactly how you construct the regular expression and match it against your data<br/>
<hr/>
<a name=81></a><i><b>Regular expressions</b></i><br/>
<b>61</b><br/>
will be covered later in the chapter. First we will look at the kinds of things that you<br/>can match with regular expressions.<br/>
Many text-processing tools support regular expressions. UNIX tools like vi, sed,<br/>
grep, and awk all support them to varying degrees. Even some Windows-based tools<br/>like Microsoft Word allow you to search text using basic kinds of regular expressions.<br/>Of all of these tools, Perl has the most powerful regular expression support.<br/>
Among others, Perl regular expressions can match the following:<br/>
■<br/>
A text phrase<br/>
■<br/>
Phrases containing optional sections<br/>
■<br/>
Phrases containing repeated sections<br/>
■<br/>
Alternate phrases (i.e., either <i>this</i> or <i>that</i>)<br/>
■<br/>
Phrases that must appear at the start or end of a word<br/>
■<br/>
Phrases that must appear at the start or end of a line<br/>
■<br/>
Phrases that must appear at the start or end of the data<br/>
■<br/>
Any character from a group of characters<br/>
■<br/>
Any character not from a group of characters<br/>
Recent versions of Perl have added a number of extensions to the standard regu-<br/>
lar expression set, some of which are still experimental at the time of this writing.<br/>For the definitive, up-to-date regular expression documentation for your version of<br/>Perl see the perlre documentation page.<br/>
<i><b>4.2.2</b></i><br/>
<i><b>Regular expression syntax</b></i><br/>
In Perl you can turn a string of characters into a regular expression by enclosing it<br/>in slash characters (/). So, for example<br/>
/regular expression/<br/>
is a regular expression which matches the string “regular expression”. <br/>
<i><b>Regular expression metacharacters<br/></b></i>Within a regular expression most characters will match themselves4 unless their<br/>meaning is modified by the presence of various metacharacters. The list of meta-<br/>characters that can be used in Perl regular expressions is <br/>
\ | ( ) [ { ^ $ * + ? .<br/>
4 That is, a letter “a” in a regular expression will match the character “a” in the target string.<br/>
<hr/>
<a name=82></a><b>62</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
Any of these metacharacters can be used to match itself in a regular expression by<br/>preceding it with a backslash character (\). You’ll see that the backslash is itself a<br/>metacharacter, so to match a literal backslash you’ll need to have two backslashes in<br/>your regular expression /foo\\bar/ matches “foo\bar”.<br/>
The dot character (.) matches any character.<br/>The normal escape sequences that are familiar from many programming lan-<br/>
guages are also available. A tab character is matched by \t, a newline by \n, a car-<br/>riage return by \r, and a form feed by \f.<br/>
<i><b>Character classes<br/></b></i>You can match any character in a group of characters (known in Perl as a <i>character<br/>class</i>) by enclosing the list of characters within square brackets ([ and ]). If a group<br/>of characters are consecutive in your character set, then you can use a dash character<br/>(-) to denote a range of characters. Therefore the regular expression<br/>
/[aeiouAEIOU]/<br/>
will match any vowel and<br/>
/[a-z]/<br/>
will match any lower case letter.<br/>
To match any character that is not in a character class, put a caret (^) at the start<br/>
of the group, so<br/>
/[^aeiouAEIOU]/<br/>
matches any nonvowel (note that this does not just match consonants; it will also<br/>match punctuation characters, spaces, control characters—and even extended ASCII<br/>characters like ñ, «, and é).<br/>
<i><b>Escape sequences<br/></b></i>There are a number of predefined character classes that can be denoted using escape<br/>sequences. Any digit is matched by \d. Any word character (i.e., digits, upper and<br/>lower case letters, and the underscore character) is matched by \w and any white<br/>space character (space, tab, carriage return, line feed, or form feed) is matched by<br/>\s. The inverses of these classes are also defined. Any nondigit is matched by \D, any<br/>nonword character is matched by \W, and any nonspace character is matched by \S.<br/>
<i><b>Matching alternatives<br/></b></i>The vertical bar character (|) is used to denote alternate matches. A regular expres-<br/>sion, such as:<br/>
/regular expression|regex/<br/>
<hr/>
<a name=83></a><i><b>Regular expressions</b></i><br/>
<b>63</b><br/>
will match either the string “regular expression” or the string “regex”. Parentheses<br/>(( and )) can be used to group strings, so while<br/>
/regexes are cool|rubbish/<br/>
will match the strings “regexes are cool” or “rubbish”, <br/>
/regexes are (cool|rubbish)/<br/>
will match “regexes are cool” or “regexes are rubbish”.<br/>
<i><b>Capturing parts of matches<br/></b></i>A side effect of grouping characters using parentheses is that if a string matches a<br/>regular expression, then the parts of the string which match the sections in paren-<br/>theses will be stored in special variables called $1, $2, $3, etc. For example, after<br/>matching a string against the previous regular expression, then $1 will contain the<br/>string “cool” or “rubbish.” We will see more examples of this later in the chapter.<br/>
<i><b>Quantifying matches<br/></b></i>You can also quantify the number of times that a string should appear using the +,<br/>*, or ? characters. Putting + after a character (or string of characters in a parentheses<br/>or a character class) allows that item to appear one or more times, * allows the item<br/>to appear zero or more times, and ? allows the item to appear zero or one time (i.e.,<br/>it becomes optional). For example:<br/>
/so+n/<br/>
will match “son”, “soon”, or “sooon”, etc., whereas<br/>
/so*n/<br/>
will match “sn”, “son”, “soon”, and “sooon”, etc., and<br/>
/so?n/<br/>
will only match “sn”, and “son”.<br/>
Similarly for groups of characters,<br/>
/(so)+n/<br/>
will match “son”, “soson”, or “sososon”, etc., whereas<br/>
/(so)*n/<br/>
will match “n”, “son”, “soson”, and “sososon”,  etc., and<br/>
/(so)?n/<br/>
will match only “n” and “son”.<br/>
<hr/>
<a name=84></a><b>64</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
You can have more control over the number of times that a term appears using the<br/>
{n,m} syntax. In this syntax the term to be repeated is followed by braces containing<br/>up to two numbers separated by a comma. The numbers indicate the minimum and<br/>maximum times that the term can appear. For example, in the regular expression<br/>
/so{1,2}n/<br/>
the “o” will match if it appears once or twice, so “son” or “soon” will match, but<br/>“sooon” will not. If the first number is omitted, then it is assumed to be zero and if<br/>the second number is omitted then there is assumed to be no limit to the number of<br/>occurrences that will match. You should notice that the +, *, and ? forms that we<br/>used earlier are not strictly necessary as they could be indicated using {1,}, {0,},<br/>and {0,1}. If only one number appears without a comma then the expression will<br/>match if the term appears exactly that number of times.<br/>
<i><b>Anchoring matches<br/></b></i>It is also possible to anchor parts of your regular expression at various points of the<br/>data. If you want to match a regular expression only at the start of your data you can<br/>use a caret (^). Similarly, a dollar sign ($) matches at the end of the data. To match<br/>an email header line which consists of a string such as “From”, “To”, or “Subject”<br/>followed by a colon, an optional space and some more text, you could use a regular<br/>expression like this:5<br/>
/^[^:]+: ?.+$/<br/>
which matches the start of the line followed by at least one noncolon character, fol-<br/>lowed by a colon, an optional space, and at least one other character before the end<br/>of the line.<br/>
Other special terms can be used to match at word boundaries. The term \b<br/>
matches only at the start or end of a word (i.e., between a \w character and a \W<br/>character) and its inverse \B only matches within a word (i.e., between two \w charac-<br/>ters). For instance, if we wanted to match “son”, but didn’t want to match it at the<br/>end of names like “Johnson” and “Robertson” we could use a regular expression like:<br/>
/\bson\b/<br/>
and if we were only interested in occurrences of “son” at the end of other words,<br/>we could use:<br/>
/\Bson\b/<br/>
5 You could also write this as /^.+?: ?.+$/, but we don’t cover the syntax for nongreedy matching until<br/>
later in the chapter.<br/>
<hr/>
<a name=85></a><i><b>Regular expressions</b></i><br/>
<b>65</b><br/>
<i><b>More complex regular expressions<br/></b></i>Recent versions of Perl have added more complexity to regular expressions allowing<br/>you to define more complex rules against which you match your strings. The full<br/>explanation of these enhancements is in your Perl documentation, but the most<br/>important additions are:<br/>
■<br/>
(?: … )—These parentheses group in the same way that normal brackets do,<br/>but when they match, their contents don’t get assigned to $1, $2, etc.<br/>
■<br/>
(?= … )—This is known as positive lookahead. It enables you to check that<br/>whatever is between the parentheses exists there in the string, but it doesn’t<br/>actually consume the next part of the string that is being matched. <br/>
■<br/>
(?! … )—This is negative lookahead, which is the opposite of positive looka-<br/>head. You will only get a match if whatever is in the parentheses does <i>not<br/></i>match the string there.<br/>
<i><b>4.2.3</b></i><br/>
<i><b>Using regular expressions</b></i><br/>
Most regular expressions are used in Perl programs in one of two ways. The simpler<br/>way is to check if a data string matches the regular expression, and the slightly more<br/>complex way is to replace parts of data strings with other strings.<br/>
<i><b>String matching<br/></b></i>To match a string against a regular expression in Perl we use the match operator—<br/>which is normally called m//, although it is quite possible that it looks nothing like<br/>that when you use it.<br/>
By default, the match operator works on the $_ variable. This works very well<br/>
when you are looping through an array of values. Imagine, for example, that you<br/>have a text file containing email messages and you want to print out all of the lines<br/>containing “From” headers. You could do something like this:<br/>
open MAIL, 'mail.txt' or die &#34;Can’t open mail.txt: $!&#34;;<br/>
while (&lt;MAIL&gt;) {<br/>
print if m/^From:/;<br/>
}<br/>
The while loop reads in another line from the file each time around and stores the<br/>line in $_. The match operator checks for lines beginning with the string “From:”<br/>(note the ^ character that matches the start of the line) and returns true for lines<br/>that match. These lines are then printed to STDOUT.<br/>
One nice touch with the match operator is that in many cases the m is optional so<br/>
we can write the match statement in our scripts as<br/>
print if /^From:/;<br/>
<hr/>
<a name=86></a><b>66</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
and that is how you will see it in most scripts that you encounter. It is also possible<br/>to use delimiters other than the / character, but in this case the m becomes manda-<br/>tory. To see why you might want to do this, look at this example:<br/>
open FILES 'files.txt' or die &#34;Can't open files.txt: $!&#34;;<br/>
while (&lt;FILES&gt;) {<br/>
print if /\/davec\//;<br/>
}<br/>
In this script we are doing a very similar thing to the previous example, but in this<br/>case we are scanning a list of files and printing the ones that are under a directory<br/>called davec. The directory separator character is also a slash, so we need to escape<br/>it within the regular expression with back-slashes and the whole thing ends up look-<br/>ing a little inelegant (this is sometimes known as leaning toothpick syndrome). To<br/>get around this, Perl allows us to choose our own regular expression delimiter. This<br/>can be any punctuation character, but if we choose one of the paired delimiter char-<br/>acters ((, {, [ or &lt;) to open our regular expression we must use the opposite charac-<br/>ter (), }, ] or &gt;) to close it, otherwise we just use the same character. We can<br/>therefore rewrite our match line as<br/>
print if m(/davec/);<br/>
or<br/>
print if m|/davec/|;<br/>
or even<br/>
print if m=/davec/=;<br/>
any of which may well be easier to read than the original. Note that in all of these<br/>cases we have to use the m at the start of the expression.<br/>
<i><b>More capturing<br/></b></i>Once a match has been successful, Perl sets a number of special variables. For each<br/>bracketed group in your regular expression, Perl sets a variable. The first bracket<br/>group goes into $1, the second into $2, and so on. Bracketed groups can be nested,<br/>so the order of assignment to these variables depends upon the order of the open-<br/>ing bracket of the group. Going back to our earlier email header example, if we had<br/>an email in a text file and wanted to print out all of the headers, we could do some-<br/>thing like this:6<br/>
6 This simplified example conveniently ignores the fact that email headers can continue onto more than one<br/>
line and that an email body can contain the character “:”.<br/>
<hr/>
<a name=87></a><i><b>Regular expressions</b></i><br/>
<b>67</b><br/>
open MAIL, 'mail.txt' or die &#34;Can't open mail.txt: $!&#34;;<br/>
while (&lt;MAIL&gt;) {<br/>
if (/^([^:]+): ?(.+)$/) {<br/>
print &#34;Header $1 has the value $2\n&#34;;<br/>
}<br/>
We have added two sets of brackets to the original regular expression which will cap-<br/>ture the header name and value into $1 and $2 so that we can print them out in the<br/>next line. If a match operation is evaluated in an array context, it returns the values<br/>of $1, $2, and so forth in a list. We could, therefore, rewrite the previous example as:<br/>
open MAIL, 'mail.txt' or die &#34;Can't open mail.txt: $!&#34;;<br/>
my ($header, $value);<br/>
while (&lt;MAIL&gt;) {<br/>
if (($header, $value) = /^([^:]+): ?(.+)$/) {<br/>
print &#34;Header $header has the value $value\n&#34;;<br/>
}<br/>
}<br/>
There are other variables that Perl sets on a successful match. These include $&amp;<br/>which is set to the part of the string that matched the whole regular expression, $‘<br/>which is set to the part of the string before the part that matched the regular<br/>expression, and $’ which is set to the part of the string after the part that matched<br/>the regular expressions. Therefore after executing the following code:<br/>
$_ = 'Matching regular expressions';<br/>
m/regular expression/;<br/>
$&amp; will contain the string “regular expression”, $‘ will contain “Matching ”, and $’<br/>will contain “s”. Obviously these variables are far more useful if your regular expres-<br/>sion is not a fixed string.<br/>
There is one small downside to using these variables. Perl has to do a lot more<br/>
work to keep them up to date. If you don’t use them it doesn’t set them. However,<br/>if you use them in just one match in your program, Perl will then keep them<br/>updated for every match. Using them can therefore have an effect on performance.<br/>
<i><b>Matching against other variables<br/></b></i>Obviously not every string that you are going to want to match is going to be in $_,<br/>so Perl provides a binding operator which binds the match to another variable. The<br/>operator looks like this:<br/>
$string =~ m/regular expression/<br/>
<hr/>
<a name=88></a><b>68</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
This statement searches for a match for the string “regular expression” within the<br/>text in the variable $string.<br/>
<i><b>Match modifiers<br/></b></i>There are a number of optional modifiers that can be applied to the match operator<br/>to change the way that it works. These modifiers are all placed after the closing<br/>delimiter. The most commonly used modifier is i which forces the match to be<br/>case-insensitive, so that<br/>
m/hello/i<br/>
will match “hello”, “HELLO”, “Hello”, or any other combination of cases. Earlier<br/>we saw a regular expression for matching vowels that looked like this<br/>
/[aeiouAEIOU]/<br/>
Now that we have the i modifier, we can rewrite this as<br/>
/[aeiou]/i<br/>
The next two modifiers are s and m which force the match to treat the data string as<br/>either single or multiple lines. In multiple line mode, “.” will match a newline char-<br/>acter (which would not happen by default). Also ^ and $ will match at the start and<br/>end of any line. To match the start and end of the entire string you can use the<br/>anchors \A and \Z.<br/>
The final modifier is x. This allows you to put white space and comments within<br/>
your regular expressions. The regular expressions that we have looked at so far have<br/>been very simple, but regular expressions are largely what give Perl its reputation of<br/>being written in line noise. If we look again at the regular expression we used to<br/>match email headers, is it easier to follow like this:<br/>
m/^[^:]+\s?.+$/<br/>
or like this<br/>
m/^<br/>
# start of line<br/>
[^:]+ # at least one non-colon<br/>
:<br/>
# a colon<br/>
\s?<br/>
# an optional white space character<br/>
.+<br/>
# at least one other character<br/>
$/x<br/>
# end of line<br/>
And that’s just a simple example!<br/>
<hr/>
<a name=89></a><i><b>Regular expressions</b></i><br/>
<b>69</b><br/>
<i><b>String replacement<br/></b></i>The string replacement operation looks strikingly similar to the string-matching<br/>operator, and works in a quite similar fashion. The operator is usually called s///<br/>although, like the string-matching operator, it can actually take many forms.<br/>
The simplest way of using the string replacement operator is to replace occur-<br/>
rences of one string with another string. For example to replace “Dave” with<br/>“David” you would use this code:<br/>
s/Dave/David/;<br/>
The first expression (Dave) is evaluated as a regular expression. The second expres-<br/>sion is a string that will replace whatever matched the regular expression in the orig-<br/>inal data string. This replacement string can contain any of the variables that get set<br/>on a successful match. It is therefore possible to rewrite the previous example as:<br/>
s/(Dav)e/${1}id/<br/>
As with the match operator, the operation defaults to affecting whatever is in the vari-<br/>able $_, but you can bind the operation to a different variable using the =~ operator.<br/>
<i><b>Substitution modifiers<br/></b></i>All of the match operator modifiers (i, s, m, and x) work in the same way on the<br/>substitution operator but there are a few extra modifiers. By default, the substitu-<br/>tion only takes place on the first string matched in the data string. For example:<br/>
my $data = &#34;This is Dave’s data. It is the data belonging to Dave&#34;;<br/>
$data =~ s/Dave/David/;<br/>
will result in $data containing the string “This is David’s data. It is the data<br/>belonging to Dave”. The second occurrence of Dave was untouched. In order to<br/>affect all occurrences of the string we can use the g modifier.<br/>
my $data = &#34;This is Dave’s data. It is the data belonging to Dave&#34;;<br/>
$data =~ s/Dave/David/g;<br/>
This works as expected and leaves $data containing the string “This is David’s<br/>data. It is the data belonging to David”.<br/>
The other two new modifiers only affect the substitution if either the search<br/>
string or the replacement string contains variables or executable code. Consider the<br/>following code:<br/>
my ($new, $old) = @ARGV;<br/>
while (&lt;STDIN&gt;) {<br/>
s/$old/$new/g;<br/>
<hr/>
<a name=90></a><b>70</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
print;<br/>
}<br/>
which is a very simple text substitution filter. It takes two strings as arguments. The<br/>first is a string to search for and the second is a string to replace it with. It then<br/>reads whatever is passed to it on STDIN and replaces one string with the other. This<br/>certainly works, but it is not very efficient. Each time around, the loop Perl doesn’t<br/>know that the contents of $old haven’t changed so it is forced to recompile the<br/>regular expression each time. We, however, know that $old has a fixed value. We<br/>can therefore let Perl know this, by adding the o modifier to the substitution opera-<br/>tor. This tells Perl that it is safe to compile the regular expression once and to reuse<br/>the same version each time around the loop. We should change the substitution line<br/>to read<br/>
s/$old/$new/go;<br/>
There is one more modifier to explain and that is the e modifier. When this modi-<br/>fier is used, the replacement string is treated as executable code and is passed to<br/>eval. The return value from the evaluation is then used as the replacement string.7<br/>As an example, here is a fairly strange way to print out a table of squares:<br/>
foreach (1 .. 12) {<br/>
s/(\d+)/print &#34;$1 squared is &#34;, $1*$1, &#34;\n&#34;/e;<br/>
}<br/>
which produces the following output:<br/>
<b>1 squared is 1</b><br/>
<b>2 squared is 4</b><br/>
<b>3 squared is 9</b><br/>
<b>4 squared is 16</b><br/>
<b>5 squared is 25</b><br/>
<b>6 squared is 36</b><br/>
<b>7 squared is 49</b><br/>
<b>8 squared is 64</b><br/>
<b>9 squared is 81</b><br/>
<b>10 squared is 100</b><br/>
<b>11 squared is 121</b><br/>
<b>12 squared is 144</b><br/>
<i><b>4.2.4</b></i><br/>
<i><b>Example: translating from English to American</b></i><br/>
To finish this overview of regular expressions, let’s write a script that translates from<br/>English to American. To make it easier for ourselves we’ll make a few assumptions.<br/>
7 Actually it isn’t quite that simple, as you can have multiple instances of the e modifier and the replacement<br/>
string is evaluated for each one.<br/>
<hr/>
<a name=91></a><i><b>Regular expressions</b></i><br/>
<b>71</b><br/>
We’ll assume that each English word has just one American translation.8 We’ll also<br/>store our translations in a text file so it is easy to add to them. The program will<br/>look something like this:<br/>
1: #!/usr/bin/perl -w<br/>
2: use strict;<br/>
3:<br/>
4: while (&lt;STDIN&gt;) {<br/>
5:<br/>
6:<br/>
s/(\w+)/translate($1)/ge;<br/>
7:<br/>
print;<br/>
8: }<br/>
9:<br/>
10: my %trans;<br/>
11: sub translate {<br/>
12:<br/>
my $word = shift;<br/>
13:<br/>
14:<br/>
$trans{lc $word} ||= get_trans(lc $word);<br/>
15: }<br/>
16:<br/>
17: sub get_trans {<br/>
18:<br/>
my $word = shift;<br/>
19:<br/>
20:<br/>
my $file = 'american.txt';<br/>
21:<br/>
open(TRANS, $file) || die &#34;Can't open $file: $!&#34;;<br/>
22:<br/>
23:<br/>
my ($line, $english, $american);<br/>
24:<br/>
while (defined($line = &lt;TRANS&gt;)) {<br/>
25:<br/>
chomp $line;<br/>
26:<br/>
($english, $american) = split(/\t/, $line);<br/>
27:<br/>
do {$word = $american; last; } if $english eq $word;<br/>
28:<br/>
}<br/>
29:<br/>
close TRANS;<br/>
30:<br/>
return $word;<br/>
31: }<br/>
<i><b>How the translation program works<br/></b></i>Lines 1 and 2 are the standard way to start a Perl script. <br/>
The loop starting on line 4 reads from STDIN and puts each line in turn in the<br/>
$_ variable.<br/>
Line 6 does most of the work. It looks for groups of word characters. Each time<br/>
it finds one it stores the word in $1. The replacement string is the result of execut-<br/>ing the code translate($1). Notice the two modifiers: g which means that every<br/>
8 We’ll also conveniently ignore situations where an English phrase should be replaced by a different phrase<br/>
in American, such as “car park” and “parking lot.”<br/>
<hr/>
<a name=92></a><b>72</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
word in the line will be converted, and e which forces Perl to execute the replace-<br/>ment string before putting it back into the original string.<br/>
Line 7 prints the value of $_, which is now the translated line. Note that when<br/>
given no arguments, print defaults to printing the contents of the $_ variable—<br/>which in this case is exactly what we want.<br/>
Line 10 defines a caching hash which the translate function uses to store<br/>
words which it already knows how to translate.<br/>
The translate function which starts on line 11 uses a caching algorithm similar<br/>
to the Orcish Manoeuvre. If the current word doesn’t exist in the %trans hash, it<br/>calls get_trans to get a translation of the word. Notice that we always work with<br/>lower case versions of the word.<br/>
Line 17 starts the get_trans function, which will read any necessary words<br/>
from the file containing a list of translatable words.<br/>
Line 20 defines the name of the translations file and line 21 attempts to open it.<br/>
If the file can’t be opened, then the program dies with an error message.<br/>
Line 24 loops though the translations file a line at a time, putting each line of<br/>
text into $line and line 25 removes the newline character from the line.<br/>
Line 26 splits the line on the tab character which separates the English and<br/>
American words.<br/>
Line 27 sets $word to the American word if the English word matches the word<br/>
we are seeking.<br/>
Line 29 closes the file.<br/>Line 30 returns either the translation or the original word if a translation is not<br/>
found while looping through the file. This ensures that the function always returns<br/>a valid word and therefore that the %trans hash will contain an entry for every<br/>word that we’ve come across. If we didn’t do this, then for each word that didn’t<br/>need to be translated, we would have no entry in the hash and would have to search<br/>the entire translations file each time. This way we only search the translations file<br/>once for each unique word.<br/>
<i><b>Using the translation program<br/></b></i>As an example of the use of this script, create a file called american.txt which con-<br/>tains a line for each word that you want to translate. Each line should have the English<br/>word followed by a tab character and the equivalent American word. For example:<br/>
hello&lt;TAB&gt;hiya<br/>
pavement&lt;TAB&gt;sidewalk<br/>
Create another file containing the text that you want to translate. In my test, I used<br/>
Hello.<br/>
Please stay on the pavement.<br/>
<hr/>
<a name=93></a><i><b>Regular expressions</b></i><br/>
<b>73</b><br/>
and running the program using the command line<br/>
translate.pl &lt; in.txt<br/>
produced the output<br/>
<b>hiya.</b><br/>
<b>Please stay on the sidewalk.</b><br/>
If you wanted to keep the translated text in another text file then you could run the<br/>program using the command line<br/>
translate.pl &lt; in.txt &gt; out.txt<br/>
Once again we make use of the power of the UNIX filter model as discussed in<br/>chapter 2.<br/>
This isn’t a particularly useful script. It doesn’t, for example, handle capitaliza-<br/>
tion of the words that it translates. In the next section we’ll look at something a lit-<br/>tle more powerful.<br/>
<i><b>4.2.5</b></i><br/>
<i><b>More examples: /etc/passwd</b></i><br/>
Let’s look at a few more examples of real-world data munging tasks for which you<br/>would use regular expressions. In these examples we will use a well-known standard<br/>UNIX data file as our input data. The file we will use is the /etc/passwd file which<br/>stores a list of users on a UNIX system. The file is a colon-separated, record-based<br/>file. This means that each line in the file represents one user, and the various pieces<br/>of information about each user are separated with a colon. A typical line in one of<br/>these files looks like this:<br/>
dave:Rg6kuZvwIDF.A:501:100:Dave Cross:/home/dave:/bin/bash<br/>
The seven sections of this line have the following meanings:<br/>
1<br/>
The username<br/>
2<br/>
The user’s password (in an encrypted form)9<br/>
3<br/>
The unique ID of the user on this system<br/>
4<br/>
The ID of the user’s default group<br/>
5<br/>
The user’s full name10<br/>
6<br/>
The path to the user’s home directory<br/>
7<br/>
The user’s command shell<br/>
9 On a system using shadow passwords, the encrypted password won’t be in this field.<br/>10 Strictly, this field can contain any text that the system administrator chooses—but this is my system and<br/>
I’ve chosen to store full names here.<br/>
<hr/>
<a name=94></a><b>74</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
The precise meaning of some of these fields may not be clear to non-UNIX users,<br/>
but it should be clear enough to understand the following examples.<br/>
<i><b>Example: reading /etc/passwd<br/></b></i>Let’s start by writing a routine to read the data into internal data structures. This<br/>routine can then be used by any of the following examples. As always, for flexibility,<br/>we’ll assume that the data is coming in via STDIN.<br/>
sub read_passwd {<br/>
my %users;<br/>
my @fields = qw/name pword uid gid fullname home shell/;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my %rec;<br/>
@rec{@fields) = split(/:/);<br/>
$users{$rec-&gt;{name}} = \%rec;<br/>
}<br/>
return \%users;<br/>
}<br/>
In a similar manner to other input routines we have written, this routine reads the<br/>data into a data structure and returns a reference to that data structure. In this case<br/>we have chosen a hash as the main data structure, as the users on the system have no<br/>implicit ordering and it seems quite likely that we will want to get the information<br/>on a specific user. A hash allows us to do this very easily. This raises one other issue:<br/>what is the best choice for the key of the hash? The answer depends on just what we<br/>are planning to do with the data, but in this case I have chosen the username. In<br/>other cases the user ID might be a useful choice. All of the other columns would be<br/>bad choices, as they aren’t guaranteed to be unique across all users.11<br/>
So, we have decided on a hash where the keys are the usernames. What will the<br/>
values of our hash be? In this case I have chosen to use another level of hash where<br/>the keys are the names of the various data values (as defined in the array @fields)<br/>and the values are the actual values.<br/>
Our input routine therefore reads each line from STDIN and splits it on colons<br/>
and puts the values directly into a hash called %rec. A reference to %rec is then<br/>stored in the main %users hash. Notice that because %rec is a lexical variable that is<br/>scoped to within the while loop, each time around the loop we get a new variable<br/>
11 It seems unlikely that the home directory of a user would be nonunique, but it is (just) possible to imag-<br/>
ine scenarios where it makes sense for two or more users to share a home directory.<br/>
<hr/>
<a name=95></a><i><b>Regular expressions</b></i><br/>
<b>75</b><br/>
and therefore a new reference. If %rec were declared outside the loop it would<br/>always be the same variable and every time around the loop we would be overwrit-<br/>ing the same location in memory.<br/>
Having created a hash for each line in the input file and assigned it to the correct<br/>
record in %users, our routine finally returns a reference to %users. We are now<br/>ready to start doing some real work.<br/>
<i><b>Example: listing users<br/></b></i>To start with, let’s produce a list of all of the real names of all of the users on the<br/>system. As that would be a little too simple we’ll introduce a couple of refinements.<br/>First, included in the list of users in /etc/passwd are a number of special accounts<br/>that aren’t for real users. These will include root (the superuser), lp (a user ID<br/>which is often used to carry out printer administration tasks) and a number of other<br/>task-oriented users. Assuming that we can detect these uses by the fact that their full<br/>names will be empty, we’ll exclude them from the output. Secondly, in the original<br/>file, the full names are in the format &lt;forename&gt; &lt;surname&gt;. We’ll print them out<br/>as &lt;surname&gt;, &lt;forename&gt;, and sort them in surname order. Here’s the script:<br/>
1: use strict;<br/>
2:<br/>
3: my $users = read_passwd();<br/>
4:<br/>
5: my @names;<br/>
6: foreach (keys %{$users}) {<br/>
7:<br/>
next unless $users-&gt;{$_}{fullname};<br/>
8:<br/>
9:<br/>
my ($forename, $surname) = split(/\s+/, $users-&gt;{$_}{fullname}, 2);<br/>
10:<br/>
11:<br/>
push @names, &#34;$surname, $forename&#34;;<br/>
12: }<br/>
13:<br/>
14: print map { &#34;$_\n&#34; } sort @names;<br/>
Most of this script is self-explanatory. The key lines are:<br/>
Line 6 gets each key in the %users hash in turn.<br/>Line 7 skips any record that doesn’t have a full name, thereby ignoring the spe-<br/>
cial users.<br/>
Line 9 splits the full name on white space. Note that we pass a third argument to<br/>
split.12 This limits the number of elements in the returned list.<br/>
12 Notice, however, that we are making assumptions here about the format of the name. This algorithm<br/>
assumes that the first word in the name is the forename and everything else is the surname. If the name is<br/>not in this format then things will go wrong. For example, think about what would happen if the name<br/>were “Dame Elizabeth Taylor” or “Randal L. Schwartz.” As always, it is very important to know your data.<br/>
<hr/>
<a name=96></a><b>76</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
Line 11 builds the reversed name and pushes it onto another array.<br/>Line 14 prints the array of names in sorted order.<br/>
<i><b>Example: listing particular users<br/></b></i>Now suppose we want to get a report on the users that use the Bourne shell (/bin/<br/>sh). Maybe we want to email them to suggest that they use bash instead. We might<br/>write something like this:<br/>
1: use strict;<br/>
2:<br/>
3: my $users = read_passwd();<br/>
4:<br/>
6: foreach (keys %{$users}) {<br/>
7:<br/>
print &#34;$_\n&#34; if $users-&gt;{$_}{shell} eq '/bin/sh';<br/>
8: }<br/>
Again we have a very simple script. Most of the real work is being done on line 7.<br/>This line checks the value in $users-&gt;{$_}{shell} against the string “/bin/sh”,<br/>and if it matches it prints out the current key (which is the username). Notice that<br/>we could also have chosen to match against a regular expression using the code<br/>
print &#34;$_\n&#34; if $users-&gt;{$_}{shell} =~ m|^/bin/sh$|<br/>
If performance is important to you, then you could benchmark the two solutions<br/>and choose the faster one. Otherwise the solution you choose is a matter of per-<br/>sonal preference.<br/>
<i><b>4.2.6</b></i><br/>
<i><b>Taking it to extremes</b></i><br/>
Of course, using regular expressions for transforming data is a very powerful technique<br/>and, like all powerful techniques, it is open to abuse. As an example of what you can do<br/>with this technique, let’s take a brief look at the Text::Bastardize module which is<br/>available from the CPAN at http://search.cpan.org/search?dist=Text-Bastardize.<br/>
This module will take an innocent piece of text and will abuse it in various<br/>
increasingly bizarre ways. The complete set of transformations available in the cur-<br/>rent version (0.06 as of the time of writing) is as follows:<br/>
■<br/>
rdct—Converts the text to hyperreductionist English. This removes vowels<br/>within words, changes “you” to “u” and “are” to “r” and carries out a num-<br/>ber of other conversions.<br/>
■<br/>
pig—Converts the text to Pig Latin. Pig Latin is a bizarre corruption of<br/>English in which the first syllable of a word is moved to the end of the word<br/>and the sound “ay” is appended.<br/>
■<br/>
k3wlt0k—Converts the text to “cool-talk” as used by certain denizens of the<br/>Internet (the d00dz who deal in k3wl war3z).<br/>
<hr/>
<a name=97></a><i><b>Further information</b></i><br/>
<b>77</b><br/>
■<br/>
rot13—Applies rot13 “encryption” to the text. In this very basic type of<br/>encryption, each letter is replaced with one that is thirteen letters past it in<br/>the alphabet. This method is often used in newsgroup posts to disguise<br/>potential plot spoilers or material which might give offense to casual readers.<br/>
■<br/>
rev—Reverses the order of the letters in the text.<br/>
■<br/>
censor—Censors text which might be thought inappropriate. It does this by<br/>replacing some of the vowels with asterisks.<br/>
■<br/>
n20e—Performs numerical abbreviations on the text. Words over six letters<br/>in length have all but their first and last letters removed and replaced with a<br/>number indicating the number of letters removed.<br/>
It is, of course, unlikely that this module is ever used as anything other than an<br/>
example of a text transformation tool, but it is a very good example of one and it<br/>can be very instructive to look at the code of the module.<br/>
As an example of the use of the module, here is a script that performs all of the<br/>
transformations in turn on a piece of text that is read from STDIN. Notice that the<br/>piece of text that is to be transformed is set using the charge function.<br/>
#!/usr/perl/bin/perl -w<br/>
use strict;<br/>
use Text::Bastardize;<br/>
my $text = Text::Bastardize-&gt;new;<br/>
print 'Say something: ';<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
$text-&gt;charge($_);<br/>
foreach my $xfm (qw/rdct pig k3wlt0k rot13 rev censor n20e/) {<br/>
print &#34;$xfm: &#34;;<br/>
print eval &#34;\$text-&gt;$xfm&#34;;<br/>
print &#34;\n&#34;;<br/>
}<br/>
}<br/>
<i><b>4.3</b></i><br/>
<i><b>Further information</b></i><br/>
The best place to obtain definitive information about regular expressions is from<br/>the perlre manual page that comes with every installation of Perl. You can access<br/>this by typing<br/>
perldoc perlre<br/>
on your command line.<br/>
<hr/>
<a name=98></a><b>78</b><br/>
CHAPTER <br/>
<i><b>Pattern matching</b></i><br/>
You can get more information than you will ever need from <i>Mastering Regular</i><br/>
<i>Expressions</i>, by Jeffrey Friedl (O’Reilly).<br/>
<i><b>4.4</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
Perl has very powerful text matching and processing facilities.<br/>
■<br/>
Often you can achieve what you want using basic text-processing functions<br/>such as substr, index, and uc.<br/>
■<br/>
Regular expressions are a more powerful method of describing text that you<br/>want to match.<br/>
■<br/>
Regular expressions are most often used in the text matching (m//) and text<br/>substitution (s///) operators.<br/>
<hr/>
<a name=99></a><i>Part II</i><br/>
<i>Data munging</i><br/>
In which our heroes first come into contact with the data munging<br/>
beast. Three times they battle it, and each time the beast takes on a dif-<br/>ferent form. <br/>
At first the beast appears without structure and our heroes fight val-<br/>
iantly to impose structure upon it. They learn new techniques for find-<br/>ing hidden structure and emerge triumphant.<br/>
The second time the beast appears structured into records. Our<br/>
heroes find many ways to split the records apart and recombine them in<br/>other useful ways. <br/>
The third time the beast appears in even more strongly structured<br/>
forms. Once again our heroes discover enough new techniques to see<br/>through all of their enemies’ disguises.<br/>
Our heroes end this section of the tale believing that they can handle<br/>
the beast in all of its guises, but disappointment is soon to follow. <br/>
<hr/>
<a name=100></a><hr/>
<a name=101></a><img class="yflip" src="dmp-101_1.jpg"/><br/>
<i>Unstr</i><br/>
<i>5</i><br/>
<i>uctured data</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Reading an ASCII file<br/>
■<br/>
Producing text statistics<br/>
■<br/>
Performing format conversions<br/>
■<br/>
Reformatting numbers<br/>
<i>81</i><br/>
<hr/>
<a name=102></a><b>82</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
The simplest kind of data that can require munging is unstructured data. This is<br/>data that has no internal structure imposed on it in any way. In some ways this is the<br/>most difficult data to deal with as there is often very little that you can do with it.<br/>
A good example of unstructured data is a plain ASCII file that contains text. In<br/>
this chapter we will look at some of the things that we can do with a file like this.<br/>
<i><b>5.1</b></i><br/>
<i><b>ASCII text files</b></i><br/>
An ASCII text file contains data that is readable by a person. It can be created in a<br/>text editor like vi or emacs in UNIX, Notepad in Windows, or edit in DOS. You<br/>should note that the files created by most word processors are not ASCII text, but<br/>some proprietary text format.1 It is also possible that the file could be created by<br/>some other computer system.<br/>
An ASCII text file, like all data files, is nothing but a series of bytes of binary data.<br/>
It is only the software that you use to view the file (an editor perhaps) that inter-<br/>prets the different bytes of data as ASCII characters.<br/>
<i><b>5.1.1</b></i><br/>
<i><b>Reading the file</b></i><br/>
One of the simplest things that we can do with an ASCII file is to read it into a data<br/>structure for later manipulation. The most suitable format for the data structure<br/>depends, of course, on the exact nature of the data in the file and what you are plan-<br/>ning to do with it, but for readable text an array of lines will probably be the most<br/>appropriate structure. If you are interested in the individual words in each line then<br/>it will probably make sense to split each line into an array of words. Notice that<br/>because order is important when reading text we use Perl arrays (which are also<br/>ordered) to store the data, rather than hashes (which are unordered).<br/>
<i><b>Example: Reading text into an array of arrays<br/></b></i>Let’s write an input routine that will read an unstructured text file into an array of<br/>arrays. As always we will assume that the file is coming to us via STDIN.<br/>
1: sub read_text {<br/>
2:<br/>
3:<br/>
my @file;<br/>
4:<br/>
5:<br/>
push @file, [split] while &lt;STDIN&gt;;<br/>
6:<br/>
7:<br/>
return \@file;<br/>
8: }<br/>
1 Most word processors do have a facility to save the document in ASCII text format; however, this will de-<br/>
stroy most of the formatting of the document.<br/>
<hr/>
<a name=103></a><i><b>ASCII text files</b></i><br/>
<b>83</b><br/>
Let’s look at this line by line.<br/>
Line 3 defines a variable that will contain the array of lines. Each element of this<br/>
array will be a reference to another array. Each element of these second-level arrays<br/>will contain one of the words from the line.<br/>
Line 5 does most of the work. It might be easier to follow if you read it in<br/>
reverse. It is actually a contraction of code that, when expanded, looks something<br/>like this:<br/>
while (&lt;STDIN&gt;) {<br/>
my @line = split(/\s+/, $_);<br/>
push @file, [@line];<br/>
}<br/>
which may be a little easier to follow. For each line in the file, we split the line wher-<br/>ever we see one or more white space characters. We then create an anonymous array<br/>which is a copy of the array returned by split and push the reference returned by the<br/>anonymous array constructor onto an @file.<br/>
Also implicit in this line is our definition of a word. In this case we are using<br/>
Perl’s built-in \s character class to define our word separators as white space charac-<br/>ters (recall that split uses \s+ as the delimiter by default). Your application may<br/>require something a little more complicated.<br/>
Line 7 returns a reference to the array.<br/>Our new function can be called like this:<br/>
my $file = read_text;<br/>
and we can then access any line of the file using<br/>
my $line = $file-&gt;[$x];<br/>
where $x contains the number of the line that we are interested in. After this call,<br/>$line will contain a reference to the line array. We can, therefore, access any given<br/>word using<br/>
my $word = $line-&gt;[$y];<br/>
or, from the original $file reference:<br/>
my $word = $file-&gt;[$x][$y];<br/>
Of course, all of this is only a very good idea if your text file is of a reasonable size, as<br/>attempting to store the entire text of “War and Peace” in memory may cause your<br/>computer to start swapping memory to disk, which will slow down your program.2<br/>
2 Then again, if you have enough memory that you can store the entire text of <i>War and Peace</i> in it without<br/>
swapping to disk, that would be the most efficient way to process it.<br/>
<hr/>
<a name=104></a><b>84</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
<i><b>Finer control of input<br/></b></i>If you are, however, planning to store all of the text in memory then there are a<br/>couple of tricks that might be of use to you. If you want to read the file into an<br/>array of lines without splitting the lines into individual words, then you can do it in<br/>one line like this:<br/>
my @file = &lt;FILE&gt;;<br/>
If, on the other hand, you want the whole text to be stored in one scalar variable<br/>then you should look at the $/ variable. This variable is the input record separator<br/>and its default value is a newline character. This means that, by default, data read<br/>from a &lt;&gt; operator will be read until a newline is encountered. Setting this variable<br/>to undef will read the whole input stream in one go.3 You can, therefore, read in a<br/>whole file by doing this<br/>
local $/ = undef;<br/>
my $file = &lt;FILE&gt;;<br/>
You can set $/ to any value that your program will find useful. Another value that is<br/>often used is an empty string. This puts Perl into paragraph mode where a blank<br/>line is used as the input delimiter.<br/>
If your file is too large to fit efficiently into memory then you are going to have<br/>
to process a row at a time (or a record at a time if you have changed $/). We will<br/>look at line-based and record-based data in the next chapter, but for the rest of this<br/>chapter we will assume that we can get the whole file in memory at one time.<br/>
<i><b>5.1.2</b></i><br/>
<i><b>Text transformations</b></i><br/>
Having read the file into our data structures, the simplest thing to do is to trans-<br/>form part of the data using the simple regular expression techniques that we dis-<br/>cussed in the last chapter. In this case the lines or individual words of the data are<br/>largely irrelevant to us, and our lives become much easier if we read the whole file<br/>into a scalar variable. <br/>
<i><b>Example: simple text replacement<br/></b></i>For example, if we have a text file where we want to convert all instances of “Win-<br/>dows” to “Linux”, we can write a short script like this:<br/>
my $file;<br/>
{<br/>
local $/ = undef;<br/>
3 Note that $/ (like most Perl internal variables) is, by default, global, so altering it in one place will affect<br/>
your whole program. For that reason, it is usually a good idea to use local and enclosing braces to ensure<br/>that any changes have a strictly limited scope.<br/>
<hr/>
<a name=105></a><i><b>ASCII text files</b></i><br/>
<b>85</b><br/>
$file = &lt;STDIN&gt;;<br/>
}<br/>
$file =~ s/Windows/Linux/g;<br/>
print $file;<br/>
Notice how the section that reads the data has been wrapped in a bare block in<br/>order to provide a limited scope for the local copy of the $/ variable. Also, we have<br/>used the g modifier on the substitution command in order to change all occur-<br/>rences of Windows.<br/>
All of the power of regular expression substitutions is available to us. It would be<br/>
simple to rewrite our translation program from the previous chapter to translate the<br/>whole input file in one operation.<br/>
<i><b>5.1.3</b></i><br/>
<i><b>Text statistics</b></i><br/>
One of the useful things that we can do is to produce statistics on the text file. It is<br/>simple to produce information on the number of lines or words in a file. It is only a<br/>little harder to find the longest word or to produce a table that counts the occur-<br/>rences of each word. In the following examples we will assume that a file is read in<br/>using the read_text function that we defined earlier in the chapter. This function<br/>returns a reference to an array of arrays. We will produce a script that counts the<br/>lines and words in a file and then reports on the lengths of words and the most-used<br/>words in the text.<br/>
<i><b>Example: producing text statistics</b></i><br/>
1: # Variables to keep track of where we are in the file<br/>
2: my ($line, $word);<br/>
3:<br/>
4: # Variables to store stats<br/>
5: my ($num_lines, $num_words);<br/>
6: my (%words, %lengths);<br/>
7:<br/>
8: my $text = read_text();<br/>
9:<br/>
10: $num_lines = scalar @{$text};<br/>
11:<br/>
12: foreach $line (@{$text}) {<br/>
13:<br/>
$num_words += scalar @{$line};<br/>
14:<br/>
15:<br/>
foreach $word (@{$line}) {<br/>
16:<br/>
$words{$word}++;<br/>
17:<br/>
$lengths{length $word}++;<br/>
18:<br/>
}<br/>
19: }<br/>
20:<br/>
<hr/>
<a name=106></a><b>86</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
21: my @sorted_words = sort { $words{$b} &lt;=&gt; $words{$a} } keys %words;<br/>
22: my @sorted_lengths = sort { $lengths{$b} &lt;=&gt; $lengths{$a} } keys %lengths;<br/>
23:<br/>
24: print &#34;Your file contains $num_lines lines &#34;;<br/>
25: print &#34;and $num_words words\n\n&#34;;<br/>
26:<br/>
27: print &#34;The 5 most popular words were:\n&#34;;<br/>
28: print map { &#34;$_ ($words{$_} times)\n&#34; } @sorted_words[0 .. 4];<br/>
29:<br/>
30: print &#34;\nThe 5 most popular word lengths were:\n&#34;;<br/>
31: print map { &#34;$_ ($lengths{$_} words)\n&#34; } @sorted_lengths[0 .. 4];<br/>
Line 2 declares two variables that we will use to keep track of where we are in the file.<br/>
Lines 5 and 6 declare four variables that we will use to produce the statistics.<br/>
$num_lines and $num_words are the numbers of lines and words in the file.<br/>%words is a hash that will keep a count of the number of times each word has<br/>occurred in the file. Its key will be the word and its value will be the number of<br/>times the word has been seen. %lengths is a hash that keeps count of the frequency<br/>of word lengths in a similar fashion.<br/>
Line 8 calls our read_text function to get the contents of the file.<br/>Line 10 calculates the number of lines in the file. This is simply the number of<br/>
elements in the $text array.<br/>
Line 12 starts to loop around each line in the array.<br/>Line 13 increases the $num_words variable with the number of elements in the<br/>
$line array. This is equal to the number of words in the line.<br/>
Line 15 starts to loop around the words on the line.<br/>Lines 16 and 17 increment the relevant entries in the two hashes.<br/>Lines 21 and 22 create two arrays which contain the keys of the %words and<br/>
%lengths hashes, sorted in the order of decreasing hash values.<br/>
Lines 24 and 25 print out the total number of words and lines in the file.<br/>Lines 27 and 28 print out the five most popular words in the file by taking the<br/>
first five elements in the @sorted_words array and printing the value associated<br/>with that key in the %words hash. Lines 30 and 31 do the same thing for the<br/>@sorted_lengths array.<br/>
<i><b>Example: calculating average word length<br/></b></i>As a final example of producing text file statistics, let’s calculate the average word<br/>length in the files. Once again we will use the existing read_text function to read<br/>in our text.<br/>
my ($total_length, $num_words);<br/>
my $text = read_text();<br/>
<hr/>
<a name=107></a><i><b>Data conversions</b></i><br/>
<b>87</b><br/>
my ($word, $line);<br/>
foreach $line (@{$text}) {<br/>
$num_words += scalar @{$line};<br/>
foreach $word (@{$line}) {<br/>
$total_length += length $word;<br/>
}<br/>
}<br/>
printf &#34;The average word length is %.2f\n&#34;, $total_length / $num_words;<br/>
<i><b>5.2</b></i><br/>
<i><b>Data conversions</b></i><br/>
One of the most useful things that you might want to do to unstructured data is to<br/>perform simple data format conversions on it. In this section we’ll take a look at<br/>three typical types of conversions that you might need to do.<br/>
<i><b>5.2.1</b></i><br/>
<i><b>Converting the character set</b></i><br/>
Most textual data that you will come across will be in ASCII, but there may well be<br/>occasions when you have to deal with other character sets. If you are exchanging<br/>data with IBM mainframe systems then you will often have to convert data to and<br/>from EBCDIC. You may also come across multibyte characters if you are dealing with<br/>data from a country where these characters are commonplace (like China or Japan).<br/>
<i><b>Unicode<br/></b></i>For multibyte characters, Perl version 5.6 includes some support for Unicode via<br/>the new utf8 module. This was introduced in order to make it easier to work with<br/>XML using Perl (XML uses Unicode in UTF-8 format to define all of its character<br/>data). If you have an older version of Perl you may find the Unicode::Map8 and<br/>Unicode::String modules to be interesting.<br/>
<i><b>Converting between ASCII and EBCDIC<br/></b></i>For converting between ASCII and EBCDIC you can use the Convert::EBCDIC<br/>module from the CPAN. This module can be used either as an object or as a traditional<br/>module. As a traditional module, it exports two functions called ascii2ebcdic and<br/>ebcdic2ascii. Note that these functions need to be explicitly imported into your<br/>namespace. As an object, it has two methods called toascii and toebcdic. The fol-<br/>lowing example uses the traditional method to convert the ASCII data arriving on<br/>STDIN into EBCDIC.<br/>
use strict;<br/>
use Convert::EBCDIC qw/ascii2ebcdic/;<br/>
my $data;<br/>
<hr/>
<a name=108></a><b>88</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
{<br/>
local $/ = undef;<br/>
$data = &lt;STDIN&gt;;<br/>
}<br/>
print ascii2ebcdic($data);<br/>
The second example uses the object interface to convert EBCDIC data to ASCII.<br/>
use strict;<br/>
use Convert::EBCDIC;<br/>
my $data;<br/>
my $conv = Convert::EBCDIC-&gt;new;<br/>
my $data;<br/>
{<br/>
local $/ = undef;<br/>
$data = &lt;STDIN&gt;;<br/>
}<br/>
print $conv-&gt;toascii($data);<br/>
The Convert::EBCDIC constructor takes one optional parameter which is a 256<br/>character string which defines a translation table.<br/>
<i><b>5.2.2</b></i><br/>
<i><b>Converting line endings</b></i><br/>
As I mentioned above, an ASCII text file is no more than a stream of binary data. It<br/>is only the software that we use to process it that interprets the data in such a way<br/>that it produces lines of text. One important character (or sequence of characters)<br/>in a text file is the character which separates different lines of text. When, for exam-<br/>ple, a text editor reaches this character in a file, it will know that the following char-<br/>acters must be displayed starting at the first column of the following line of the<br/>user’s display.<br/>
<i><b>Different line end characters<br/></b></i>Over the years, two characters in particular have come to be the most commonly<br/>used line end characters. They are the characters with the ASCII codes 10 (line feed)<br/>and 13 (carriage return). The line feed is used by UNIX (and Linux) systems. Apple<br/>Macintoshes use the carriage return. DOS and Windows use a combination of both<br/>characters, the carriage return followed by the line feed.<br/>
This difference in line endings causes no problems when data files are used on the<br/>
same system on which they were created, but when you start to transfer data files<br/>between different systems it can lead to some confusion. You may have edited a file<br/>that was created under Windows in a UNIX text editor. If so you will have seen an<br/>
<hr/>
<a name=109></a><i><b>Data conversions</b></i><br/>
<b>89</b><br/>
extra ^M character at the end of each line of text.4 This is the printable equivalent of<br/>the carriage return character that Windows inserts before each line feed. Similarly, a<br/>UNIX text file opened in Windows Notepad will have no carriage returns before the<br/>line feed and, therefore, Notepad will not recognize the end of line character<br/>sequence. All the lines will subsequently be run together, separated only by a black<br/>rectangle, which is Windows’ way of representing the unprintable line feed character.<br/>
There are ways to avoid this problem. Transferring files between systems using<br/>
FTP in ASCII mode, for example, will automatically convert the line endings into<br/>the appropriate form. It is almost guaranteed, however, that at some point you will<br/>find yourself dealing with a data file that has incorrect line endings for your system.<br/>Perl is, of course, the perfect language for correcting this problem. <br/>
<i><b>Example: a simple line end conversion filter<br/></b></i>The following program can be used as a filter to clean up problem files. It takes two<br/>parameters, which are the line endings on the source and target systems. These are<br/>the strings CR, LF, or CRLF.<br/>
In the program, instead of using \n and \r we use the ASCII control character<br/>
sequences \cM and \cJ (Ctrl-M and Ctrl-J). This is because Perl is cleverer than we<br/>might like it to be in this case. Whenever Perl sees a \n sequence in a program it<br/>actually converts it to the correct end-of-line character sequence for the current sys-<br/>tem. This is very useful most of the time (it means, for example, that you don’t<br/>need to use print &#34;some text\r\n&#34;; to output text when using Perl on a Win-<br/>dows system). But in this situation it masks the very problem that we’re trying to<br/>solve—so we have to go to a lower level representation of the characters.<br/>
#!/usr/local/bin/perl -w<br/>
use strict;<br/>
(@ARGV == 2) or die &#34;Error: source and target formats not given.&#34;;<br/>
my ($src, $tgt) = @ARGV;<br/>
my %conv = (CR =&gt;<br/>
&#34;\cM&#34;,<br/>
LF =&gt;<br/>
&#34;\cJ&#34;,<br/>
CRLF =&gt; &#34;\cM\cJ&#34;);<br/>
$src = $conv{$src};<br/>
$tgt = $conv{$tgt};<br/>
$/ = $src;<br/>
while (&lt;STDIN&gt;) {<br/>
4 This is becoming less common as many editors will now display the lines without the ^M, and indicate the<br/>
newline style in the status line.<br/>
<hr/>
<a name=110></a><b>90</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
s/$src/$tgt/go;<br/>
print;<br/>
}<br/>
Notice that we use the o modifier on the substitution as we know that the source<br/>will not change during the execution of the while loop.<br/>
<i><b>5.2.3</b></i><br/>
<i><b>Converting number formats</b></i><br/>
Sometimes the unstructured data that you receive will contain numerical data and<br/>the only changes that you will want to make are to reformat the numbers into a<br/>standardized format. This breaks down into two processes. First you have to recog-<br/>nize the numbers you are interested in, then you need to reformat them.<br/>
<i><b>Recognizing numbers<br/></b></i>How do you recognize a number? The answer depends on what sort of numbers<br/>you are dealing with. Are they integers or floating points? Can they be negative? Do<br/>you accept exponential notation (such as 1E6 for 1 × 106)? When you answer<br/>these questions, you can build a regular expression that matches the particular type<br/>of number that you need to process.<br/>
To match natural numbers (i.e., positive integers) you can use a simple regular<br/>
expression such as:<br/>
/\d+/<br/>
To match integers (with optional +/- signs) use<br/>
/[-+]?\d+/<br/>
To match a floating point number use<br/>
/[-+]?(\d+(\.\d*)?|\.\d+)/<br/>
To match a number that can optionally be in exponential notation, use<br/>
/[-+]?(?=\d|\.\d)\d*(\.\d*)?([eE]([-+]?\d+))?/<br/>
As these become rather complex, it might be a suitable time to consider using Perl’s<br/>precompiled regular expression feature and creating your number-matching regular<br/>expressions in advance. You can do something like this:<br/>
my $num_re = qr/[-+]?(?=\d|\.\d)\d*(\.\d*)?([eE]([-+]?\d+))?/;<br/>
my @nums;<br/>
while ($data =~ /$num_re/g) {<br/>
push @nums, $1;<br/>
}<br/>
to print out a list of all of the numbers in $data.<br/>
<hr/>
<a name=111></a><i><b>Data conversions</b></i><br/>
<b>91</b><br/>
If you have a function, reformat, that will change the numbers into your pre-<br/>
ferred format then you can use code like this:<br/>
$data =~ s/$num_re/reformat($1)/ge;<br/>
which makes use, once more, of the e modifier to execute the replacement string<br/>before using it.<br/>
<i><b>Reformatting numbers with sprintf<br/></b></i>The simplest way to reformat a number is to pass it through sprintf. This will<br/>enable you to do things like fix the number of decimal places, pad the start of the<br/>number with spaces or zeroes, and right or left align the number within its field.<br/>Here is an example of the sort of things that you can do:<br/>
my $number = 123.456789;<br/>
my @fmts = ('0.2f', '.2f', '10.4f', '-10.4f');<br/>
foreach (@fmts) {<br/>
my $fmt = sprintf &#34;%$_&#34;, $number;<br/>
print &#34;$_: [$fmt]\n&#34;;<br/>
}<br/>
which gives the following output:<br/>
<b>0.2f: [123.46]</b><br/>
<b>.2f: [123.46]</b><br/>
<b>10.4f: [</b><br/>
<b>123.4568]</b><br/>
<b>-10.4f: [123.4568</b><br/>
<b>]</b><br/>
(The brackets are there to show the exact start and end of each output field.)<br/>
<i><b>Reformatting numbers with CPAN modules<br/></b></i>There are, however, a couple of modules available on the CPAN which allow you<br/>to do far more sophisticated formatting of numbers. They are Convert::SciEng<br/>and Number::Format.<br/>
<i><b>Convert::SciEng</b></i><br/>
Convert::SciEng is a module for converting numbers to and from a format in<br/>which they have a postfix letter indicating the magnitude of the number. This con-<br/>version is called <i>fixing</i> and <i>unfixing</i> the number. The module recognizes two<br/>different schemes of fixes, the SI scheme and the SPICE scheme. The module inter-<br/>face is via an object interface. A new object is created by calling the class new method<br/>and passing it a string indicating which fix scheme you want to use (SI or SPICE).<br/>
my $conv = Convert::SciEng-&gt;new('SI');<br/>
You can then start fixing and unfixing numbers. The following:<br/>
<hr/>
<a name=112></a><b>92</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
print $conv-&gt;unfix('2.34u');<br/>
will print the value 2.34e-06. The “u” is taken to mean the SI symbol for microunits.<br/>
You can also pass an array to unfix, as in<br/>
print map { &#34;$_\n&#34; } $conv-&gt;unfix(qw/1P 1T 1G 1M 1K 1 1m 1u 1p 1f 1a/);<br/>
which will produce the output<br/>
<b>1e+015</b><br/>
<b>1000000000000</b><br/>
<b>1000000000</b><br/>
<b>1000000</b><br/>
<b>1000</b><br/>
<b>1</b><br/>
<b>0.001</b><br/>
<b>1e-006</b><br/>
<b>1e-012</b><br/>
<b>1e-015</b><br/>
<b>1e-018</b><br/>
(and also demonstrates the complete range of postfixes understood by the SI scheme).<br/>
You can also adjust the format in which the results are returned in by using the<br/>
format method and passing it a new format string. The format string is simply a<br/>string that will be passed to sprintf whenever a value is required. The default for-<br/>mat is %5.5g.<br/>
There is, of course, also a fix method that takes a number and returns a value<br/>
with the correct postfix letter appended:<br/>
print $conv-&gt;fix(100_000)<br/>
prints “100K” and<br/>
print $conv-&gt;fix(1_000_000)<br/>
prints “1M”.<br/>
<i><b>Number::Format<br/></b></i>The Number::Format module is a more general-purpose module for formatting<br/>numbers in interesting ways. Like Convert::SciEng, it is accessed through an<br/>object-oriented interface. Calling the new method creates a new formatter object.<br/>This method takes as its argument a hash which contains various formatting<br/>options. These options are detailed in appendix A along with the other object<br/>methods contained within Number::Format.<br/>
Here are some examples of using this module:<br/>
my $fmt = Number::Format-&gt;new; # use all defaults<br/>
my $number = 1234567.890;<br/>
<hr/>
<a name=113></a><i><b>Data conversions</b></i><br/>
<b>93</b><br/>
print $fmt-&gt;round($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_number($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_negative($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_picture($number, '###########'), &#34;\n&#34;;<br/>
print $fmt-&gt;format_price($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_bytes($number), &#34;\n&#34;;<br/>
print $fmt-&gt;unformat_number('1,000,000.00'), &#34;\n&#34;;<br/>
This results in:<br/>
<b>1234567.89</b><br/>
<b>1,234,567.89</b><br/>
<b>-1234567.89</b><br/>
<b>1234568</b><br/>
<b>USD 1,234,567.89</b><br/>
<b>1.18M</b><br/>
<b>1000000</b><br/>
Changing the formatting options slightly:<br/>
my $fmt = Number::Format-&gt;new(INTL_CURRENCY_SYMBOL =&gt; 'GBP',<br/>
DECIMAL_DIGITS =&gt; 1);<br/>
my $number = 1234567.890;<br/>
print $fmt-&gt;round($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_number($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_negative($number), &#34;\n&#34;;<br/>
print $fmt-&gt;format_picture($number, '###########'), &#34;\n&#34;;<br/>
print $fmt-&gt;format_bytes($number), &#34;\n&#34;;<br/>
print $fmt-&gt;unformat_number('1,000,000.00'), &#34;\n&#34;;<br/>
results in:<br/>
<b>1234567.9</b><br/>
<b>1,234,567.9</b><br/>
<b>-1234567.89</b><br/>
<b>1234568</b><br/>
<b>GBP 1,234,567.89</b><br/>
<b>1.18M</b><br/>
<b>1000000</b><br/>
If we were formatting numbers for a German system, we might try something like this:<br/>
my $de = Number::Format-&gt;new(INT_CURR_SYMBOL =&gt; 'DEM ',<br/>
THOUSANDS_SEP =&gt; '.',<br/>
DECIMAL_POINT =&gt; ',');<br/>
my $number = 1234567.890;<br/>
print $de-&gt;format_number($number), &#34;\n&#34;;<br/>
print $de-&gt;format_negative($number), &#34;\n&#34;;<br/>
print $de-&gt;format_price($number), &#34;\n&#34;;<br/>
which would result in:<br/>
<hr/>
<a name=114></a><b>94</b><br/>
CHAPTER <br/>
<i><b>Unstructured data</b></i><br/>
<b>1.234.567,89</b><br/>
<b>-1234567.89</b><br/>
<b>DEM 1.234.567,89</b><br/>
And finally, if we were accountants, we might want to do something like this:<br/>
my $fmt = Number::Format-&gt;new(NEG_FORMAT=&gt; '(x)');<br/>
my $debt = -12345678.90;<br/>
print $fmt-&gt;format_negative($debt);<br/>
which would give us:<br/>
<b>(12345678.90)</b><br/>
It is, of course, possible to combine Number::Format with some of the other tech-<br/>niques that we were using earlier. If we had a text document that contained num-<br/>bers in different formats and we wanted to ensure that they were all in our standard<br/>format we could do it like this:<br/>
use Number::Format;<br/>
my $data;<br/>
{<br/>
local $/ = undef;<br/>
$data = &lt;STDIN&gt;;<br/>
}<br/>
my $fmt = Number::Format-&gt;new;<br/>
my $num_re = qr/[-+]?(?=\d|\.\d)\d*(\.\d*)?([eE]([-+]?\d+))?/;<br/>
$data =~ s/$num_re/$fmt-&gt;format_number($1)/ge;<br/>
print $data;<br/>
<i><b>5.3</b></i><br/>
<i><b>Further information</b></i><br/>
For more information about input control variables such as $/, see the perldoc<br/>perlvar manual pages.<br/>
For more information about the Unicode support in Perl, see the perldoc<br/>
perlunicode and perldoc utf8 manual pages.<br/>
For more information about sprintf, see the perldoc -f sprintf manual page.<br/>Both Convert::SciEng and Number::Format can be found on the CPAN.<br/>
Once you have installed them, their documentation will be available using the<br/>perldoc command.<br/>
<hr/>
<a name=115></a><i><b>Summary</b></i><br/>
<b>95</b><br/>
<i><b>5.4</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
Most unstructured data is found in ASCII text files.<br/>
■<br/>
Perl can be used to extract statistics from text files very easily.<br/>
■<br/>
Many useful data format conversions can be carried out either using the stan-<br/>dard Perl distribution or with the addition of modules from the CPAN.<br/>
<hr/>
<a name=116></a><img class="yflip" src="dmp-116_1.jpg"/><br/>
<i>Recor</i><br/>
<i>6</i><br/>
<i>d-oriented data</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Reading, writing, and processing simple <br/>record-oriented data<br/>
■<br/>
Caching data<br/>
■<br/>
Currency conversion<br/>
■<br/>
The comma separated value format<br/>
■<br/>
Creating complex data records<br/>
■<br/>
Problems with date fields <br/>
<i>96</i><br/>
<hr/>
<a name=117></a><i><b>Simple record-oriented data</b></i><br/>
<b>97</b><br/>
A very large proportion of the data that you will come across in data munging tasks<br/>will be record oriented. In this chapter we will take a look at some common ways to<br/>deal with this kind of data. <br/>
<i><b>6.1</b></i><br/>
<i><b>Simple record-oriented data</b></i><br/>
We have already seen examples of simple record-oriented data. The CD data file that<br/>we examined in previous chapters had one line of data for each CD in my collection.<br/>Each of these lines of data is a record. As we will see later, a record can be larger or<br/>smaller than one line, but we will begin by looking in more detail at files where each<br/>line is one record. <br/>
<i><b>6.1.1</b></i><br/>
<i><b>Reading simple record-oriented data</b></i><br/>
Perl makes it very easy to deal with record-oriented data, particularly simple records<br/>of the type we are discussing here. We have seen before the idiom where you can<br/>read a file a line at a time using a construct like<br/>
while (&lt;FILE&gt;) {<br/>
chomp; # remove newline<br/>
# each line in turn is assigned to $_<br/>
}<br/>
Let’s take a closer look and see what Perl is doing here to make life easier.<br/>
The most important part of the construct is the use of &lt;FILE&gt; to read data from<br/>
the file handle FILE which has presumably been assigned to a file earlier in the pro-<br/>gram by a call to the open function. This file input operator can return two differ-<br/>ent results, depending on whether it is used in scalar context or array context.<br/>
When called in a scalar context, the file input operator returns the next record<br/>
from the file handle. This begs the obvious question of what constitutes a record.<br/>The answer is that input records are separated by a sequence of characters called<br/>(logically enough) the input record separator. This value is stored in the variable $/.<br/>The default value is a newline \n (which is translated to the appropriate actual char-<br/>acters for the specific operating system), but this can be altered to any other string of<br/>characters. We will look at this usage in more detail later, but for now the default<br/>value will suffice.<br/>
When called in an array context, the file input operator returns a list in which<br/>
each element is a record from the input file.<br/>
You can, therefore, call the file input operator in one of these two ways:<br/>
my $next_line = &lt;FILE&gt;;<br/>
my @whole_file = &lt;FILE&gt;;<br/>
<hr/>
<a name=118></a><b>98</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
In both of these examples it is important to realize that each record—whether it is<br/>the record stored in $next_line or one of the records in @whole_file—will still<br/>contain the value of $/ at the end.1 Often you will want to get rid of this and the<br/>easiest way to do it is by using the chomp function. chomp is passed either a scalar or<br/>an array and removes the value of $/ from the end of the scalar or each element of<br/>the array. If no argument is passed to chomp then it works on $_.2<br/>
<i><b>Reading data a record at a time (from first principles)<br/></b></i>Now that we understand a little more about the file input operator and chomp, let’s<br/>see if we can build our standard data munging input construct from first principles.<br/>
A first attempt at processing each line in a file might look something like this:<br/>
my $line;<br/>
while ($line = &lt;FILE&gt;) {<br/>
chomp $line;<br/>
…<br/>
}<br/>
This is a good start, but it has a subtle bug in it. The conditional expression in the<br/>while loop is checking for the truth of the scalar variable $line. This variable is set<br/>from the next line taken from FILE. Generally this is fine, but there are certain con-<br/>ditions when a valid line in a file can evaluate to false. The most obvious of these is<br/>when the final line in a file contains the value 0 (zero) and has no end of line char-<br/>acters after it.3 In this case, the variable $line will contain the value 0 which will<br/>evaluate as false and the final line of the file will not be processed.<br/>
Although this bug is a little obscure, it is still worthwhile finding a solution that<br/>
doesn’t exhibit this problem. This is simple enough to do by checking that the line<br/>is defined instead of evaluating to true. The contents of a variable are said to be<br/>defined if they are not the special Perl value undef. Any variable that contains a<br/>value that evaluates to false will still be defined. Whether or not a value is defined<br/>can be tested using the defined function. The file input operator returns undef<br/>when the end of the file is reached. We can therefore rewrite our first attempt into<br/>something like this:<br/>
1 Except, possibly, the last line in the file.<br/>2 In versions of Perl before Perl 5, the chomp function did not exist. Instead we had to use a function called<br/>
chop, which simply removed the last character from a string without checking what it was. As this is still<br/>an occasionally useful thing to do to a string, chop is still available in Perl, but most of the time chomp is<br/>more appropriate.<br/>
3 It would have to the be last line, because for any other line, the existence of the end of line characters<br/>
following the data will ensure that there is enough data in the string for it to evaluate as true.<br/>
<hr/>
<a name=119></a><i><b>Simple record-oriented data</b></i><br/>
<b>99</b><br/>
my $line;<br/>
while (defined($line = &lt;FILE&gt;)) {<br/>
chomp $line;<br/>
…<br/>
}<br/>
and this will exhibit all of the behavior that we need. There are still a couple of<br/>improvements that we can make, but these are more about making the code Perlish<br/>than about fixing bugs.<br/>
The first of the changes is to make use of the Perl default variable $_. A lot of<br/>
Perl code can be made more streamlined by using $_. In this case it makes a small<br/>amount of difference. We no longer need to define $line and we can make use of<br/>the fact that chomp works on $_ by default. Our code will now look like this:<br/>
while (defined($_ = &lt;FILE&gt;)) {<br/>
chomp;<br/>
…<br/>
}<br/>
The last piece of optimization is one that you wouldn’t be able to guess at, as it uses<br/>a piece of syntactic sugar that was put in by the authors of Perl when they realized<br/>what a common task this would be. If the file input operator is the only thing that is<br/>in the conditional expression of a while loop, then the result of the operator is<br/>magically assigned to the $_ variable and the resulting value is checked to see that it<br/>is defined (rather than checking that it is true.) This means that you can write:<br/>
while (&lt;FILE&gt;)) {<br/>
chomp;<br/>
…<br/>
}<br/>
at which point we are back with our original code (but, hopefully, with a deeper<br/>understanding of the complexities beneath the surface of such simple looking code).<br/>
Notice that this final optimization is dependent on two things being true:<br/>
1<br/>
The file input operator must be the only thing in the conditional expres-<br/>sion, so you can’t write things like<br/>
while (&lt;FILE&gt; and $_ ne 'END') { # THIS DOESN'T WORK!<br/>
…<br/>
}<br/>
2<br/>
The conditional expression must be part of a while loop, so you can’t write<br/>things like<br/>
if (&lt;FILE&gt;) { # THIS DOESN'T WORK EITHER!<br/>
print;<br/>
} else {<br/>
print &#34;No data\n&#34;;<br/>
}<br/>
<hr/>
<a name=120></a><b>100</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
<i><b>Counting the current record number<br/></b></i>While looping through a file like this it is often useful to know which line you are<br/>currently processing. This useful information is stored in the $. variable.4 The value<br/>is reset when the file handle is closed, which means that this works:<br/>
open FILE, 'input.txt' or die &#34;Can't open input file: $!\n&#34;;<br/>
while (&lt;FILE&gt;) {<br/>
# do stuff<br/>
}<br/>
print &#34;$. records processed.\n&#34;;<br/>
close FILE;<br/>
but the following code is wrong as it will always print zero.<br/>
# THIS CODE DOESN'T WORK<br/>
open FILE, &#34;input.txt&#34; or die &#34;Can't open input file: $!\n&#34;;<br/>
while (&lt;FILE&gt;) {<br/>
# do stuff<br/>
}<br/>
close FILE;<br/>
print &#34;$. records processed.\n&#34;;<br/>
In many of these examples, I have moved away from using STDIN, simply to indi-<br/>cate that these methods will work on any file handle. To finish this section, here is a<br/>very short example using STDIN that will add line numbers to any file passed to it.<br/>
#!/usr/local/bin/perl -w<br/>
use strict;<br/>
print &#34;$.: $_&#34; while &lt;STDIN&gt;;<br/>
<i><b>6.1.2</b></i><br/>
<i><b>Processing simple record-oriented data</b></i><br/>
So now that we know how to get our records from the input stream (either one at a<br/>time or all together in an array) what do we do with them? Of course, the answer to<br/>that question depends to a great extent on what your end result should be, but here<br/>are a few ideas.<br/>
<i><b>Extracting data fields<br/></b></i>Chances are that within your record there will be individual data items (otherwise<br/>known as fields) and you will need to break up the record to access these fields.<br/>Fields can be denoted in a record in a number of ways, but most methods fall into<br/>
4 Actually, $. contains the current line number in the file handle that you read most recently. This allows you<br/>
to still use $. if you have more than one file open. It’s also worth mentioning that the definition of a line<br/>is determined by the contents of the input separator variable ($/), which we’ll cover in more detail later.<br/>
<hr/>
<a name=121></a><i><b>Simple record-oriented data</b></i><br/>
<b>101</b><br/>
one of two camps. In one method the start and end of a particular field is denoted<br/>by a sequence of characters that won’t appear in the fields themselves. This is<br/>known as delimited or separated data.5 In the other method each field is defined to<br/>take up a certain number of characters and is space—or zero—padded if it is less<br/>than the defined size. This is known as fixed-width data. We will cover fixed-width<br/>data in more detail in the next chapter and for now will limit ourselves to separated<br/>and delimited data.<br/>
We have seen separated data before. The CD example that we have looked at in<br/>
previous chapters is an example of a tab-separated data file. In the file each line rep-<br/>resents one CD, and within a line the various fields are separated by the tab charac-<br/>ter. An obvious way to deal with this data is the one that we used before, i.e., using<br/>split to separate the record into individual fields like this:<br/>
my $record = &lt;STDIN&gt;;<br/>
chomp $record;<br/>
my @fields = split(/\t/, $record);<br/>
The fields will then be in the elements of @fields. Often, a more natural way to<br/>model a data record is by using a hash. For example, to build a %cd hash from a<br/>record in our CD file, we could do something like this:<br/>
my $record = &lt;STDIN&gt;;<br/>
chomp $record;<br/>
my %cd;<br/>
($cd{artist}, $cd{title}, $cd{label}, $cd{year}) = split (/\t/, $record);<br/>
We can then access the individual fields within the record using:<br/>
my $label = $cd{label};<br/>
my $title = $cd{title};<br/>
and so on.<br/>
Within the actual CD file input code from chapter 3 we simplified this code<br/>
slightly by writing it like this:<br/>
my @fields = qw/artist title label year/;<br/>
my $record = &lt;FILE&gt;;<br/>
chomp $record;<br/>
my %cd;<br/>
@cd{@fields} = split(/\t/, $record);<br/>
5 Strictly speaking, there is a difference between separated and delimited data. <i>Separated data</i> has a character<br/>
sequence between each field and <i>delimited data</i> has a character sequence at the start and end of each field.<br/>In practical terms, however, the methods for dealing with them are very similar and many people tend to<br/>use the terms as if they are interchangeable.<br/>
<hr/>
<a name=122></a><b>102</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
In this example we make use of a hash slice to make assigning values to the hash<br/>much easier. Another side effect is that it makes maintenance a little easier as well. If<br/>a new field is added to the input file, then the only change required to the input<br/>routine is to add another element to the @fields array.<br/>
We now have a simple and efficient way to read in simple record-oriented data<br/>
and split each record into its individual fields.<br/>
<i><b>6.1.3</b></i><br/>
<i><b>Writing simple record-oriented data</b></i><br/>
Of course, having read in your data and carried out suitable data munging, you will<br/>next need to output your data in some way. The obvious choice is to use print,<br/>but there are other options and even print has a few subtleties that will make your<br/>life easier.<br/>
<i><b>Controlling output—separating output records<br/></b></i>In the same way that Perl defines a variable ($/) that contains the input record sep-<br/>arator, it defines another variable ($\) which contains the output record separator.<br/>Normally this variable is set to undef which leaves you free to control exactly where<br/>you output the record separator. If you set it to another value, then that value will<br/>be appended to the end of the output from each print statement. If you know that<br/>in your output file each record must be separated by a newline character, then<br/>instead of writing code like this:<br/>
foreach (@output_records) {<br/>
print &#34;$_\n&#34;;<br/>
}<br/>
you can do something like this:<br/>
{<br/>
local $\ = &#34;\n&#34;;<br/>
foreach (@output_records) {<br/>
print;<br/>
}<br/>
}<br/>
(Notice how we’ve localized the change to $\ so that we don’t inadvertently break<br/>any print statements elsewhere in the program.)<br/>
Generally people don’t use this variable because it isn’t really any more efficient. <br/>
<i><b>Controlling output—printing lists of items<br/></b></i>Other variables that are much more useful are the output field separator ($,) and<br/>the output list separator ($&#34;). The output field separator is printed between the ele-<br/>ments of the list passed to a print statement and the output list separator is printed<br/>
<hr/>
<a name=123></a><i><b>Simple record-oriented data</b></i><br/>
<b>103</b><br/>
between the elements of a list that is interpolated in a double quoted string. These<br/>concepts are dangerously similar so let’s see if we can make it a little clearer.<br/>
In Perl the print function works on a list. This list can be passed to the function<br/>
in a number of different ways. Here are a couple of examples:<br/>
print 'This list has one element';<br/>
print 'This', 'list', 'has', 'five', 'elements';<br/>
In the first example the list passed to print has only one element. In the second<br/>example the list has five elements that are separated by commas. The output field<br/>separator ($,) controls what is printed between the individual elements. By<br/>default, this variable is set to the empty string (so the second example above prints<br/>Thislisthasfiveelements). If we were to change the value of $, to a space<br/>character before executing the print statement, then we would get something a<br/>little more readable. The following:<br/>
$, = ' ';<br/>
print 'This', 'list', 'has', 'five', 'elements';<br/>
produces the output<br/>
<b>This list has five elements</b><br/>
This can be useful if your output data is stored in a number of variables. For exam-<br/>ple, if our CD data was in variables called $band, $title, $label, and $year and<br/>we wanted to create a tab separated file, we could do something like this:<br/>
$\ = &#34;\n&#34;;<br/>
$, = &#34;\t&#34;;<br/>
print $band, $title, $label, $year;<br/>
which would automatically put a tab character between each field and a newline<br/>character on the end of the record.<br/>
Another way that a list is often passed to print is in an array variable. You will<br/>
sometimes see code like this:<br/>
my @list = qw/This is a list of items/;<br/>
print @list;<br/>
in which case the elements of @list are printed with nothing separating them<br/>(Thisisalistofitems). A common way to get round this is to use join:<br/>
my @list = qw/This is a list of items/;<br/>
print join(' ', @list);<br/>
which will put spaces between each of the elements being printed.<br/>
A more elegant way to handle this is to use the list separator variable ($&#34;). This<br/>
variable controls what is printed between the elements of an array when the array is<br/>
<hr/>
<a name=124></a><b>104</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
in double quotes. The default value is a space. This means that if we change our<br/>original code to<br/>
my @list = qw/This is a list of items/;<br/>
print &#34;@list&#34;;<br/>
then we will get spaces printed between the elements of our list. In order to print<br/>the data with tabs separating each record we simply have to set $&#34; to a tab character<br/>(\t). In chapter 3 when we were reading in the CD data file we stored the data in<br/>an array of hashes. An easy way to print out this data would be to use code like this:<br/>
my @fields = qw/name title label year/;<br/>
local $&#34; = &#34;\t&#34;;<br/>
local $\ = &#34;\n&#34;;<br/>
foreach (@CDs) {<br/>
my %CD = %$_;<br/>
print &#34;@CD{@fields}&#34;;<br/>
}<br/>
<i><b>Controlling output—printing to different file handles<br/></b></i>Recall that the syntax of the print statement is one of the following:<br/>
print;<br/>
print LIST;<br/>
print FILEHANDLE LIST;<br/>
In the first version the contents of $_ are printed to the default output file handle (usu-<br/>ally STDOUT). In the second version the contents of LIST are printed to the default out-<br/>put file handle. In the third version the contents of LIST are printed to FILEHANDLE.<br/>
Notice that I said that the default output file handle is <i>usually</i> STDOUT. If you are<br/>
doing a lot of printing to a different file handle, then it is possible to change the<br/>default using the select function.6 If you call select with no parameters, it will<br/>return the name of the currently selected output file handle, so<br/>
print select;<br/>
will normally print main::STDOUT. If you call select with the name of a file han-<br/>dle, it will replace the current default output file handle with the new one. It returns<br/>the previously selected file handle so that you can store it and reset it later. If you<br/>needed to write a lot of data to a particular file, you could use code like this:<br/>
open FILE, '&gt;out.txt' or die &#34;Can't open out.txt: $!&#34;;<br/>
my $old = select FILE;<br/>
6 Or rather one of the select functions. Perl has two functions called select and knows which one you<br/>
mean by the number of arguments you pass it. This one has either zero arguments or one argument. The<br/>other one (which we won’t cover in this book as it is used in network programming) has four arguments.<br/>
<hr/>
<a name=125></a><i><b>Simple record-oriented data</b></i><br/>
<b>105</b><br/>
foreach (@data) {<br/>
print;<br/>
}<br/>
select $old;<br/>
Between the two calls to select, the default output file handle is changed to be<br/>FILE and all print statements without a specific file handle will be written to FILE.<br/>Notice that when we have finished we reset the default file handle to whatever it<br/>was before we started (we stored this value in $file). You shouldn’t assume that<br/>the default file handle is STDOUT before you change it, as some other part of the<br/>program may have changed it already.<br/>
Another variable that is useful when writing data is $|. Setting this variable to a<br/>
nonzero value will force the output buffer to be flushed immediately after every<br/>print (or write) statement. This has the effect of making the output stream look<br/>as if it were unbuffered. This variable acts on the currently selected output file han-<br/>dle. If you want to unbuffer any other file handle, you will need to select it, change<br/>the value of $|, and then reselect the previous file handle using code like this:<br/>
my $file = select FILE;<br/>
$| = 1;<br/>
select $file;<br/>
While this works, it isn’t as compact as it could be, so in many Perl programs you<br/>will see this code instead:<br/>
select((select(FILE), $| = 1)[0]);<br/>
This is perhaps one of the strangest looking pieces of Perl that you’ll come across<br/>but it’s really quite simple if you look closely.<br/>
The central part of the code is building a list. The first element of the list is the<br/>
return value from select(FILE), which will be the previously selected file handle.<br/>As a side effect, this piece of code selects FILE as the new default file handle. The<br/>second element of the list is the result of evaluating $| = 1, which is always 1. As a<br/>side effect, this code will unbuffer the current default file handle (which is now<br/>FILE). The code now takes the first element of this list (which is the previously<br/>selected file handle) and passes that to select, thereby returning the default file<br/>handle to its previous state.<br/>
<i><b>6.1.4</b></i><br/>
<i><b>Caching data</b></i><br/>
One common data munging task is translating data from one format to another<br/>using a lookup table. Often a good way to handle this is to cache data as you use it,<br/>as the next example will demonstrate.<br/>
<hr/>
<a name=126></a><b>106</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
<i><b>Example: currency conversion<br/></b></i>A good example of data translation would be converting data from one currency to<br/>another. Suppose that you were given a data file with three columns, a monetary<br/>amount, the currency that it is in,7 and the date that should be used for currency<br/>conversions. You need to be able to present this data in any of a hundred or so pos-<br/>sible currencies. The daily currency rates are stored in a database. In pseudocode, a<br/>first attempt at this program might look something like this:<br/>
Get target currency<br/>
For each data row<br/>
Split data into amount, currency, and date<br/>
Get conversion rate between source and target currencies on given date<br/>
Multiply amount by conversion rate<br/>
Output converted amount<br/>
Next<br/>
This would, of course, do the job but is it the most efficient way of doing it? What<br/>if the source data was all in the same currency and for the same date? We would end<br/>up retrieving the same exchange rate from the database each time.<br/>
Maybe we should read all of the possible exchange rates in at the start and store<br/>
them in memory. We would then have very fast access to any exchange rate without<br/>having to go back to the database. This option would work if we had a reasonably<br/>small number of currencies and a small range of dates (perhaps we are only con-<br/>cerned with U.S. dollars, Sterling, and Deutschmarks over the last week). For any<br/>large number of currencies or date range, the overhead of reading them all into<br/>memory would be prohibitive. And, once again, if the source data all had the same<br/>currency and date then we would be wasting a lot of our time.<br/>
The solution to our problem is to cache the exchange rates that we have already<br/>
read from the database. Look at this script:<br/>
#!/usr/bin/perl -w<br/>
my $target_curr = shift;<br/>
my %rates;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my ($amount, $source_curr, $date) = split(/\t/);<br/>
$rates{&#34;$source_curr|$target_curr|$date&#34;} ||= get_rate($source_curr,<br/>
$target_curr,<br/>
$date);<br/>
$amount *= $rates{&#34;$source_curr|$target_curr|$date&#34;};<br/>
print &#34;$amount\t$target_curr\t$date\n&#34;;<br/>
}<br/>
7 The International Standards Organization (ISO) defines a list of three letter codes for each internationally<br/>
recognized currency (USD for U.S. Dollar, GBP for the pound sterling, and a hundred or so others).<br/>
<hr/>
<a name=127></a><i><b>Simple record-oriented data</b></i><br/>
<b>107</b><br/>
In this script we assume that the get_rate function goes to the database and<br/>returns the exchange rate between the source and target currencies on the given<br/>date. We have introduced a hash which caches the return values from this function.<br/>Remember that in Perl<br/>
$a ||= $b;<br/>
means the same thing as<br/>
$a = $a || $b;<br/>
and also that the Perl || operator is short-circuiting, which means that the expres-<br/>sion after the operator is only evaluated if the expression before the operator is false.<br/>
Bearing this in mind, take another look at this line of the above script:<br/>
$rates{&#34;$source_curr|$target_curr|$date&#34;} ||= get_rate($source_curr,<br/>
$target_curr,<br/>
$date);<br/>
The first time that this line is reached, the %rates hash is empty. The get_rate<br/>function is therefore called and the exchange rate that is returned is written into the<br/>hash with a key made up from the three parameters.<br/>
The next time that this line is reached with the same combination of parameters,<br/>
a value is found in the hash and the get_rate function does not get called.8<br/>
<i><b>Taking caching further—Memoize.pm<br/></b></i>This trick is very similar to the Orcish Manoeuvre which we saw when we were dis-<br/>cussing sorting techniques in chapter 3. It is, however, possible to take things one<br/>step further. On the CPAN there is a module called Memoize.pm which was written<br/>by Mark-Jason Dominus. This module includes a function called memoize which<br/>will automatically wrap caching functionality around any function in your program.<br/>We would use it in our currency conversion script like this:<br/>
#!/usr/bin/perl –w<br/>
use Memoize;<br/>
memoize 'get_rate';<br/>
my $target_curr = shift;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
8 You might notice that we’re checking the <i>value</i> in the hash rather than the <i>existence</i> of a value. This may<br/>
cause a problem if the value can legitimately be zero (or any other value which is evaluated as false—the<br/>string “0”, the empty string, or the value undef). In this case the existence of a zero exchange rate may<br/>cause a few more serious problems than a bug in a Perl script, so I think that we can safely ignore that<br/>possibility. You may need to code around this problem.<br/>
<hr/>
<a name=128></a><b>108</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
my ($amount, $source_curr, $date) = split(/\t/);<br/>
$amount *= get_rate($source_curr, $target_curr, $date);<br/>
print &#34;$amount\t$target_curr\t$date\n&#34;;<br/>
}<br/>
Notice how the introduction of Memoize actually simplifies the code. What Memoize<br/>does is it replaces any call to a memoized function (get_rate in our example) with a<br/>call to a new function. This new function checks an internal cache and calls the origi-<br/>nal function only if there is not an appropriate cached value already available. An arti-<br/>cle explaining these concepts in some detail appeared in issue 13 (Vol. 4, No. 1)<br/>Spring 1999 of <i>The</i> <i>Perl Journal</i>.<br/>
Not every function call is a suitable candidate for caching or memoization but,<br/>
when you find one that is, you can see a remarkable increase in performance.<br/>
<i><b>6.2</b></i><br/>
<i><b>Comma-separated files</b></i><br/>
A very common form of record-oriented data is the comma-separated value (CSV)<br/>format. In this format each record is one line of the data file and within that record<br/>each field is separated with commas. This format is often used for extracting data<br/>from spreadsheets or databases.<br/>
<i><b>6.2.1</b></i><br/>
<i><b>Anatomy of CSV data</b></i><br/>
At first glance it might seem that there is nothing particularly difficult about dealing<br/>with comma-separated data. The structure is very similar to the tab or pipe sepa-<br/>rated files that we have looked at before. The difference is that while tab and pipe<br/>characters are relatively rare in many kinds of data, the comma can quite often<br/>appear in data records, especially if the data is textual. To get around these problems<br/>there are a couple of additions to the CSV definition. These are:<br/>
■<br/>
A comma should not be classed as a separator if it is in a string that is<br/>enclosed in double quotes.<br/>
■<br/>
Within a double quoted string, a double quote character is represented by<br/>two consecutive double quotes.<br/>
Suddenly things get a bit more complex. This means that the following is a valid<br/>
CSV record:<br/>
&#34;Cross, Dave&#34;,07/09/1962,M,&#34;Field with &#34;&#34;embedded&#34;&#34; quotes&#34;<br/>
We can’t simply split this data on commas, as we would have done before because<br/>the extra comma in the first field will generate an extra field. Also, the double<br/>quotes around the first and last fields are not part of the data and need to be<br/>stripped off and the doubled double quotes in the last field need to be converted to<br/>single double quotes!<br/>
<hr/>
<a name=129></a><i><b>Comma-separated files</b></i><br/>
<b>109</b><br/>
<i><b>6.2.2</b></i><br/>
<i><b>Text::CSV_XS</b></i><br/>
Fortunately, this problem has already been solved for you. On the CPAN there is a<br/>module called <br/>
9<br/>
Text::CSV_XS  which will extract the data from CSV files and will<br/>
also generate CSV records from your data. The best way to explain how it works is<br/>to leap right in with an example or two. Suppose that we had a CSV file which con-<br/>tained data like the previous example line. The code to extract and print the data<br/>fields would look like this:<br/>
use Text::CSV_XS;<br/>
my $csv = Text::CSV-&gt;new;<br/>
$csv-&gt;parse(&lt;STDIN&gt;);<br/>
my @fields = $csv-&gt;fields;<br/>
local $&#34; = '|';<br/>
print &#34;@fields\n&#34;;<br/>
Assuming the input line above, this will print:<br/>
Cross, Dave|07/09/1962|M|Field with &#34;embedded&#34; quotes<br/>
Notice the use of $&#34; to print pipe characters between the fields.<br/>
Text::CSV_XS also works in reverse. It will create CSV records from your data.<br/>
As an example, let’s rebuild the same data line from the individual data fields.<br/>
my @new_cols = ('Cross, Dave', '07/09/1962', 'M',<br/>
'Field with &#34;embedded&#34; quotes');<br/>
$csv-&gt;combine(@new_cols);<br/>
print $csv-&gt;string;<br/>
This code prints:<br/>
&#34;Cross, Dave&#34;,07/09/1962,M,&#34;Field with &#34;&#34;embedded&#34;&#34; quotes&#34;<br/>
which is back to our original data.<br/>
The important functions in Text:CSV are therefore:<br/>
■<br/>
new—Creates a CSV object through which all other functions can be called.<br/>
■<br/>
parse($csv_data)—Parses a CSV  data  string  that  is  passed  to  it.  The<br/>extracted columns are stored internally within the CSV object and can be<br/>accessed using the fields method.<br/>
■<br/>
fields —Returns an array containing the parsed CSV data fields.<br/>
9 Text::CSV_XS is a newer and faster version of the older Text::CSV module. As the name implies,<br/>
Text::CSV_XS is partially implemented in C, which makes it faster. The Text::CSV module is pure Perl.<br/>
<hr/>
<a name=130></a><b>110</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
■<br/>
combine(@fields)—Takes a list of data fields and converts them into a CSV<br/>data record. The CSV record is stored internally within the CSV object and<br/>can be accessed using the string method.<br/>
■<br/>
string —Returns a string which is the last created CSV data record.<br/>
With this in mind, it is simple to create generic CSV data reading and writing routines.<br/>
use Text::CSV;<br/>
sub read_csv {<br/>
my $csv = Text::CSV-&gt;new;<br/>
my @data;<br/>
while (&lt;STDIN&gt;) {<br/>
$csv-&gt;parse($_);<br/>
push @data, [$csv-&gt;fields];<br/>
}<br/>
return \@data;<br/>
}<br/>
sub write_csv {<br/>
my $data = shift;<br/>
my $csv = Text::CSV-&gt;new;<br/>
foreach (@$data) {<br/>
$csv-&gt;combine(@$_);<br/>
print $csv-&gt;string;<br/>
}<br/>
}<br/>
These functions would be called from within a program like this:<br/>
my $data = read_csv;<br/>
foreach (@$data) {<br/>
# Do something to each record.<br/>
# Individual fields are accessed as<br/>
#<br/>
$_-&gt;[0], $_-&gt;[1], etc …<br/>
}<br/>
write_csv($data);<br/>
<i><b>6.3</b></i><br/>
<i><b>Complex records</b></i><br/>
All of the data we have seen up to now has had one line per record, but as I hinted<br/>earlier it is quite possible for data records to span more than one line in a data file.<br/>Perl makes it almost as simple to deal with nearly any kind of data. The secret to<br/>handling more complex data records is to make good use of the Perl variables that<br/>we mentioned in previous sections. <br/>
<hr/>
<a name=131></a><i><b>Complex records</b></i><br/>
<b>111</b><br/>
<i><b>6.3.1</b></i><br/>
<i><b>Example: a different CD file</b></i><br/>
Imagine, for example, if our CD file was in a slightly different format, like this:<br/>
Name: Bragg, Billy<br/>
Title: Workers' Playtime<br/>
Label: Cooking Vinyl<br/>
Year: 1987<br/>
%%<br/>
Name: Bragg, Billy<br/>
Title: Mermaid Avenue<br/>
Label: EMI<br/>
Year: 1998<br/>
%%<br/>
Name: Black, Mary<br/>
Title: The Holy Ground<br/>
Label: Grapevine<br/>
Year: 1993<br/>
%%<br/>
Name: Black, Mary<br/>
Title: Circus<br/>
Label: Grapevine<br/>
Year: 1996<br/>
%%<br/>
Name: Bowie, David<br/>
Title: Hunky Dory<br/>
Label: RCA<br/>
Year: 1971<br/>
%%<br/>
Name: Bowie, David<br/>
Title: Earthling<br/>
Label: EMI<br/>
Year: 1997<br/>
In this case the data is exactly the same, but a record is now spread over a number of<br/>lines. Notice that the records are separated by a line containing the character<br/>sequence %%.10 This will be our clue in working out the best way to read these<br/>records. Earlier we briefly mentioned the variable $/ which defines the input record<br/>separator. By setting this variable to an appropriate value we can get Perl to read the<br/>file one whole record at a time. In this case the appropriate value is \n%%\n. We can<br/>now read in records like this:<br/>
local $/ = &#34;\n%%\n&#34;;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
print &#34;Record $. is\n$_&#34;;<br/>
}<br/>
10 This is a surprisingly common record separator, due to its use as the record separator in the data files read<br/>
by the UNIX fortune program.<br/>
<hr/>
<a name=132></a><b>112</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
Remember that when Perl reads to the next occurrence of the input record separa-<br/>tor, it includes the separator character sequence in the string that it returns. We<br/>therefore use chomp to remove that sequence from the string before processing it.<br/>
So now we have the record in a variable. How do we go about extracting the<br/>
individual fields from within the records? This is relatively easy as we can go back to<br/>using split to separate the fields. In this case the field separator is a newline char-<br/>acter so that is what we need to split on.<br/>
local $/ = &#34;\n%%\n&#34;;<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
print join('|', split(/\n/)), &#34;\n&#34;;<br/>
}<br/>
This code will print each of the records on one line with the fields separated by a<br/>pipe character. We are very close to having all of the fields in a form that we can use,<br/>but there is one more step to take.<br/>
<i><b>Making use of the extra data<br/></b></i>One difference between this format and the original (one record per line) format<br/>for the CD file is that the individual fields are now labeled. We need to lose these<br/>labels, but we can first make good use of them. Eventually we want each of our<br/>records to end up in a hash. The values of the hash will be the values of the data<br/>fields, but what are the keys? In previous versions of the CD input routines we have<br/>always hard-coded the names of the data fields, but here we have been given them.<br/>Let’s use them to create the keys of our hash. This will hopefully become clearer<br/>when you see this code:<br/>
1: $/ = &#34;\n%%\n&#34;;<br/>
2:<br/>
3: my @CDs;<br/>
4:<br/>
5: while (&lt;STDIN&gt;) {<br/>
6:<br/>
chomp;<br/>
7:<br/>
my (%CD, $field);<br/>
8:<br/>
9:<br/>
my @fields = split(/\n/);<br/>
10:<br/>
foreach $field (@fields) {<br/>
11:<br/>
my ($key, $val) = split (/:\s*/, $field, 2);<br/>
12:<br/>
$CD{lc $key} = $val;<br/>
13:<br/>
}<br/>
14:<br/>
15:<br/>
push @CDs, \%CD;<br/>
16: }<br/>
<hr/>
<a name=133></a><i><b>Complex records</b></i><br/>
<b>113</b><br/>
Let’s examine this code line by line.<br/>
Line 1 sets the input record separator to be %%\n.<br/>Line 3 defines an array variable that we will use to store the CDs.<br/>Line 5 starts the while loop which reads each line from STDIN in to $_.<br/>Line 6 calls chomp to remove the %%\n characters from the end of $_.<br/>Line 7 defines two temporary variables. %CD will store the data for one CD and<br/>
$field will be used as temporary storage when processing the fields.<br/>
Line 9 creates an array @fields which contains each of the fields in the record,<br/>
split on the newline character. Notice that split throws away the separator charac-<br/>ter so that the fields in the array do not have newline characters at the end of them.<br/>
Line 10 starts a foreach loop which processes each field in the record in turn.<br/>
The field being processed is stored in $field.<br/>
Line 11 splits the field into its key and its value, assigning the results to $key and<br/>
$value. Note that the regular expression that we split on is /:\s*/. This matches a<br/>colon followed by zero or more white space characters. In our sample data, the sep-<br/>arator is always a colon followed by exactly one space, but we have made our script<br/>a little more flexible. We also pass a limit to split so that the list returned always<br/>contains two or fewer elements.<br/>
Line 12 assigns the value to the key in the %CD hash. Notice that we actually use<br/>
the lower-case version of $key. Again this just allows us to cope with a few more<br/>potential problems in the input data.<br/>
Line 13 completes the foreach loop. At this point the %CD hash should have<br/>
four records in it.<br/>
Line 15 pushes a reference to the %CD onto the @CDs array.<br/>Line 16 completes the while loop. At this point the @CDs array will contain a<br/>
reference to one hash for each of the CDs in the collection.<br/>
<i><b>6.3.2</b></i><br/>
<i><b>Special values for $/</b></i><br/>
There are two other commonly used values for $/—undef and the empty string.<br/>Setting $/ to undef puts Perl into “slurp mode.” In this mode there are no record<br/>separators and the whole input file will be read in one go. Setting $/ to the empty<br/>string puts Perl into “paragraph mode.” In this mode, records are separated by one<br/>or more blank lines. Note that this is not the same as setting $/ to \n\n. If a file has<br/>two or more consecutive blank lines then setting $/ to \n\n will give you extra<br/>empty records, whereas setting it to the empty string will soak up any number of<br/>blank lines between records. There are, of course, times when either of these behav-<br/>iors is what is required.<br/>
You can also set $/ to a reference to a scalar (which should contain an integer).<br/>
In this case Perl will read that number of bytes from the input stream. For example:<br/>
<hr/>
<a name=134></a><b>114</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
local $/ = \1024;<br/>
my $data = &lt;DATA&gt;;<br/>
will read in the next kilobyte from the file handle DATA. This idiom is more useful<br/>when reading binary files.<br/>
One thing that you would sometimes like to do with $/ is set it to a regular<br/>
expression so that you can read in records that are delimited by differing record<br/>markers. Unfortunately, you must set $/ to be a fixed string, so you can’t do this.<br/>The best way to get around this is to read the whole file into a scalar variable (by<br/>setting $/ to undef) and then use split to break it up into an array of records.<br/>The first parameter to split is interpreted as a regular expression.<br/>
<i><b>6.4</b></i><br/>
<i><b>Special problems with date fields</b></i><br/>
It is very common for data records to contain dates.11 Unfortunately, Perl’s date<br/>handling seems to be one of the areas that confuses a large number of people, which<br/>is a shame, because it is really very simple. Let’s start with an overview of how Perl<br/>handles dates.<br/>
<i><b>6.4.1</b></i><br/>
<i><b>Built-in Perl date functions</b></i><br/>
As far as Perl is concerned, all dates are measured as a number of seconds since the<br/>epoch. That sounds more complex than it is. The epoch is just a date and time from<br/>which all other dates are measured. This can vary from system to system, but on<br/>many modern computer systems (including all UNIX systems) the epoch is defined<br/>as 00:00:00 GMT on Thursday, Jan. 1, 1970. The date as I’m writing this is<br/>943011797, which means that almost a billion seconds have passed since the begin-<br/>ning of 1970.<br/>
<i><b>Getting the current date and time with time functions<br/></b></i>You can attain the current date and time in this format using the time function. I<br/>generated the number in the last paragraph by running this at my command line:<br/>
perl -e &#34;print time&#34;;<br/>
This can be useful for calculating the time that a process has taken to run. You can<br/>write something like this:<br/>
my $start = time;<br/>
# Do lots of clever stuff<br/>
11 When I mention dates in this section, I generally mean dates and times.<br/>
<hr/>
<a name=135></a><i><b>Special problems with date fields</b></i><br/>
<b>115</b><br/>
my $end = time;<br/>
print &#34;Process took &#34;, $end - $start, &#34; seconds to run.&#34;;<br/>
<i><b>More readable dates and times with localtime<br/></b></i>This format for dates isn’t very user friendly, so Perl supplies the localtime func-<br/>tion to convert these values into readable formats, adjusted for your current time<br/>zone.12 localtime takes one optional argument, which is the number of seconds<br/>since the epoch. If you don’t pass this argument it calls time to get the current<br/>time. localtime returns different things depending on whether it is called in scalar<br/>or array context. In a scalar context it returns the date in a standard format. You can<br/>see this by running<br/>
perl -e &#34;print scalar localtime&#34;<br/>
at your command line. Notice the use of scalar to force a scalar context on the<br/>function call, as print gives its arguments an array context. To find when exactly a<br/>billion seconds will have passed since the epoch you can run:<br/>
perl -e &#34;print scalar localtime(1_000_000_000)&#34;<br/>
(which prints “Sun Sep  9 01:46:40 2001” on my system) and to find out when the<br/>epoch is on your system use:<br/>
perl -e &#34;print scalar localtime(0)&#34;<br/>
In an array context, localtime returns an array containing the various parts of the<br/>date. The elements of the array are:<br/>
■<br/>
the number of seconds (0–60)13<br/>
■<br/>
the number of minutes (0–59)<br/>
■<br/>
the hour of the day (0–23)<br/>
■<br/>
the day of the month (1–31)<br/>
■<br/>
the month of the year (0–11)<br/>
■<br/>
the year, as the number of years since 1900.<br/>
■<br/>
the day of the week (0 is Sunday and 6 is Saturday)<br/>
■<br/>
the day of the year<br/>
■<br/>
a Boolean flag indicating whether daylight savings time is in effect.<br/>
Some of these fields cause a lot of problems.<br/>
12 There is another function, gmtime, which does the same as localtime, but doesn’t make time zone<br/>
adjustments and returns values for GMT.<br/>
13 The 61st second is there to handle leap seconds.<br/>
<hr/>
<a name=136></a><b>116</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
The month and the day of the week are given as zero-based numbers. This is<br/>
because you are very likely to convert these into strings using an array of month or<br/>day names.<br/>
The year is given as the number of years since 1900. This is well-documented<br/>
and has always been the case, but the fact that until recently this has been a two-<br/>digit number has led many people to believe that it returns a two-digit year. This<br/>has led to a number of broken scripts gaining a great deal of currency and it is com-<br/>mon to see scripts that do something like this:<br/>
my $year = (localtime)[5];<br/>
$year = &#34;19$year&#34;; # THIS IS WRONG!<br/>
or (worse)<br/>
$year = ($year &lt; 50) ? &#34;20$year&#34; : &#34;19$year&#34;; # THIS IS WRONG!<br/>
The correct way to produce a date using localtime is to do something like this:<br/>
my @months = qw/January February March April May June July August<br/>
September October November December/;<br/>
my @days<br/>
= qw/Sunday Monday Tuesday Wednesday Thursday Friday Saturday/;<br/>
my @now = localtime;<br/>
$now[5] += 1900;<br/>
my $date = sprintf '%s %02d %s %4d, %02d:%02d:%02d',<br/>
$days[$now[6]], $now[3], $months[$now[4]], $now[5],<br/>
$now[2], $now[1], $now[0];<br/>
As hinted in the code above, if you don’t need all of the date information, it is sim-<br/>ple enough to use an array slice to get only the parts of the array that you want.<br/>These are all valid constructions:<br/>
my $year = (localtime)[5];<br/>
my ($d, $m, $y) = (localtime)[3 .. 5];<br/>
my ($year, $day_no) = (localtime)[5, 7];<br/>
<i><b>Getting the epoch seconds using timelocal<br/></b></i>It is therefore easy enough to convert the return value from time to a readable date<br/>string. It would be reasonable to want to do the same in reverse. In Perl you can do<br/>that by using the timelocal function. This function is not a Perl built-in function,<br/>but is included in the standard Perl library in the module Time::Local.<br/>
To use timelocal, you pass it a list of time values in the same format as they are<br/>
returned by localtime. The arguments are seconds, minutes, hours, day of<br/>month, month (January is 0 and December is 11), and year (in number of years<br/>since 1900; e.g., 2000 would be passed in as 100). For example to find out how<br/>many seconds will have passed at the start of the third millennium (i.e., Jan. 1,<br/>2001) you can use code like this:<br/>
<hr/>
<a name=137></a><i><b>Special problems with date fields</b></i><br/>
<b>117</b><br/>
use Time::Local;<br/>
my $secs = timelocal(0, 0, 0, 1, 0, 101);<br/>
<i><b>Examples: date and time manipulation using Perl built-in functions<br/></b></i>With localtime and timelocal it is possible to do just about any kind of data<br/>manipulation that you want. Here are a few simple examples.<br/>
<i>Finding the date in x days time<br/></i>This is, in principle, simple but there is one small complexity. The method that we<br/>use is to find the current time (in seconds) using localtime and add 86,400 (24 x<br/>60 x 60) for each day that we want to add. The complication arises when you try to<br/>calculate the date near the time when daylight saving time either starts or finishes. At<br/>that time you could have days of either 23 or 25 hours and this can affect your calcu-<br/>lation. To counter this we move the time to noon before carrying out the calculation.<br/>
use Time::Local;<br/>
my @now = localtime;<br/>
# Get the current date and time<br/>
my @then = (0, 0, 12, @now[3 .. 5]); # Normalize time to 12 noon<br/>
my $then = timelocal(@then);<br/>
# Convert to number of seconds<br/>
$then += $x * 86_400;<br/>
# Where $x is the number of days to add<br/>
@then = localtime($then);<br/>
# Convert back to array of values<br/>
@then[0 .. 2] = @now[0 .. 2];<br/>
# Replace 12 noon with real time<br/>
$then = timelocal(@then);<br/>
# Convert back to number of seconds<br/>
print scalar localtime $then;<br/>
# Print result<br/>
<i>Finding the date of the previous Saturday<br/></i>Again, this is pretty simple, with just one slightly complex calculation, which is<br/>explained in the comments. We work out the current day of the week and, therefore,<br/>can work out the number of days that we need to go back to get to Saturday.<br/>
my @days = qw/Sunday Monday Tuesday Wednesday Thursday Friday<br/>
Saturday/;<br/>
my @months = qw/January February March April May June July August<br/>
September October November December/;<br/>
my $when = 6; # Saturday is day 6 in the week.<br/>
# You can change this line to get other days of the week.<br/>
my $now = time;<br/>
my @now = localtime($now);<br/>
# This is the tricky bit.<br/>
# $diff will be the number of days since last Saturday.<br/>
# $when is the day of the week that we want.<br/>
<hr/>
<a name=138></a><b>118</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
# $now[6] is the current day of the week.<br/>
# We take the result modulus 7 to ensure that it stays in the<br/>
# range 0 - 6.<br/>
my $diff = ($now[6] - $when + 7) % 7;<br/>
my $then = $now - (24 * 60 * 60 * $diff);<br/>
my @then = localtime($then);<br/>
$then[5] += 1900;<br/>
print &#34;$days[$then[6]] $then[3] $months[$then[4]] $then[5]&#34;;<br/>
<i>Finding the date of the first Monday in a given year<br/></i>This is very similar in concept to the last example. We calculate the day of the week<br/>that January 1 fell on in the given year, and from that we can calculate the number<br/>of days that we have to move forward to get to the first Monday.<br/>
use Time::Local;<br/>
# Get the year to work on<br/>
my $year = shift || (localtime)[5] + 1900;<br/>
# Get epoch time of Jan 1st in that year<br/>
my $jan_1 = timelocal(0, 0, 0, 1, 0, $year - 1900);<br/>
# Get day of week for Jan 1<br/>
my $day = (localtime($jan_1))[6];<br/>
# Monday is day 1 (Sunday is day 0)<br/>
my $monday = 1;<br/>
# Calculate the number of days to the first Monday<br/>
my $diff = (7 - $day + $monday) % 7;<br/>
# Add the correct number of days to $jan_1<br/>
print scalar localtime($jan_1 + (86_400 * $diff));<br/>
<i><b>Better date and time formatting with POSIX::strftime<br/></b></i>There is one other important date function that comes with the Perl standard<br/>library. This is the strftime function that is part of the POSIX module. POSIX is an<br/>attempt to standardize system calls across a number of computer vendors’ systems<br/>(particularly among UNIX vendors) and the Perl POSIX module is an interface to<br/>these standard functions. The strftime function allows you to format dates and<br/>times in a very controllable manner. The function takes as arguments a format<br/>string and a list of date and time values in the same format as they are returned by<br/>localtime. The format string can contain any characters, but certain character<br/>sequences will be replaced by various parts of the date and time. The actual set of<br/>sequences supported will vary from system to system, but most systems should sup-<br/>port the sequences shown in table 6.1.<br/>
<hr/>
<a name=139></a><i><b>Special problems with date fields</b></i><br/>
<b>119</b><br/>
Table 6.1<br/>
<b>POSIX::strftime</b> character sequences<br/>
%a <br/>
short day name (Sun to Sat)<br/>
%A <br/>
long day name (Sunday to Saturday)<br/>
%b <br/>
short month name (Jan to Dec)<br/>
%B <br/>
long month name (January to December)<br/>
%c <br/>
full date and time in the same format as <br/>
localtime returns in scalar context<br/>
%d <br/>
day of the month (01 to 31)<br/>
%H <br/>
hour in 24-hour clock (00 to 23)<br/>
%I <br/>
hour in 12-hour clock (01 to 12)<br/>
%j <br/>
day of the year (001 to 366)<br/>
%m <br/>
month of the year (01 to 12)<br/>
%M <br/>
minutes after the hour (00 to 59)<br/>
%p <br/>
AM or PM<br/>
%S <br/>
seconds after the minute (00 to 59)<br/>
%w <br/>
day of the week (0 to 6)<br/>
%y <br/>
year of the century (00 to 99)<br/>
%Y <br/>
year (0000 to 9999)<br/>
%Z <br/>
time zone string (e.g., GMT)<br/>
%% <br/>
a percent character<br/>
Here is a simple script which uses strftime.<br/>
use POSIX qw(strftime);<br/>
foreach ('%c', '%A %d %B %Y', 'Day %j', '%I:%M:%S%p (%Z)') {<br/>
print strftime($_, localtime), &#34;\n&#34;;<br/>
}<br/>
which gives the following output:<br/>
<b>22/05/00 14:38:38</b><br/>
<b>Monday 22 May 2000</b><br/>
<b>Day 143</b><br/>
<b>02:38:38PM (GMT Daylight Time)</b><br/>
<hr/>
<a name=140></a><b>120</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
<i><b>International issues with date formats<br/></b></i>One of the most intractable problems with dates has nothing to do with computer<br/>software, but with culture. If I tell you that I am writing this on 8/9/2000, with-<br/>out knowing whether I am European or American you have no way of knowing if I<br/>mean the 8th of September or the 9th of August. For that reason I’d recommend<br/>that whenever possible you always use dates that are in the order year, month, and<br/>day as that is far less likely to be misunderstood. There is an ISO standard (number<br/>8601) which recommends that dates and times are displayed in formats which can<br/>be reproduced using the POSIX::strftime templates %Y-%m-%dT%h:%M:%S (for<br/>date and time) or %Y-%m-%d (for just the date).<br/>
All of the functions that we have just discussed come with every distribution of<br/>
Perl. You should therefore see that it is quite easy to carry out complex date manip-<br/>ulation with vanilla Perl. As you might suspect, however, on the CPAN there are a<br/>number of modules that will make your coding life even easier. We will look in some<br/>detail at two of them: Date::Calc and Date::Manip.<br/>
<i><b>6.4.2</b></i><br/>
<i><b>Date::Calc</b></i><br/>
Date::Calc contains a number of functions for carrying out calculations using dates.<br/>
One important thing to know about Date::Calc is that it represents dates dif-<br/>
ferently from Perl’s internal functions. In particular when dealing with months, the<br/>numbers will be in the range 1 to 12 (instead of 0 to 11), and when dealing with<br/>days of the week the numbers will be in the range 1 to 7 instead of 0 to 6.<br/>
<i><b>Examples: date and time manipulation with Date::Calc<br/></b></i>Let’s look at using Date::Calc for solving the same three problems that we dis-<br/>cussed in the section on built-in functions.<br/>
<i>Finding the date in x days time<br/></i>With Date::Calc, this becomes trivial as we simply call Today to get the current<br/>date and then call Add_Delta_Days to get the result. Of course we can also call<br/>Date_to_Text to get a more user friendly output. The code would look like this:<br/>
print Date_to_Text(Add_Delta_Days(Today(), $x)); # Where $x is the<br/>
# number of days to add<br/>
<i>Finding the date of the previous Saturday<br/></i>There are a number of different ways to solve this problem but here is a reasonably<br/>simple one. We find the week number of the current week and then calculate the date<br/>of Monday in this week. We then subtract two days to get to the previous Saturday.<br/>
my ($year, $month, $day) = Today;<br/>
my $week = Week_Number($year, $month, $day);<br/>
print Date_to_Text(Add_Delta_Days(Monday_of_Week($week, $year), -2));<br/>
<hr/>
<a name=141></a><i><b>Special problems with date fields</b></i><br/>
<b>121</b><br/>
<i>Finding the date of the first Monday in a given year<br/></i>This isn’t as simple as it sounds. The obvious way would be to do this:<br/>
print Date_to_Text(Monday_of_Week(1, $year));<br/>
but if you try this for 2001 you’ll get Mon 31-Dec 2000. The problem is in the def-<br/>inition of week one of a year. Week one of a year is defined to be the week that con-<br/>tains January 4. You can, therefore, see that if the first Monday of the year is<br/>January 5, then that day is defined as being in week two and the Monday of week<br/>one is, in fact, December 29 of the previous year. We will need to do something a<br/>little more sophisticated. If we calculate which week number contains January 7 and<br/>then find the Monday of that week, we will always get the first Monday in the year.<br/>The code looks like this:<br/>
my $week = Week_Number($year, 1, 7);<br/>
print Date_to_Text(Monday_of_Week($week, $year));<br/>
<i><b>6.4.3</b></i><br/>
<i><b>Date::Manip</b></i><br/>
Date::Manip is, if possible, even bigger and more complex than Date::Calc.<br/>Many of the same functions are available (although, obviously, they often have dif-<br/>ferent names).<br/>
<i><b>Examples: date and time manipulation with Date::Manip<br/></b></i>Let’s once more look at solving our three standard problems.<br/>
<i>Finding the date in x days time<br/></i>With Date::Manip, the code would look like this:<br/>
print UnixDate(DateCalc(ParseDateString('now'), &#34;+${x}d&#34;),<br/>
&#34;%d/%m/%Y %H:%M:%S&#34;);<br/>
# Where $x is the number of days to add<br/>
<i>Finding the date of the previous Saturday<br/></i>Again this is very simple with Date::Manip. We can use the Date_GetPrev func-<br/>tion to get the date immediately. In the call to Date_GetPrev, 6 is for Saturday and<br/>0 is the $curr flag so it won’t return the current date if today is a Saturday.<br/>
my $today = ParseDateString('today');<br/>
my $sat = Date_GetPrev($today, 6, 0);<br/>
print UnixDate($sat, &#34;%d/%m/%Y&#34;);<br/>
<i>Finding the date of the first Monday in a given year<br/></i>This is another problem that is much easier with Date::Manip. We can use<br/>Date_GetNext to get the date of the first Monday after January 1, passing it 1 in<br/>the $curr flag so it returns the current date if it is a Monday.<br/>
<hr/>
<a name=142></a><b>122</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
my $jan_1 = ParseDateString(&#34;1 Jan $year&#34;);<br/>
my $mon = Date_GetNext($jan_1, 1, 1);<br/>
print UnixDate($mon, &#34;%d/%m/%Y&#34;);<br/>
<i><b>6.4.4</b></i><br/>
<i><b>Choosing between date modules</b></i><br/>
We have seen a number of different ways to handle problems involving dates. It<br/>might be difficult to see how to choose between these various methods. My advice:<br/>use built-in Perl functions unless you have a really good reason not to.<br/>
The major reason for this is performance. Date::Manip is a very large module<br/>
which does a number of very complex things and they are all implemented in pure<br/>Perl code. Most things can be handled much more efficiently with custom written<br/>Perl code. I hope I’ve demonstrated that there are very few date manipulations<br/>which can’t be achieved with the standard Perl functions and modules. It is a ques-<br/>tion of balancing the ease of writing the program against the speed at which it runs.<br/>
<i><b>Benchmarking date modules<br/></b></i>As an example, look at this benchmark program which compares the speed of the<br/>Data::Manip ParseDate function with that of a piece of custom Perl code which<br/>builds up the same string using localtime.<br/>
#!/usr/bin/perl -w<br/>
use strict;<br/>
use Date::Manip;<br/>
use Benchmark;<br/>
timethese(5000, {'localtime' =&gt; \&amp;ltime, date_manip =&gt; \&amp;dmanip});<br/>
sub ltime {<br/>
my @now = localtime;<br/>
sprintf(&#34;%4d%02d%02d%02d:%02d:%02d&#34;,<br/>
$now[5] + 1900, ++$now[4], $now[3], $now[2], $now[1], $now[0]);<br/>
}<br/>
sub dmanip {<br/>
ParseDate('now');<br/>
}<br/>
Running this script gives the following output:<br/>
<b>Benchmark: timing 5000 iterations of date_manip, localtime …</b><br/>
<b>date_manip: 29 wallclock secs (28.89 usr +</b><br/>
<b>0.00 sys = 28.89 CPU)</b><br/>
<b>localtime:</b><br/>
<b>2 wallclock secs ( 2.04 usr +</b><br/>
<b>0.00 sys =</b><br/>
<b>2.04 CPU)</b><br/>
As you can see, the standard Perl version is almost fifteen times faster.<br/>
Having seen this evidence, you might be wondering if it is ever a good idea to<br/>
use Date::Manip. There is one very good reason for using Date::Manip, and it is<br/>
<hr/>
<a name=143></a><i><b>Extended example: web access logs</b></i><br/>
<b>123</b><br/>
the ParseDate function itself. If you are ever in a position where you are reading in<br/>a date and you are not completely sure which format it will be in, then ParseDate<br/>will most likely be able to read the date and convert it into a standard form. Here<br/>are some of the more extreme examples of that in action:<br/>
use Date::Manip;<br/>
my @times = ('tomorrow',<br/>
'next wednesday',<br/>
'5 weeks ago');<br/>
foreach (@times) {<br/>
print UnixDate(ParseDate($_), '%d %b %Y'), &#34;\n&#34;;<br/>
}<br/>
which displays:<br/>
<b>08 Feb 2000</b><br/>
<b>09 Feb 2000</b><br/>
<b>03 Jan 2000</b><br/>
(or, rather, the equivalent dates for the date when it is run).<br/>
<i><b>6.5</b></i><br/>
<i><b>Extended example: web access logs</b></i><br/>
One of the most common sources of line-oriented data is a web server access log. It<br/>seems that everyone needs to wring as much information as possible from these files<br/>in order to see if their web site is attracting a large enough audience to justify the<br/>huge sums of money spent on it.<br/>
Most web servers write access logs in a standard format. Here is a sample of a real<br/>
access log. This sample comes from a log written by an Apache web server. Apache<br/>is the Open Source web server which runs more web sites than any other server.<br/>
158.152.136.193 - - [31/Dec/1999:21:27:27 -0800] &#34;GET /index.html HTTP/1.1&#34; 200 2987<br/>
158.152.136.193 - - [31/Dec/1999:21:27:27 -0800] &#34;GET /head.gif HTTP/1.1&#34; 200 4389<br/>
158.152.136.193 - - [31/Dec/1999:21:27:28 -0800] &#34;GET /menu.gif HTTP/1.1&#34; 200 7317<br/>
Each of these lines represents one access request that the server has received. Let’s<br/>look at the fields in one of these lines and see what each one represents.<br/>
The first field is the IP address from which the request came. It is possible in<br/>
most web servers to have these addresses resolved to hostnames before they are<br/>logged, but on a heavily used site this can seriously impact performance, so most<br/>webmasters leave this option turned off.<br/>
The second and third fields (the two dash characters) denote which user made this<br/>
request. These fields will contain interesting data only if the requested page is not<br/>public, so the user must go through some kind of authorization in order to see it.<br/>
<hr/>
<a name=144></a><b>124</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
The fourth field is the date and time of the access. It shows the local date and<br/>
time together with the difference from UTC (so in this case the server is hosted in<br/>the Pacific time zone of the U.S.A.).<br/>
The fifth field shows the actual HTTP request that was made. It is in three parts:<br/>
the request type (in this case, GET), the URL that was requested, and the protocol<br/>used (HTTP/1.1).<br/>
The final two fields contain the response code that was returned to the browser<br/>
(200 means that the request was successful and the contents of the URL have been<br/>sent) and the number of bytes returned.<br/>
Armed with this knowledge we can look at the three lines and work out exactly<br/>
what happened. At half past nine on New Year’s Eve someone at IP address<br/>158.152.136.193 made three requests to the web site. The person requested<br/>index.html, head.gif, and menu.gif. Each of these requests was successful and we<br/>returned a total of 14,000 bytes to them.<br/>
This kind of analysis is very useful and not very difficult, but a busy web site will<br/>
have many thousands of hits every day. How are you supposed to get meaningful<br/>information from that amount of input data? Using Perl, of course.<br/>
It wouldn’t be very difficult to write something to break apart a log line and ana-<br/>
lyze the data, but it’s not completely simple—some fields are separated by spaces,<br/>others have embedded spaces. Luckily this is such a common task that someone has<br/>already written a module to process web access logs. It is called Logfile and you can<br/>find it on the CPAN.<br/>
Using Logfile is very simple. It consists of a number of submodules, each<br/>
tuned to handle a particular type of web server log. They are all subclasses of the<br/>module Logfile::Base. As our access log was generated by Apache we will use<br/>Logfile::Apache.<br/>
Logfile is an object-oriented module, so all processing is carried out via a Logfile<br/>
object. The first thing we need to do is create a Logfile object.<br/>
my $log = Logfile::Apache-&gt;new(File =&gt; 'access_log',<br/>
Group =&gt; [qw(Host Date File Bytes User)]);<br/>
The named parameters to this function make it very easy to follow what is going on.<br/>The File parameter is the name of the access log that you want to analyze. Group is<br/>a reference to a list of indexes that you will want to use to produce reports. The five<br/>indexes listed in the code snippet correspond to sections of the Apache log record.<br/>In addition to these, the module understands a couple of others. Domain is the top<br/>level that the requesting host is in (e.g., .com, .uk, .org), which is calculated from<br/>the hostname. Hour is the hour of the day that the request took place. It is calcu-<br/>lated from the date field.<br/>
<hr/>
<a name=145></a><i><b>Extended example: web access logs</b></i><br/>
<b>125</b><br/>
Having created the Logfile object you can then start to produce reports with it.<br/>
To list our files in order of popularity we can simply do this:<br/>
$log-&gt;report(Group =&gt; 'File');<br/>
which produces a report like this:<br/>
<b>File</b><br/>
<b>Records</b><br/>
<b>==================================</b><br/>
<b>/</b><br/>
<b>11</b><br/>
<b>2.53%</b><br/>
<b>/examples</b><br/>
<b>1</b><br/>
<b>0.23%</b><br/>
<b>/examples/index.html</b><br/>
<b>1</b><br/>
<b>0.23%</b><br/>
<b>/images/graph</b><br/>
<b>1</b><br/>
<b>0.23%</b><br/>
<b>/images/pix</b><br/>
<b>1</b><br/>
<b>0.23%</b><br/>
<b>/images/sidebar</b><br/>
<b>1</b><br/>
<b>0.23%</b><br/>
<b>/images/thumbnail</b><br/>
<b>5</b><br/>
<b>1.15%</b><br/>
<b>/index</b><br/>
<b>1</b><br/>
<b>0.23%</b><br/>
<b>.</b><br/>
<b>.</b><br/>
<b>.</b><br/>
<b>[other lines snipped]</b><br/>
This is an alphabetized list of all of the files that were listed in the access log. We can<br/>make more sense if we sort the output by number of hits and perhaps just list the<br/>top ten files by changing the code like this:<br/>
$log-&gt;report(Group =&gt; 'File', Sort =&gt; 'Records', Top =&gt; 10);<br/>
We then get a more understandable report that looks like this:<br/>
<b>File</b><br/>
<b>Records</b><br/>
<b>==================================</b><br/>
<b>/new/images</b><br/>
<b>129 29.72%</b><br/>
<b>/new/music</b><br/>
<b>80 18.43%</b><br/>
<b>/new/personal</b><br/>
<b>52 11.98%</b><br/>
<b>/new/friends</b><br/>
<b>47 10.83%</b><br/>
<b>/splash/splashes</b><br/>
<b>28</b><br/>
<b>6.45%</b><br/>
<b>/new/pics</b><br/>
<b>26</b><br/>
<b>5.99%</b><br/>
<b>/new/stuff</b><br/>
<b>21</b><br/>
<b>4.84%</b><br/>
<b>/</b><br/>
<b>11</b><br/>
<b>2.53%</b><br/>
<b>/new/splash</b><br/>
<b>6</b><br/>
<b>1.38%</b><br/>
<b>/images/thumbnail</b><br/>
<b>5</b><br/>
<b>1.15%</b><br/>
Perhaps instead of wanting to know the most popular files, you are interested in the<br/>most popular times of the day that people visit your site. You can do this using the<br/>Hour index. The following:<br/>
$log-&gt;report(Group =&gt; 'Hour');<br/>
will list all of the hours in chronological order and <br/>
$log-&gt;report(Group =&gt; 'Hour', Sort =&gt; 'Records');<br/>
<hr/>
<a name=146></a><b>126</b><br/>
CHAPTER <br/>
<i><b>Record-oriented data</b></i><br/>
will order them by the number of hits in each hour. If you want to find the quietest<br/>time of the day, simply reverse the order of the sort<br/>
$log-&gt;report(Group =&gt; 'Hour', Sort =&gt; 'Records', Reverse =&gt; 1);<br/>
There are a number of other types of reports that you can get using Logfile, but it<br/>would be impossible to cover them all here. Have a look at the examples in the<br/>README file and the test files to get some good ideas.<br/>
<i><b>6.6</b></i><br/>
<i><b>Further information</b></i><br/>
For more information about the $/, $, and $&#34; variables (together with other useful<br/>Perl variables) see the perldoc perlvar manual pages.<br/>
For more information about the built-in date handling functions see the<br/>
perldoc perlfunc manual pages.<br/>
For more information about the POSIX::strftime function see the perldoc<br/>
POSIX manual page and your system’s documentation for a list of supported char-<br/>acter sequences.<br/>
Both the Date::Manip and Date::Calc modules are available from the CPAN.<br/>
Having installed them you can read their full documentation by typing perldoc<br/>Date::Manip or perldoc Date::Calc at your command line.<br/>
<i><b>6.7</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
Record-oriented data is very easy to handle in Perl, particularly if you make<br/>appropriate use of the I/O control variables such as $/, $&#34;, and $,.<br/>
■<br/>
The  Text::CSV_XS  CPAN module makes it very easy to read and write<br/>comma-separated values.<br/>
■<br/>
Data caching can speed up your programs when used carefully, and using<br/>Memoize.pm can make adding caching to a program very easy.<br/>
■<br/>
Perl has very powerful built-in date and time processing functions.<br/>
■<br/>
More complex date and time manipulation can be carried out using modules<br/>from CPAN.<br/>
<hr/>
<a name=147></a><img class="yflip" src="dmp-147_1.jpg"/><br/>
<i>7</i><br/>
<i>Fixed-width and</i><br/>
<i>binary data</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Reading fixed-width data<br/>
■<br/>
Using regular expressions with <br/>fixed-width data<br/>
■<br/>
Writing fixed-width data <br/>
■<br/>
Graphics file formats<br/>
■<br/>
Reading and writing MP3 files <br/>
<i>127</i><br/>
<hr/>
<a name=148></a><b>128</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
In this chapter we will complete our survey of simple data formats by examining<br/>fixed-width and binary data. Many of the methods we have discussed in previous<br/>chapters will still prove to be useful, but we will also look at some new tricks. <br/>
<i><b>7.1</b></i><br/>
<i><b>Fixed-width data</b></i><br/>
Fixed-width data is becoming less common, but it is still possible that you will come<br/>across it, particularly if you are exchanging data with an older computer system that<br/>runs on a mainframe or is written in COBOL. <br/>
<i><b>7.1.1</b></i><br/>
<i><b>Reading fixed-width data</b></i><br/>
In a fixed-width data record, there is nothing to distinguish one data item from the<br/>next one. Each data item is simply written immediately after the preceding one,<br/>after padding it to a defined width. This padding can either be with zeroes or with<br/>spaces and can be before or after the data.1 In order to interpret the data, we need<br/>more information about the way it has been written. This is normally sent separately<br/>from the data itself but, as we shall see later, it is also possible to encode this data<br/>within the files.<br/>
Here is an example of two fixed-width data records:<br/>
00374Bloggs &amp; Co<br/>
19991105100103+00015000<br/>
00375Smith Brothers<br/>
19991106001234-00004999<br/>
As you can see, it’s tricky to understand exactly what is going on here. It looks as<br/>though there is an ascending sequence number at the start and perhaps a customer<br/>name. Some of the data in the middle looks like it might be a date—but until we<br/>get a full definition of the data we can’t be sure even how many data fields there are.<br/>
Here is the definition of the data:<br/>
■<br/>
<i>Columns 1 to 5</i>—Transaction number (numeric)<br/>
■<br/>
<i>Columns 6 to 25</i>—Customer name (text)<br/>
■<br/>
<i>Columns 26 to 33</i>—Date of transaction (YYYYMMDD)<br/>
■<br/>
<i>Columns 34 to 39</i>—Customer’s transaction number (numeric)<br/>
■<br/>
<i>Column 40</i>—Transaction direction (+/-)<br/>
■<br/>
<i>Columns 41 to 48</i>—Amount of transaction (numeric with two implied deci-<br/>mal places)<br/>
1 Although it is most common to find numerical data prepadded with zeroes and text data postpadded<br/>
with spaces.<br/>
<hr/>
<a name=149></a><i><b>Fixed-width data</b></i><br/>
<b>129</b><br/>
Now we can start to make some sense of the data. We can see that on Novem-<br/>
ber 5, 1999, we received a check (number 100103) for $150.00 from Bloggs &amp;<br/>Co. and on November 6, 1999, we paid $49.99 to Smith Brothers in response to<br/>their invoice number 1234.<br/>
<i><b>Example: extracting fixed-width data fields with substr<br/></b></i>So how do we go about extracting that information from the data? Here’s a first<br/>attempt using the substr function to do the work:<br/>
my @cols = qw(5 25 33 39 40 48);<br/>
while (&lt;STDIN&gt;) {<br/>
my @rec;<br/>
my $prev = 0;<br/>
foreach my $col (@cols) {<br/>
push @rec, substr($_, $prev, $col - $prev);<br/>
$prev = $col;<br/>
}<br/>
print join('¦', @rec);<br/>
print &#34;\n&#34;;<br/>
}<br/>
While this code works, it’s not particularly easy to understand. We use an array of<br/>column positions to tell us where each column ends. Notice that we’ve actually<br/>used the positions where the columns begin rather than end. This is because the<br/>column definitions that we were given start from column one, whereas Perl arrays<br/>start from zero—all in all, not the most maintainable piece of code. <br/>
<i><b>Example: extracting fixed-width data with regular expressions<br/></b></i>Perhaps we’d do better if we used regular expressions:<br/>
my @widths = qw(5 20 8 6 1 8);<br/>
my $regex;<br/>
$regex .= &#34;(.{$_})&#34; foreach @widths;<br/>
while (&lt;STDIN&gt;) {<br/>
my @rec = /$regex/;<br/>
print join('¦', @rec);<br/>
print &#34;\n&#34;;<br/>
}<br/>
In this case we’ve switched from using column start (or end) positions to using col-<br/>umn widths. It’s not very difficult to build this list given our previous list. We then<br/>use the list of widths to construct a regular expression which we can match against<br/>each row of our data file in turn. The regular expression that we build looks like this:<br/>
<hr/>
<a name=150></a><b>130</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
(.{5})(.{20})(.{8})(.{6})(.{1})(.{8})<br/>
which is really a very simple regular expression. For each column in the data record,<br/>there is an element of the form (.{x}), where x is the width of the column. This<br/>element will match any character x times and the parentheses will save the result of<br/>the match. Matching this regular expression against a data record and assigning the<br/>result to an array will give us a list containing all of the $1, $2, … $n variables in order.<br/>
This isn’t a very interesting use of regular expressions. There must be a better way. <br/>
<i><b>Example: extracting fixed-width data with unpack<br/></b></i>In this case the best way is to use Perl’s unpack function. unpack takes a scalar<br/>expression and breaks it into a list of values according to a template that it is given.<br/>The template consists of a sequence of characters which define the type and size of<br/>the individual fields. A simple way to break apart our current data would be like this:<br/>
my $template = 'a5a20a8a6aa8';<br/>
while (&lt;STDIN&gt;) {<br/>
my @rec = unpack($template, $_);<br/>
print join('¦', @rec);<br/>
print &#34;\n&#34;;<br/>
}<br/>
which returns exactly the same set of data that we have seen in all of the examples<br/>above. In this case our template consists of the letter a for each field followed by the<br/>length of the field (the length is optional on single-character fields like our +/-<br/>field). The a designates each field as an ASCII string, but the template can contain<br/>many other options. For reference, here is one of the data lines that was produced<br/>by the previous example:<br/>
<b>00374¦Bloggs &amp; Co</b><br/>
<b>¦19991105¦100103¦+¦00015000</b><br/>
Notice that the numbers are still prepadded with zeroes and the string is still post-<br/>padded with spaces. Now see what happens if we replace each a in the template<br/>with an A.<br/>
<b>00374¦Bloggs &amp; Co¦19991105¦100103¦+¦00015000</b><br/>
The spaces at the end of the string are removed. Depending on your application,<br/>this may or may not be what you want. Perl gives you the flexibility to choose the<br/>most appropriate route.<br/>
There are a number of other options that can be used in the unpack template<br/>
and we’ll see some more of them when we look at binary data in more detail. For<br/>ASCII data, only a and A are useful.<br/>
<hr/>
<a name=151></a><i><b>Fixed-width data</b></i><br/>
<b>131</b><br/>
<i><b>Multiple record types<br/></b></i>One slight variation of the fixed-width data record has different sets of data fields for<br/>different types of data within the same file. Consider a system that maintains a prod-<br/>uct list and, at the end of each day, produces a file that lists all new products added<br/>and old products deleted during the day. For a new product, you will need a lot of<br/>data (perhaps product code, description, price, stock count and supplier identifier).<br/>For the deleted product you only need the product code (but you might also list the<br/>product description to make the report easier to follow). Each record will have some<br/>kind of identifier and the start of the line denoting which kind of record it is. In our<br/>example they will be the strings ADD and DEL. Here are some sample data:<br/>
ADD0101Super Widget<br/>
00999901000SUPP01<br/>
ADD0102Ultra Widget<br/>
01499900500SUPP01<br/>
DEL0050Basic Widget<br/>
DEL0051Cheap Widget<br/>
On the day covered by this data, we have added two new widgets to our product<br/>catalogue. The Super Widget (product code 0101) costs $99.99 and we have 1000<br/>in stock. The Ultra Widget (product code 0102) costs $149.99 and we have 500 in<br/>stock. We purchase both new widgets from the same supplier. At the same time we<br/>have discontinued two older products, the Basic Widget (Product Code 0050) and<br/>the Cheap Widget (Product Code 0051).<br/>
<i><b>Example: reading multiple fixed-width record types<br/></b></i>A program to read a file such as the previous example might look like this:<br/>
my %templates = (ADD =&gt; 'a4A14a6a5a6',<br/>
DEL =&gt; 'a4A14');<br/>
while (&lt;STDIN&gt;) {<br/>
my ($type, $data) = unpack('a3a*', $_);<br/>
my @rec = unpack($templates{$type}, $data);<br/>
print &#34;$type - &#34;, join('¦', @rec);<br/>
print &#34;\n&#34;;<br/>
}<br/>
In this case we are storing the two possible templates in a hash and unpacking the<br/>data in two stages. In the first stage we separate the record type from the main part<br/>of the data. We then use the record type to choose the appropriate template to<br/>unpack the rest of the data. One thing that we haven’t seen before is the use of * as<br/>a field length to mean “use all characters to the end of the string.” This is very use-<br/>ful when we don’t know how long our string will be.<br/>
<hr/>
<a name=152></a><b>132</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
<i><b>Data with no end-of-record marker<br/></b></i>Another difference that you may come across with fixed-width data is that some-<br/>times it comes without a defined end-of-record marker. As both the size of each field<br/>in a record and the number of fields in a record are well defined, we know how long<br/>each record will be. It is, therefore, possible to send the data as a stream of bytes and<br/>leave it up to the receiving program to split the data into individual records.<br/>
Perl, of course, has a number of ways to do this. You could read the whole file<br/>
into memory and split the data using substr or unpack, but for many tasks the<br/>amount of data to process makes this unfeasible.<br/>
The most efficient way is to use a completely different method of reading your<br/>
data. In addition to the &lt;FILE&gt; syntax that reads data from file handles one record<br/>at a time, Perl supports a more traditional syntax using the read and seek func-<br/>tions. The read function takes three or four arguments. The first three are: a file<br/>handle to read data from, a scalar variable to read the data into, and the maximum<br/>number of bytes to read. The fourth, optional, argument is an offset into the vari-<br/>able where you want to start writing the data (this is rarely used). read returns the<br/>number of bytes read (which can be less than the requested number if you are near<br/>the end of a file) and zero when there is no more data to read. <br/>
Each open file handle has a current position associated with it called a file pointer<br/>
and read takes its data from the file pointer and moves the pointer to the end of the<br/>data it has read. You can also reposition the file pointer explicitly using the seek<br/>function. seek takes three arguments: the file handle, the offset you wish to move<br/>to, and a value that indicates how the offset should be interpreted. If this value is 0<br/>then the offset is calculated from the start of the file, if it is 1 the offset is calculated<br/>from the current position, and if it is 2 the offset is calculated from the end of the<br/>file. You can always find out the current position of the file pointer by using tell,<br/>which returns the offset from the start of the file in bytes. seek and tell are often<br/>unnecessary when handling ASCII fixed-width data files, as you usually just read the<br/>file in sequential order.<br/>
<i><b>Example: reading data with no end-of-record markers using read<br/></b></i>As an example, if our previous data file were written without newlines, we could use<br/>code like this to read it (obviously we could use any of the previously discussed<br/>techniques to split the record up once we have read it):<br/>
my $template = 'A5A20A8A6AA8';<br/>
my $data;<br/>
while (read STDIN, $data, 48) {<br/>
my @rec = unpack($template, $data);<br/>
<hr/>
<a name=153></a><i><b>Fixed-width data</b></i><br/>
<b>133</b><br/>
print join('¦', @rec);<br/>
print &#34;\n&#34;;<br/>
}<br/>
<i><b>Example: reading multiple record types without end-of-record markers<br/></b></i>It is also possible to handle variable length, fixed-width records using a method sim-<br/>ilar to this. In this case we read 3 bytes first to get the record type and then use this<br/>to decide how many more bytes to read on a further pass.<br/>
my %templates = (ADD =&gt; {len =&gt; 35,<br/>
tem =&gt; 'a4A14a6a5a6'},<br/>
DEL =&gt; {len =&gt; 18,<br/>
tem =&gt; 'a4A14'});<br/>
my $type;<br/>
while (read STDIN, $type, 3) {<br/>
read STDIN, $data, $templates{$type}-&gt;{len};<br/>
my @rec = unpack($templates{$type}-&gt;{tem}, $data);<br/>
print &#34;$type - &#34;, join('¦', @rec);<br/>
print &#34;\n&#34;;<br/>
}<br/>
<i><b>Defining record structure within the data file<br/></b></i>I mentioned earlier that it is possible that the structure of the data could be defined<br/>in the file. You could then write your script to be flexible enough that it handles<br/>any changes in the structure (assuming that the definition of the structure remains<br/>the same).<br/>
There are a number of ways to encode this metadata, most of them based around<br/>
putting the information in the first row of the file. In this case you would read the<br/>first line separately and parse it to extract the data. You would then use this informa-<br/>tion to build the format string that you pass to unpack. Here are a couple of the<br/>encoding methods that you might find—and how to deal with them.<br/>
<i>Fixed-width numbers indicating column widths<br/></i>In this case, the first line will be a string of numbers. You will be told how long each<br/>number is (probably two or three digits). You can unpack the record into an array<br/>of numbers. Each of these numbers is the width of one field. You can, therefore,<br/>build up an unpack format to use on the rest of the file.<br/>
my $line = &lt;STDIN&gt;;<br/>
# The metadata line<br/>
my $width = 3;<br/>
# The width of each number in $line;<br/>
my $fields = length($line) / $width;<br/>
my $meta_fmt = 'a3' x $fields;<br/>
my @widths = unpack($meta_fmt, $line);<br/>
<hr/>
<a name=154></a><b>134</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
my $fmt = join('', map { &#34;A$_&#34; } @widths);<br/>
while (&lt;STDIN&gt;) {<br/>
my @data = unpack($fmt, $_);<br/>
# Do something useful with the fields in @data<br/>
}<br/>
Notice that we can calculate the number of fields in each record by dividing the<br/>length of the metadata record by the width of each number in it. It might be useful<br/>to add a sanity check at that point to ensure that this calculation gives an integer<br/>answer as it should.<br/>
Using this method our financial data file would look like this:<br/>
<b>005020008006001008</b><br/>
<b>00374Bloggs &amp; Co</b><br/>
<b>19991105100103+00015000</b><br/>
<b>00375Smith Brothers</b><br/>
<b>19991106001234-00004999</b><br/>
The first line contains the field widths (5, 20, 8, 6, 1, and 8), all padded out to<br/>three digit numbers.<br/>
<i>Field-end markers<br/></i>In this method, the first row in the file is a blank row that contains a marker (per-<br/>haps a | character) wherever a field will end in the following rows. In other words,<br/>our example file would look like this:<br/>
|<br/>
|<br/>
|<br/>
||<br/>
|<br/>
00374Bloggs &amp; Co<br/>
19991105100103+00015000<br/>
00375Smith Brothers<br/>
19991106001234-00004999<br/>
To deal with this metadata, we can split the row on the marker character and use<br/>the length of the various elements to calculate the lengths of the fields:<br/>
my $line = &lt;STDIN&gt;; # The metadata line<br/>
chomp $line;<br/>
my $mark = '|'; # The field marker<br/>
my @fields = split($mark, $line);<br/>
my @widths = map { length($_) + 1 } @fields;<br/>
my $fmt = join('', map { &#34;A$_&#34; } @widths);<br/>
while (&lt;STDIN&gt;) {<br/>
chomp;<br/>
my @data = unpack($fmt, $_);<br/>
# Do something useful with the fields in @data<br/>
}<br/>
Notice that we add one to the length of each element to get the width. This is<br/>because the marker character is not included in the array returned by the split, but it<br/>should be included in the width of the field. <br/>
<hr/>
<a name=155></a><i><b>Fixed-width data</b></i><br/>
<b>135</b><br/>
These are just two common ways to encode field structures in a fixed-width data<br/>
file. You will come across others, but it is always a case of working out the best way<br/>to extract the required information from the metadata record. Of course, if you<br/>have any influence in the design of your input file, you might like to suggest that<br/>the first line contains the format that you need to pass to unpack—let your source<br/>system do the hard work!<br/>
<i><b>7.1.2</b></i><br/>
<i><b>Writing fixed-width data </b></i><br/>
If you have to read fixed-width data there is, of course, a chance that eventually you<br/>will need to write it. In this section we’ll look at some common ways to do this.<br/>
<i><b>Writing fixed-width data using pack<br/></b></i>Luckily, Perl has a function which is the opposite of unpack and, logically enough,<br/>it is called pack. pack takes a template and a list of values and returns a string con-<br/>taining the list packed according to the rules given by the template. Once again the<br/>full power of pack will be useful when we look at binary data, but for ASCII data we<br/>will just use the A and a template options. These options have slightly different<br/>meanings in a pack template than the ones they have in an unpack template.<br/>Table 7.1 summarizes these differences.<br/>
Table 7.1<br/>
Meanings of A and a in pack and unpack templates<br/>
A<br/>
a<br/>
pack<br/>
Pad string with spaces<br/>
Pad string with null characters<br/>
unpack<br/>
Strip trailing nulls and spaces<br/>
Leave trailing nulls and spaces<br/>
Therefore, if we have a number of strings and wish to pack them into a fixed-<br/>
width data record, we can do something like this:<br/>
my @strings = qw(Here are a number of strings);<br/>
my $template = 'A6A6A3A8A4A10';<br/>
print pack($template, @strings), &#34;\n&#34;;<br/>
and our strings will all be space padded to the sizes given in the pack template.<br/>There is, however, a problem padding numbers using this method, as Perl doesn’t<br/>know the difference between text fields and numerical fields, so you end up with<br/>numbers postpadded with spaces (or nulls, depending on the template you use).<br/>This may, of course, be fine for your data, but if you want to prepad numbers with<br/>spaces then you should use the sprintf or printf functions.<br/>
<hr/>
<a name=156></a><b>136</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
<i><b>Writing fixed-width data using printf and sprintf<br/></b></i>These two functions do very similar things. The only difference is that sprintf<br/>returns its results in a scalar variable, whereas printf will write them directly to a<br/>file handle. Both of the functions take a format description followed by a list of val-<br/>ues which are substituted into the format string. The contents of the format string<br/>control how the values appear in the final result. At each place in the format string<br/>where you want a value to be substituted you place a format specifier in the format<br/>%m.nx, where m and n control the size of the field and x controls how the value<br/>should be interpreted. Full details of the syntax for format specifiers can be found in<br/>your Perl documentation but, for our current purposes, a small subset will suffice.<br/>
To put integers into the string, use the format specifier %d;2 to force the field to<br/>
be five characters wide, use the format specifier %5d; and to prepad the field with<br/>zeroes, use %05d. Here is an example which demonstrates these options:<br/>
my @formats = qw(%d %5d %05d);<br/>
my $num = 123;<br/>
foreach (@formats) {<br/>
printf &#34;¦$_¦\n&#34;, $num;<br/>
}<br/>
Running this code produces the following results:<br/>
<b>¦123¦</b><br/>
<b>¦</b><br/>
<b>123¦</b><br/>
<b>¦00123¦</b><br/>
You can do similar things with floating point numbers using %f. In this case you can<br/>control the total width of the field and also the number of characters after the deci-<br/>mal point by using notation such as %6.2f (for a 6 character field with two charac-<br/>ters after the decimal point). Here is an example of this:<br/>
my @formats = qw(%f %6.2f %06.2f);<br/>
my $num = 12.3;<br/>
foreach (@formats) {<br/>
printf &#34;¦$_¦\n&#34;, $num;<br/>
}<br/>
which gives the following results (notice that the default number of decimal places<br/>is six):<br/>
<b>¦12.300000¦</b><br/>
<b>¦ 12.30¦</b><br/>
<b>¦012.30¦</b><br/>
2 %d is actually for a signed integer. If you need an unsigned value, use %u.<br/>
<hr/>
<a name=157></a><i><b>Fixed-width data</b></i><br/>
<b>137</b><br/>
For strings we can use the format specifier %s. Again, we can use a number within<br/>the specifier to define the size of the field. You’ll notice from the previous examples<br/>that when the data was smaller than the field it was to be used in, the data was right<br/>justified within the field. With numbers, that is generally what you want (especially<br/>when you are going to prepad the number with zeroes) but, as we’ve seen previ-<br/>ously, text is often left justified and postpadded with spaces. In order to left justify<br/>the text we can prepend a minus sign to the size specifier. Here are some examples:<br/>
my @formats = qw(%s %10s %010s %-10s %-010s);<br/>
my $str = 'Text';<br/>
foreach (@formats) {<br/>
printf &#34;¦$_¦\n&#34;, $str;<br/>
}<br/>
which gives the following output:<br/>
<b>¦Text¦</b><br/>
<b>¦</b><br/>
<b>Text¦</b><br/>
<b>¦000000Text¦</b><br/>
<b>¦Text</b><br/>
<b>¦</b><br/>
<b>¦Text</b><br/>
<b>¦</b><br/>
Notice that we can prepad strings with zeroes just as we can for numbers, but it’s<br/>difficult to think of a situation where that would be useful.<br/>
<i><b>Example: writing fixed-width data with sprintf<br/></b></i>Putting this all together, we can produce code which can output fixed-width finan-<br/>cial transaction records like the ones we were reading earlier.<br/>
my %rec1 = ( txnref =&gt; 374,<br/>
cust<br/>
=&gt; 'Bloggs &amp; Co',<br/>
date<br/>
=&gt; 19991105,<br/>
extref =&gt; 100103,<br/>
dir<br/>
=&gt; '+',<br/>
amt<br/>
=&gt; 15000 );<br/>
my %rec2 = ( txnref =&gt; 375,<br/>
cust<br/>
=&gt; 'Smith Brothers',<br/>
date<br/>
=&gt; 19991106,<br/>
extref =&gt; 1234,<br/>
dir<br/>
=&gt; '-',<br/>
amt<br/>
=&gt; 4999 );<br/>
my @cols = (<br/>
{ name<br/>
=&gt; 'txnref',<br/>
width =&gt; 5,<br/>
num<br/>
=&gt; 1 },<br/>
{ name<br/>
=&gt; 'cust',<br/>
<hr/>
<a name=158></a><b>138</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
width =&gt; 20,<br/>
num<br/>
=&gt; 0 },<br/>
{ name<br/>
=&gt; 'date',<br/>
width =&gt; 8,<br/>
num<br/>
=&gt; 1 },<br/>
{ name<br/>
=&gt; 'extref',<br/>
width =&gt; 6,<br/>
num<br/>
=&gt; 1 },<br/>
{ name<br/>
=&gt; 'dir',<br/>
width =&gt; 1,<br/>
num<br/>
=&gt; 0 },<br/>
{ name<br/>
=&gt; 'amt',<br/>
width =&gt; 8,<br/>
num<br/>
=&gt; 1 } );<br/>
my $format = build_fmt(\@cols);<br/>
print fixed_rec(\%rec1, \@cols, $format);<br/>
print fixed_rec(\%rec2, \@cols, $format);<br/>
sub build_fmt {<br/>
my $cols = shift;<br/>
my $fmt;<br/>
foreach (@$cols) {<br/>
if ($_-&gt;{num}) {<br/>
$fmt .= &#34;%0$_-&gt;{width}s&#34;;<br/>
} else {<br/>
$fmt .= &#34;%-$_-&gt;{width}s&#34;;<br/>
}<br/>
}<br/>
return $fmt;<br/>
}<br/>
sub fixed_rec {<br/>
my ($rec, $cols, $fmt) = @_;<br/>
my @vals = map { $rec-&gt;{$_-&gt;{name}} } @$cols;<br/>
sprintf(&#34;$fmt\n&#34;, @vals);<br/>
}<br/>
In this program, we use an array of hashes (@cols) to define the characteristics of<br/>each data field in our record. These characteristics include the name of the column<br/>together with the width that we want it to be in the output, and a flag indicating<br/>whether or not it is a numeric field. We then use the data in this array to build a<br/>suitable sprintf format string in the function build_fmt. The fixed_rec func-<br/>tion then extracts the relevant data from the record (which is stored in a hash) into<br/>
<hr/>
<a name=159></a><i><b>Binary data</b></i><br/>
<b>139</b><br/>
an array and feeds that array to sprintf along with the format. This creates our<br/>fixed-width record. As expected, the results of running this program are the records<br/>that we started with at the beginning of this chapter.<br/>
<i><b>7.2</b></i><br/>
<i><b>Binary data</b></i><br/>
All of the data that we have looked at so far has been ASCII data. That is, it has been<br/>encoded using a system laid down by the American Standards Committee for Infor-<br/>mation Interchange. In this code, 128 characters3 have been given a numerical<br/>equivalent value from 0 to 127. For example, the space character is number 32, the<br/>digits 0 to 9 have the numbers 48 to 57, and the letters of the alphabet appear from<br/>65 to 90 in upper case and from 97 to 122 in lower case. Other numbers are taken<br/>up by punctuation marks and various control characters. <br/>
When an ASCII character is written to a file, what is actually written is the binary<br/>
version of the ASCII code for the given character. For example the number 123<br/>would be written to the file as 00110001 00110010 00110011 (the binary equiva-<br/>lents of 49, 50, and 51). The advantage of this type of data is that it is very easy to<br/>write software that allows users to make sense of the data. All you need to do is con-<br/>vert each byte of data into its equivalent ASCII character. The major disadvantage is<br/>the amount of space used. In the previous example we used 3 bytes of data to store<br/>a number, but if we had stored the binary number 01111011 (the binary equivalent<br/>of 123) we could have used a third of the space.<br/>
For this reason, there are a number of applications which store data in binary for-<br/>
mat. In many cases these are proprietary binary formats which are kept secret so<br/>that one company has a competitive advantage over another. A good example of<br/>this is spreadsheets. Microsoft and Lotus have their own spreadsheet file format<br/>and, although Lotus 123 can read Microsoft Excel files, each time a new feature is<br/>added to Excel, Lotus has to do more work to ensure that its Excel file converter<br/>can handle the new feature. Other binary file formats are in the public domain and<br/>can therefore be used easily by applications from many different sources. Probably<br/>the best example of this is in graphics files, where any number of applications across<br/>many different platforms can happily read and write each other’s files.<br/>
We’ll start by writing a script that can extract useful data from a graphics file. The<br/>
most ubiquitous graphics file format (especially across the Internet) is the CompuServe<br/><i>Graphics Interchange Format</i> (or GIF). Unfortunately for us, this file format uses a pat-<br/>ented data compression technique and the owners of the patent (Unisys) are trying to<br/>
3 There are a number of extensions to the ASCII character set which define 256 characters, but the fact that<br/>
they are nonstandard can make dealing with them problematic.<br/>
<hr/>
<a name=160></a><b>140</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
ensure that only properly licensed software is used to create GIF files.4 As Perl is Open<br/>Source, it does not fall into this category, and you shouldn’t use it to create GIFs. I<br/>believe that using Perl to read GIFs would not violate the licensing terms, but to be<br/>sure we’ll look at the <i>Portable Network Graphics</i> (PNG) format instead.<br/>
<i><b>7.2.1</b></i><br/>
<i><b>Reading PNG files</b></i><br/>
In order to read any binary file, you will need a definition of the format. I’m using<br/>the definition in <i>Programming Web Graphics with Perl &amp; GNU Software</i> by Shawn<br/>P. Wallace (O’Reilly), but you can get the definitive version from the PNG group<br/>home page at http://www.cdrom.com/pub/png/.<br/>
<i><b>Reading the file format signature<br/></b></i>Most binary files start with a <i>signature</i>, that is a few bytes that identify the format of<br/>the file. This is so that applications that are reading the file can easily check that the<br/>file is in a format that they can understand. In the case of PNG files, the first 8 bytes<br/>always contain the hex value 0x89 followed by the string PNG\cM\cJ\cZ\cM. In<br/>order to check that a file is a valid PNG file, you should do something like this:<br/>
my data;<br/>
read(PNG, $data, 8);<br/>
die &#34;Not a valid PNG\n&#34; unless $data eq '\x89PNG\cM\cJ\cZ\cM';<br/>
Note that we use \x89 to match the hex number 0x89 and \cZ to match Control-Z. <br/>
<i><b>Reading the data chunks<br/></b></i>After this header sequence, a PNG file is made up of a number of <i>chunks</i>. Each<br/>chunk contains an 8-byte header, some amount of data, and a 4-byte trailer. Each<br/>header record contains the length in a 4-byte integer followed by four characters<br/>indicating the type of the chunk. The length field gives you the number of bytes<br/>that you should read from the file and the type tells you how to process it. There are<br/>a number of different chunk types in the PNG specification, but we will look only at<br/>the IHDR (header) chunk, which is always the first chunk in the file and defines cer-<br/>tain global attributes of the image. <br/>
<i><b>Example: reading a PNG file<br/></b></i>A complete program to extract this data from a PNG file (passed in via STDIN) looks<br/>like this:<br/>
4 You can read more about this dispute in Lincoln Stein’s excellent article at:<br/>
http://www.webtechniques.com/archives/1999/12/webm/.<br/>
<hr/>
<a name=161></a><i><b>Binary data</b></i><br/>
<b>141</b><br/>
binmode STDIN;<br/>
my $data;<br/>
read(STDIN, $data, 8);<br/>
die &#34;Not a PNG file&#34; unless $data eq &#34;\x89PNG\cM\cJ\cZ\cM&#34;;<br/>
while (read(STDIN, $data, 8)) {<br/>
my ($size, $type) = unpack('Na4', $data);<br/>
print &#34;$type ($size bytes)\n&#34;;<br/>
read(STDIN, $data, $size);<br/>
if ($type eq 'IHDR') {<br/>
my ($w, $h, $bitdepth, $coltype, $comptype, $filtype, $interlscheme) =<br/>
unpack('NNCCCCC', $data);<br/>
print &lt;&lt; &#34;END&#34;;<br/>
Width: $w, Height: $h<br/>
Bit Depth: $bitdepth, Color Type: $coltype<br/>
Compression Type: $comptype, Filtering Type: $filtype<br/>
Interlace Scheme: $interlscheme<br/>
END<br/>
}<br/>
read(STDIN, $data, 4);<br/>
}<br/>
The first thing to do when dealing with binary data is to put the file handle that you<br/>will be reading into binary mode by calling binmode on it. This is necessary on<br/>operating systems which differentiate between binary and text files (these include<br/>DOS and Windows). On these operating systems, a \cM\cJ end-of-line marker in a<br/>text file gets translated to \n as it is read in. If this sequence appears in a binary file,<br/>it needs to be left untouched. Operating systems, such as UNIX, don’t make this<br/>binary/text differentiation, so under them binmode has no effect. For reasons of<br/>portability it is advisable to always call this function.<br/>
Having called binmode, we can then start reading our binary data. As we saw<br/>
before, the first thing that we do is to read the first 8 bytes and check them<br/>against the signature for PNG files. If it matches we continue, otherwise we termi-<br/>nate the program.<br/>
We then go into a while loop, reading the header of each chunk in the file. We<br/>
read 8 bytes of raw data and convert it into something easier to understand using<br/>unpack. Notice that we use N to extract the 4-byte integer and a4 to extract the<br/>4-character string. The full set of options that you can use in an unpack format<br/>string is given in the documentation that came with your Perl distribution. It is in<br/>the perlfunc manual page (and notice that the full set of options is listed under<br/>the pack function). Having established the type of the chunk and the amount of<br/>data that it contains, we can read in that amount of data from the file. In our pro-<br/>gram we also display the information to the user.<br/>
<hr/>
<a name=162></a><b>142</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
The type of the chunk determines how we process the data we have read. In our<br/>
case, we are only dealing with the IHDR chunk, and that is defined as two 4-byte<br/>integers followed by five single-character strings. We can, therefore, split the data<br/>apart using the unpack format NNCCCCC. The definition of these fields is in the PNG<br/>documentation but there is a <i>précis</i> in table 7.2.<br/>
Table 7.2<br/>
Elements of a PNG IHDR chunk<br/>
Field<br/>
Type<br/>
Description<br/>
Width<br/>
4-byte integer<br/>
The width of the image in pixels<br/>
Height<br/>
4-byte integer<br/>
The height of the image in pixels<br/>
Bit Depth<br/>
1-byte character<br/>
The number of bits used to represent the color of each pixel<br/>
Color Type<br/>
1-byte character<br/>
Code indicating how colors are encoded within the image. <br/>Valid values are:<br/>
0: A number from 0–255 indicating the greyscale value<br/>2: Three numbers from 0–255 indicating the amount of red, <br/>
green, and blue<br/>
3: A number which is an index into a color table<br/>4: A greyscale value (0–255) followed by an alpha mask<br/>6: An RGB triplet (as is 2, above) followed by an alpha mask<br/>
Compression Type<br/>
1-byte character<br/>
The type of compression used (always 0 in PNG version 1.0)<br/>
Filtering Type<br/>
1-byte character<br/>
The type of filtering applied to the data (always 0 in PNG ver-<br/>sion 1.0)<br/>
Interlacing Scheme<br/>
1-byte character<br/>
The interlacing scheme used to store the data. For PNG ver-<br/>sion 1.0 this is either 0 (for no interlacing) or 1 (for Adam7 <br/>interlacing)<br/>
Having unpacked this data into more useable chunks we can display it. It may be<br/>
more useful to translate some of the numbers to descriptive strings, but we won’t<br/>do that in this example.<br/>
After reading and processing the chunk data, we need only to read in the 4 bytes<br/>
which make up the chunk footer. This value can be used as a checksum against the<br/>data in the chunk to ensure that it has not been corrupted. In this simple example<br/>we will throw it away.<br/>
Our program then goes on to read all of the other chunks in turn. It doesn’t<br/>
process them, it simply displays the type and size of each chunk it finds. A more<br/>complex program would need to read the PNG specification and work out how to<br/>process each type of chunk.<br/>
<hr/>
<a name=163></a><i><b>Binary data</b></i><br/>
<b>143</b><br/>
<i><b>Testing the PNG file reader<br/></b></i>To test this program I created a simple PNG file that was 100 pixels by 50 pixels,<br/>containing some simple text on a white background. As the program expects to<br/>read the PNG file from STDIN, I ran the program like this:<br/>
read_png.pl &lt; test.png<br/>
and the output I got looked like this:<br/>
<b>IHDR (13 bytes)</b><br/>
<b>Width: 100, Height: 50</b><br/>
<b>Bit Depth: 8, Color Type: 2</b><br/>
<b>Compression Type: 0, Filtering Type: 0</b><br/>
<b>Interlace Scheme: 0</b><br/>
<b>tEXt (21 bytes)</b><br/>
<b>tIME (7 bytes)</b><br/>
<b>pHYs (9 bytes)</b><br/>
<b>IDAT (1135 bytes)</b><br/>
<b>IEND (0 bytes)</b><br/>
From this we can see that my file was, indeed, 100 pixels by 50 pixels. There were 8<br/>bits per pixel and they were in RGB triplets. No compression, filtering, or interlac-<br/>ing was used. After the IHDR chunk, you can see various other chunks. The impor-<br/>tant one is the IDAT chunk which contains the actual image data.<br/>
<i><b>CPAN modules<br/></b></i>There are, of course, easier ways to get to this information than by writing your own<br/>program. In particular, Gisle Aas has written a module called Image::Info which is<br/>available from the CPAN. Currently (version 0.04) the module supports PNG, JPG,<br/>TIFF, and GIF file formats, and no doubt more will follow. Reading the source code<br/>for this module will give you more useful insights into reading binary files using Perl.<br/>
<i><b>7.2.2</b></i><br/>
<i><b>Reading and writing MP3 files</b></i><br/>
Another binary file format that has been getting a lot of publicity recently is the<br/>MP35 file. These files store near-CD quality sound in typically a third of the space<br/>required by raw CD data. This has led to a whole new drain on Internet bandwidth<br/>as people upload their favorite tracks to their web sites.<br/>
We won’t look at reading or writing the actual audio data in an MP3 file (encod-<br/>
ing audio data is a large enough field to deserve several books of description), but<br/>we will look at the ID3 data which is stored at the end of an MP3 file. The ID3 tags<br/>allow you to store useful information about the sounds contained in the file within<br/>
5 Short for MPEG3 or Motion Pictures Experts Group—Audio Level 3.<br/>
<hr/>
<a name=164></a><b>144</b><br/>
CHAPTER <br/>
<i><b>Fixed-width and binary data</b></i><br/>
the file itself. This includes obvious fields such as the artist, album, track name, and<br/>year of release, together with more obscure data like the genre of the track and the<br/>copyright and distribution information.<br/>
Chris Nandor has written a module which allows you to read and write these<br/>
data fields. The module is called MPEG::MP3Info and it is available from the CPAN.<br/>Using the module is very simple. Here is a sample program which displays all of the<br/>ID3 data that it can find in a given MP3 file:<br/>
use MPEG::MP3Info;<br/>
my $file = shift;<br/>
my $tag = get_mp3tag($file);<br/>
my $info = get_mp3info($file);<br/>
print &#34;Filename: $file\n&#34;;<br/>
print &#34;MP3 Tags\n&#34;;<br/>
foreach (sort keys %$tag) {<br/>
print &#34;$_ : $tag-&gt;{$_}\n&#34;;<br/>
}<br/>
print &#34;MP3 Info\n&#34;;<br/>
foreach (sort keys %$info) {<br/>
print &#34;$_ : $info-&gt;{$_}\n&#34;;<br/>
}<br/>
Notice that there are two separate parts of the ID3 data. The data returned in $tag<br/>is the data about the sound contained in the file—like track name, artist, and year of<br/>release. The data returned in $info tend to be more physical data about the actual<br/>data in the file—the bit-rate, frequency, and whether the recording is stereo or<br/>mono. For this reason, the module currently (and I’m looking at version 0.71) con-<br/>tains a set_mp3tag function, but not a set_mp3info function. It is likely that<br/>you’ll have good reasons to change the ID3 tags which defined the track and artist,<br/>but less likely that you’ll ever need to change the physical recording parameters.<br/>There is also a remove_mp3tag function which removes the ID3 data from the end<br/>of the file.<br/>
As with Image::Info which we discussed earlier, it is very instructive to read the<br/>
code of this module as it will give you many useful ideas on the best way to read and<br/>write your binary data.<br/>
<i><b>7.3</b></i><br/>
<i><b>Further information</b></i><br/>
This chapter has discussed a number of built-in Perl functions. These include pack,<br/>unpack, read, printf, and sprintf. For more information about any built-in<br/>Perl function see the perldoc perlfunc manual page. The list of type specifiers<br/>
<hr/>
<a name=165></a><i><b>Summary</b></i><br/>
<b>145</b><br/>
supported by sprintf and printf is system-dependent, so you can get this infor-<br/>mation from your system documentation.<br/>
The Image::Info and MPEG::MP3Info modules are both available from the<br/>
CPAN. Having installed them, you will be able to read their full documentation by<br/>typing perldoc Image::Info or perldoc MPEG::MP3Info at your command line.<br/>
<i><b>7.4</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
The easiest way to split apart a fixed-width data record is by using the unpack<br/>function.<br/>
■<br/>
Conversely, the easiest way to create a fixed-width data record is by using the<br/>pack function.<br/>
■<br/>
If your data doesn’t have distinct end-of-record markers, you can read a cer-<br/>tain number of bytes from your input data stream using the read function.<br/>
■<br/>
Once you have used the binmode function on a binary data stream it can be<br/>processed using exactly the same techniques as a text data stream.<br/>
<hr/>
<a name=166></a><hr/>
<a name=167></a><i>Part III</i><br/>
<i>Simple data parsing</i><br/>
As this part of the tale commences, our heroes begin to realize<br/>
that there are very good reasons for the beast to appear in more com-<br/>plex forms, and they see that their current techniques will be of limited<br/>use against these new forms. They begin to discuss more powerful tech-<br/>niques to attack them.  <br/>
The beast then appears in a new, hierarchical format. Luckily, our<br/>
heroes find a source of ready-made tools for defeating this form.<br/>
The beast appears once again in a more complex (and yet, in some<br/>
ways, simplified) guise and our heroes once more find ready-built tools<br/>for defeating this form.<br/>
At the end of this part of the tale, our heroes develop techniques<br/>
which let them build their own tools to tackle the beast whenever it<br/>appears in forms of arbitrary complexity. <br/>
<hr/>
<a name=168></a><hr/>
<a name=169></a><img class="yflip" src="dmp-169_1.jpg"/><br/>
<i>8</i><br/>
<i>Complex data formats</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Using and processing more complex <br/>data formats<br/>
■<br/>
Limitations in data parsing <br/>
■<br/>
What are parsers and why should I <br/>use them?<br/>
■<br/>
Parsers in Perl<br/>
<i>149</i><br/>
<hr/>
<a name=170></a><b>150</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
We have now completed our survey of the simple data formats that you will come<br/>across. There is, however, a whole class of more complex data formats that you will<br/>inevitably be called upon to munge at some point. The increased flexibility that<br/>these formats give us for data storage comes at a price, as they will take more time<br/>to process. In this chapter we take a look at these types of data, how you discern<br/>when to use them, and how you go about processing them.<br/>
<i><b>8.1</b></i><br/>
<i><b>Complex data files</b></i><br/>
A lot of the data that we have seen up to now has used one line to represent each<br/>record in the data set. There have been exceptions; some of the records that we saw<br/>in chapter 6 used more than one row for each record, and most of the binary data<br/>that we discussed in chapter 7 had no record-based structure at all. Even going back<br/>to the very first chapter, the first sample CD data set that we saw consisted largely of<br/>a record-based middle section, but it also has header and footer records which<br/>would have made processing it slightly more complex.<br/>
<i><b>8.1.1</b></i><br/>
<i><b>Example: metadata in the CD file </b></i><br/>
Let’s take another look at that first sample data file.<br/>
Dave's CD Collection<br/>
16 Sep 1999<br/>
Artist<br/>
Title<br/>
Label<br/>
Released<br/>
--------------------------------------------------------<br/>
Bragg, Billy<br/>
Workers' Playtime<br/>
Cooking Vinyl<br/>
1987<br/>
Bragg, Billy<br/>
Mermaid Avenue<br/>
EMI<br/>
1998<br/>
Black, Mary<br/>
The Holy Ground<br/>
Grapevine<br/>
1993<br/>
Black, Mary<br/>
Circus<br/>
Grapevine<br/>
1996<br/>
Bowie, David<br/>
Hunky Dory<br/>
RCA<br/>
1971<br/>
Bowie, David<br/>
Earthling<br/>
EMI<br/>
1987<br/>
6 Records<br/>
As you can see, the data consists of three clearly delimited sections. The main body<br/>of the file contains the meat of the report—a list of the CDs in my record collection,<br/>giving information on artist, title, recording label, and year of release. However, the<br/>header and footer records also contain important data. <br/>
The header contains information about the data file as a whole, telling us whose CD<br/>
collection it is and the date on which this snapshot is valid. It would be inappropriate to<br/>list this information for each record in the file, so the header is a good place to put it.1<br/>
1 There are other places where the information could be stored. One common solution is to store this kind<br/>
of information in the name of the data file, so that a file containing this data might be called something<br/>like 19990916_dave.txt.<br/>
<hr/>
<a name=171></a><i><b>Complex data files</b></i><br/>
<b>151</b><br/>
The information in the footer is a little different. In this case we are describing<br/>
the actual shape of the data rather than where (or when) it comes from. At first<br/>glance it might seem that this information is unnecessary, as we can find out the<br/>number of records in the file simply by counting them as we process them. The rea-<br/>son that it is useful for the file to contain an indication of the number of records is<br/>that it acts as a simple check that the file has not been corrupted between the time it<br/>was created and the time we received it. By simply comparing the number of<br/>records that we processed against the number that the file claims to contain, we can<br/>easily tell if any went missing in transmission.2<br/>
This then demonstrates one important reason for having more complex data files.<br/>
They allow us to include <i>metadata</i>—data about the data we are dealing with. <br/>
<i><b>Adding subrecords<br/></b></i>Another good reason for using more complex formats is that you are dealing with<br/>data that doesn’t actually fit very well into a simpler format. Staying with the CD<br/>example, perhaps your data file needs to contain details of the tracks on the CDs as<br/>well as the data that we already list. At this point our line-per-record approach falls<br/>down and we are forced to look at something more complicated. Perhaps we will<br/>indent track records with a tab character or prefix the track records with a + charac-<br/>ter. This would give us a file that looked something like this (listing only the first<br/>two tracks):<br/>
Dave's CD Collection<br/>
16 Sep 1999<br/>
Artist<br/>
Title<br/>
Label<br/>
Released<br/>
--------------------------------------------------------<br/>
Bragg, Billy<br/>
Workers' Playtime<br/>
Cooking Vinyl<br/>
1988<br/>
+She's Got A New Spell<br/>
+Must I Paint You A Picture<br/>
Bragg, Billy<br/>
Mermaid Avenue<br/>
EMI<br/>
1998<br/>
+Walt Whitman's Niece<br/>
+California Stars<br/>
Black, Mary<br/>
The Holy Ground<br/>
Grapevine<br/>
1993<br/>
+Summer Sent You<br/>
+Flesh And Blood<br/>
Black, Mary<br/>
Circus<br/>
Grapevine<br/>
1995<br/>
+The Circus<br/>
+In A Dream<br/>
Bowie, David<br/>
Hunky Dory<br/>
RCA<br/>
1971<br/>
+Changes<br/>
2 As with the header information, including this data within the file isn’t the only way to do it. Another com-<br/>
mon method is to send a second file with a similar name that contains the number of records. In the exam-<br/>ple of my CDs, we might have another file called 19990916_dave.rec which contains only the number 6.<br/>
<hr/>
<a name=172></a><b>152</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
+Oh You Pretty Things<br/>
Bowie, David<br/>
Earthling<br/>
EMI<br/>
1997<br/>
+Little Wonder<br/>
+Looking For Satellites<br/>
6 Records<br/>
<i><b>8.1.2</b></i><br/>
<i><b>Example: reading the expanded CD file</b></i><br/>
This file is more complicated to process than just about any other that we have seen.<br/>Here is one potential way to read the data into a data structure.<br/>
1: my %data;<br/>
2:<br/>
3: chomp($data{title} = &lt;STDIN&gt;);<br/>
4: chomp($data{date} = &lt;STDIN&gt;);<br/>
5: &lt;STDIN&gt;;<br/>
6: my ($labels, @labels);<br/>
7: chomp($labels = &lt;STDIN&gt;);<br/>
8: @labels = split(/\s+/, $labels);<br/>
9: &lt;STDIN&gt;;<br/>
10:<br/>
11: my $template = 'A14 A19 A15 A8';<br/>
12:<br/>
13: my %rec;<br/>
14: while (&lt;STDIN&gt;) {<br/>
15:<br/>
chomp;<br/>
16:<br/>
17:<br/>
last if /^\s*$/;<br/>
18:<br/>
19:<br/>
if (/^\+/) {<br/>
20:<br/>
push @{$rec{tracks}}, substr($_, 1);<br/>
21:<br/>
} else {<br/>
22:<br/>
push @{$data{CDs}}, {%rec} if keys %rec;<br/>
23:<br/>
%rec = ();<br/>
24:<br/>
@rec{@labels} = unpack($template, $_);<br/>
25:<br/>
}<br/>
26: }<br/>
27:<br/>
28: push @{$data{CDs}}, {%rec} if keys %rec;<br/>
29:<br/>
30: ($data{count}) = (&lt;STDIN&gt; =~ /(\d+)/);<br/>
31:<br/>
32: if ($data{count} == @{$data{CDs}}) {<br/>
33:<br/>
print &#34;$data{count} records processed successfully\n&#34;;<br/>
34: } else {<br/>
35:<br/>
warn &#34;Expected $data{count} records but received &#34;,<br/>
36:<br/>
scalar @{$data{CDs}}, &#34;\n&#34;;<br/>
37: }<br/>
<hr/>
<a name=173></a><i><b>Complex data files</b></i><br/>
<b>153</b><br/>
This code is not the best way to achieve this. We’ll see a far better way when we<br/>examine the module Parse::RecDescent in chapter 11, but in the meantime let’s<br/>take a look at the code in more detail to see where it’s a bit kludgy.<br/>
Line 1 defines a hash where we will store the data that we read in.<br/>Lines 3 and 4 read in the first two lines of data and store them in $data{title}<br/>
and $data{date}, respectively.<br/>
Line 5 ignores the next line in the file (which is blank).<br/>Lines 6 to 8 get the list of labels from the header line in the file and create an<br/>
array containing the labels.<br/>
Line 9 ignores the next line in the file (which is the line of dashes).<br/>Line 11 creates a template for extracting the data from the CD lines using<br/>
unpack. Note that it would have been possible to create this template automatically<br/>by calculating the lengths of the fields from the header line.<br/>
Line 13 defines a hash that will store the details of each CD as we read it in.<br/>Line 14 starts a while loop which will read in all of the CD data a line at a time.<br/>Line 15 removes the end-of-line character from data record.<br/>Line 17 terminates the loop when a blank line is found. This is because there is a<br/>
blank line between the CD records and the footer data.<br/>
Line 19 checks to see if we have a CD record or a track record by examining the<br/>
first character of the data. If it is a + then we have a track record, otherwise we<br/>assume we have a CD record.<br/>
Line 20 deals with the track record by removing the leading + and pushing the<br/>
remaining data onto a list of tracks on our current CD.<br/>
Line 22 starts to deal with a new CD. First we need to push the previous CD<br/>
record onto our list of CDs (which is stored in $data{CDs}). Notice that we also<br/>get to this line of code at the start of the first CD record. In this case there is no pre-<br/>vious CD record to store. We take care of this by only storing the record if it con-<br/>tains data. Notice also that as we reuse the same %rec variable for each CD, we<br/>make an anonymous copy of it each time.<br/>
Line 23 resets the %rec hash to be empty, and line 24 gets the data about the<br/>
new CD using unpack.<br/>
Having found the blank line at the end of the data section, we exit from the<br/>
while loop at line 26. At this point the final CD is still stored in $rec, but hasn’t<br/>been added to $data{CDs}. We put that right on line 28.<br/>
Line 30 grabs the number of records from the footer line in the file and then, as a<br/>
sanity check, we compare that number with the number of records that we have<br/>processed and stored in $data{CDs}.<br/>
Figure 8.1 shows the data structure that we store the album details in.<br/>
<hr/>
<a name=174></a><b>154</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
title<br/>
Dave's CD collection<br/>
date<br/>
16 Sep 1999<br/>
CDs<br/>
arrayref<br/>
0<br/>
hashref<br/>
artist<br/>
Billy Bragg<br/>
count 6<br/>
1<br/>
hashref<br/>
title<br/>
Workers' Playtime<br/>
2<br/>
hashref<br/>
label<br/>
Cooking Vinyl<br/>
3<br/>
hashref<br/>
released<br/>
1988<br/>
4<br/>
hashref<br/>
tracks<br/>
arrayref<br/>
5<br/>
hashref<br/>
0<br/>
She's Got A New Spell<br/>
1<br/>
Must I Paint You A Picture<br/>
<b>Figure 8.1</b><br/>
<b>Data structure modeling the complex CD data file</b><br/>
As you can see, while this approach gets the job done, it is far from elegant. A bet-<br/>
ter way to achieve this would be using a real parser. We will take a look at simple pars-<br/>ers later in this chapter, but first let’s look at more limitations of our current methods.<br/>
<i><b>8.2</b></i><br/>
<i><b>How not to parse HTML</b></i><br/>
HTML and its more flexible sibling XML have become two of the most common<br/>data formats over recent years, and there is every reason to believe that they will<br/>continue to grow in popularity in the future. They are so popular, in fact, that the<br/>next two chapters are dedicated to ways of dealing with them using dedicated mod-<br/>ules such as HTML::Parser and XML::Parser. In this section, however, I’d like to<br/>give you some idea of why these modules are necessary by pointing out the limita-<br/>tions in the data parsing methods that we have been using up to now.<br/>
<i><b>8.2.1</b></i><br/>
<i><b>Removing tags from HTML</b></i><br/>
A common requirement when processing HTML is to remove the HTML tags from<br/>the input, leaving only the plain text. We will, therefore, use this as our example.<br/>Let’s take a simple piece of HTML and examine how we might remove the tags.<br/>Here is the sample HTML that we will use:<br/>
&lt;!DOCTYPE HTML PUBLIC &#34;-//IETF//DTD HTML//EN&#34;&gt;<br/>
&lt;html&gt;<br/>
&lt;head&gt;<br/>
&lt;title&gt;Sample HTML&lt;/title&gt;<br/>
&lt;/head&gt;<br/>
&lt;body&gt;<br/>
&lt;h1&gt;Sample HTML&lt;/h1&gt;<br/>
<hr/>
<a name=175></a><i><b>How not to parse HTML</b></i><br/>
<b>155</b><br/>
&lt;p&gt;This is a sample piece of HTML.&lt;/p&gt;<br/>
&lt;ul&gt;<br/>
&lt;li&gt;It&lt;/li&gt;<br/>
&lt;li&gt;Has&lt;/li&gt;<br/>
&lt;li&gt;A&lt;/li&gt;<br/>
&lt;li&gt;List&lt;/li&gt;<br/>
&lt;/ul&gt;<br/>
&lt;p&gt;And links to the &lt;a href=&#34;prev.html&#34;&gt;Previous&lt;/a&gt; and<br/>
&lt;a href=&#34;next.html&#34;&gt;Next&lt;/a&gt; pages.&lt;/p&gt;<br/>
&lt;/body&gt;<br/>
&lt;/html&gt;<br/>
<i><b>Example: a first attempt<br/></b></i>Here is a first attempt to write code that removes all of the HTML tags. I should<br/>reiterate here that all of this code is here to demonstrate the <i>wrong</i> way to do it, so<br/>you shouldn’t be using this code in your programs.<br/>
# WARNING: This code doesn't work<br/>
use strict;<br/>
while (&lt;STDIN&gt;) {<br/>
s/&lt;.*&gt;//;<br/>
print;<br/>
}<br/>
Nothing too difficult there. Just read in the file a line at a time and remove every-<br/>thing that is between an opening &lt; and a closing &gt;. Let’s see what output we get<br/>when we run that against our sample file.<br/>
<b>and</b><br/>
<hr/>
<a name=176></a><b>156</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
That’s probably not quite what we were hoping for. So what has gone wrong? In<br/>this case we have made a simple beginner’s mistake. By default, Perl regular expres-<br/>sions are <i>greedy</i>. That is, they consume as much of the string as possible. What this<br/>means is that where we have a line like:<br/>
&lt;h1&gt;Sample HTML&lt;/h1&gt;<br/>
our regular expression will consume all the data between the first &lt; and the last &gt;,<br/>effectively removing the whole line.<br/>
<i><b>Example: another attempt using nongreedy regular expressions<br/></b></i>We can, of course, correct this by making our regular expression nongreedy. We do<br/>this by placing a ? after the greedy part of the regular expression (.*), meaning our<br/>code will now look like this:<br/>
# WARNING: This code doesn't work either<br/>
use strict;<br/>
while (&lt;STDIN&gt;) {<br/>
s/&lt;.*?&gt;//;<br/>
print;<br/>
}<br/>
and our output looks like this:<br/>
<b>Sample HTML&lt;/title&gt;</b><br/>
<b>Sample HTML&lt;/h1&gt;</b><br/>
<b>This is a sample piece of HTML.&lt;/p&gt;</b><br/>
<b>It&lt;/li&gt;</b><br/>
<b>Has&lt;/li&gt;</b><br/>
<b>A&lt;/li&gt;</b><br/>
<b>List&lt;/li&gt;</b><br/>
<b>And links to the &lt;a href=&#34;prev.html&#34;&gt;Previous&lt;/a&gt; and</b><br/>
<b>Next&lt;/a&gt; pages.&lt;/p&gt;</b><br/>
<i><b>Example: adding the g modifier<br/></b></i>The preceding output is obviously an improvement, but instead of removing too<br/>much data we are now removing too little. We are removing only the first tag that<br/>appears on each line. We can correct this by adding the g modifier to our text<br/>replacement operator so that the code looks like this:<br/>
# WARNING: This code works, but only on very simple HTML<br/>
use strict;<br/>
<hr/>
<a name=177></a><i><b>How not to parse HTML</b></i><br/>
<b>157</b><br/>
while (&lt;STDIN&gt;) {<br/>
s/&lt;.*?&gt;//g;<br/>
print;<br/>
}<br/>
And the output will look like this:<br/>
<b>Sample HTML</b><br/>
<b>Sample HTML</b><br/>
<b>This is a sample piece of HTML.</b><br/>
<b>It</b><br/>
<b>Has</b><br/>
<b>A</b><br/>
<b>List</b><br/>
<b>And links to the Previous and</b><br/>
<b>Next pages.</b><br/>
That does look a lot better.<br/>
<i><b>8.2.2</b></i><br/>
<i><b>Limitations of regular expressions   </b></i><br/>
At this point you might be tempted to think that I was exaggerating when I said<br/>that HTML parsing was difficult as we seem to have achieved it in four lines of Perl.<br/>The problem is that while we have successfully parsed this particular piece of<br/>HTML, we are still a long way from dealing with the problem in general. The<br/>HTML we have dealt with is very simple and almost certainly any real world HTML<br/>will be far more complex.<br/>
The first assumption that we have made about HTML is that all tags start and fin-<br/>
ish on the same line. You only need to look at a few web pages to see how optimis-<br/>tic that is. Many HTML tags have a number of attributes and can be spread out over<br/>a number of lines. Take this tag for example:<br/>
&lt;img src=&#34;http://www.mag-sol.com/images/logo.gif&#34;<br/>
height=&#34;25&#34; width=&#34;100&#34;<br/>
alt=&#34;Magnum Solutions Ltd.&#34;&gt;<br/>
Currently our program will leave this tag untouched. There are, of course, ways<br/>around this. We could read the whole HTML file into a single scalar variable and<br/>run our text replacement on that variable.3 The downside of this approach is that,<br/>
3 We would have to add the s modifier to the operator, to get the . to match newline characters.<br/>
<hr/>
<a name=178></a><b>158</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
while it is not a problem for a small file like our example, there may be good reasons<br/>for not reading a larger document into memory all at once.<br/>
We have seen a number of reasons why our approach to parsing HTML is flawed.<br/>
We can provide workarounds for all of the problems we have come across so far, but<br/>the next problem is a little more serious. Basically, our current methods don’t<br/>understand the structure of an HTML document and don’t know that different<br/>rules apply at different times. Take a look at the following piece of valid HTML:<br/>
&lt;img src=&#34;/images/prev.gif&#34; alt=&#34;&lt;-&#34;&gt;<br/>
&lt;img src=&#34;/images/next.gif&#34; alt=&#34;-&gt;&#34;&gt;<br/>
In this example, the web page has graphics that link to the previous and next pages.<br/>In case the user has a text-only browser or has images switched off, the author has<br/>provided alt attributes which can be displayed instead of the images. Unfortu-<br/>nately, in the process he has completely broken our basic HTML parsing routine.<br/>The &gt; symbol in the second alt attribute will be interpreted by our code as the end<br/>of the img tag. Our code doesn’t know that it should ignore &gt; symbols if they<br/>appear in quotes. Building regular expressions to deal with this is possible, but it<br/>will make your code much more complex and just when you’ve added that you’ll<br/>find another complication that you’ll need to deal with.<br/>
The point is that while you can solve all of these problems, there are always new<br/>
problems around the corner and there comes a point when you have to stop look-<br/>ing for new problems to address and put the code into use. If you can be sure of the<br/>format of your HTML, you can write code which processes the subset of HTML that<br/>you know you will be dealing with, but the only way to deal with all HTML is to use<br/>an HTML parser. We’ll see a lot more about parsing HTML (and also XML) in the<br/>following chapters.<br/>
<i><b>8.3</b></i><br/>
<i><b>Parsers</b></i><br/>
We’ve seen in the previous section that for certain types of data, our usual regular<br/>expression-based approach is not guaranteed to work. We must therefore find a new<br/>approach. This will involve the use of parlance.<br/>
<i><b>8.3.1</b></i><br/>
<i><b>An introduction to parsers</b></i><br/>
As I have hinted throughout this chapter, the solution to all of these problems is to<br/>use a parser. A <i>parser</i> is a piece of software that takes a piece of input data and looks<br/>for recognizable patterns within it. This is, of course, what all of our parsing rou-<br/>tines have been doing, but we are now looking at a far more mathematically rigor-<br/>ous way of splitting up our input data.<br/>
<hr/>
<a name=179></a><i><b>Parsers</b></i><br/>
<b>159</b><br/>
Before I go into the details of parsing, I should point out that this is a very com-<br/>
plex field and there is a lot of very specific jargon which I cannot address here in<br/>detail. If you find your interest piqued by this high-level summary you might want<br/>to look at the books recommended at the end of this chapter.<br/>
<i><b>An introduction to parsing jargon<br/></b></i>I said that parsers look for recognizable patterns in the input data. The first ques-<br/>tion, therefore, should be: how do parsers know what patterns to recognize? Any<br/>parser works on a grammar that defines the allowable words in the input data and<br/>their allowed relationships with each other. Although I say words, obviously in the<br/>kinds of data that we are dealing with these words can, in fact, be any string of char-<br/>acters. In parsing parlance they are more accurately known as <i>tokens</i>.<br/>
The grammar therefore defines the tokens that the input data should contain and<br/>
how they should be related. It does this by defining a number of rules. A rule has a<br/>name and a definition. The definition contains the list of items that can be used to<br/>match the rule. These items can either be <i>subrules</i> or a definition of the actual text<br/>that makes up the token. This may all become a bit clearer if we look at a simple<br/>grammar. Figure 8.2 shows a grammar which defines a particular type of simple<br/>English sentence.<br/>
<b>Terminal</b><br/>
<b>Rule name</b><br/>
<b>Production</b><br/>
sentence<br/>
-&gt; subject VERB object<br/>
subject<br/>
-&gt; noun_phrase<br/>
object<br/>
-&gt; noun_phrase<br/>
<b>Alternative</b><br/>
noun_phrase -&gt; PRONOUN<br/>
<b>productions</b><br/>
|<br/>
PROPER_NOUN<br/>
|<br/>
ARTICLE NOUN<br/>
<b>Figure 8.2</b><br/>
<b>Simple grammar</b><br/>
This grammar says that a sentence is made up of a subject followed by a verb and<br/>
an object. The verb is a <i>terminal</i> (in capital letters) which means that no further<br/>definition is required. Both the subject and the object are noun phrases and a noun<br/>phrase is defined as either a pronoun, a proper noun, or an article followed by a<br/>noun. In the last rule, pronouns, proper nouns, articles, and nouns are all terminals.<br/>Notice that the vertical bars in the definition of a noun_phrase indicate alterna-<br/>tives, i.e., a noun phrase rule can be matched by one of three different forms. Each<br/>of these alternatives is called a <i>production</i>.<br/>
<i><b>Matching the grammar against input data<br/></b></i>Having defined the grammar, the parser now has to match the input data against<br/>the grammar. First it will break up the input text into tokens. A separate process<br/>
<hr/>
<a name=180></a><b>160</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
called a lexer often does this. The parser then examines the stream of tokens and<br/>compares it with the grammar. There are two different ways that a parser will<br/>attempt this. <br/>
<i>Bottom-up parsers<br/></i>An LR (scan left, expand rightmost subrule) parser will work like a finite state<br/>machine. Starting in a valid start state, the parser will compare the next token with<br/>the grammar to see if it matches a possible successor state. If so, it moves to the suc-<br/>cessor state and starts the process again. Figure 8.3 shows how this process works<br/>for our simple grammar. The parser begins at the Start node and takes the first<br/>token from the input stream. The parser is allowed to move to any successor state<br/>which is linked to its current state by an arrow (but only in the direction of the<br/>arrow). If the parser gets to the end of the stream of tokens and is at the Finish<br/>node, then the parse was successful; otherwise the parse has failed. If at any point<br/>the parser finds a token which does not match the successor states of its current<br/>state, then the parse also fails.<br/>
Start<br/>
PROPER<br/>
PRONOUN<br/>
ARTICLE<br/>
_NOUN<br/>
VERB<br/>
NOUN<br/>
PROPER<br/>
PRONOUN<br/>
ARTICLE<br/>
_NOUN<br/>
NOUN<br/>
Finish<br/>
<b>Figure 8.3</b><br/>
<b>LR Parser</b><br/>
At any point, if the finite state machine cannot find a matching successor state, it<br/>
will go back a state and try an alternative route. If it gets to the end of the input<br/>data and finds itself in a valid end state, then the parse has succeeded; if not it has<br/>failed. This type of parser is also known as a <i>bottom-up</i> parser.<br/>
<hr/>
<a name=181></a><i><b>Parsers</b></i><br/>
<b>161</b><br/>
<i>Top-down parsers<br/></i>An LL (scan left, expand leftmost subrule) parser will start by trying to match the<br/>highest level rule first (the sentence rule in our example). To do that, it needs to<br/>match the subrules within the top-level rule, so it would start to match the subject<br/>rule and so on down the grammar. Once it has matched all of the terminals in a rule,<br/>it knows that has matched that rule. Figure 8.4 shows the route that an LL parser<br/>would take when trying to match an input stream against out sample grammar.<br/>
sentence<br/>
sequence of<br/>
subject<br/>
VERB<br/>
object<br/>
noun_phrase<br/>
one of<br/>
PROPER<br/>
PRONOUN<br/>
sequence of<br/>
_NOUN<br/>
ARTICLE<br/>
NOUN<br/>
<b>Figure 8.4</b><br/>
<b>LL Parser</b><br/>
Matching all of the subrules in a production means that it has matched the pro-<br/>
duction and, therefore, the rule that the production is part of. If the parser matches<br/>all of the subrules and terminals in one of the productions of the top-level rule,<br/>then the parse has succeeded. If the parser runs out of productions to try before<br/>matching the top-level rule, then the parse has failed. For obvious reasons, this type<br/>of parser is also known as a <i>top-down</i> parser.<br/>
<i><b>8.3.2</b></i><br/>
<i><b>Parsers in Perl</b></i><br/>
Parsers in Perl come in two types: prebuilt parsers such as HTML::Parser and<br/>XML::Parser, which are designed to parse a particular type of data, and modules<br/>
<hr/>
<a name=182></a><b>162</b><br/>
CHAPTER <br/>
<i><b>Complex data formats</b></i><br/>
such as Parse::Yapp and Parse::RecDescent which allow you to create your<br/>own parsers from a grammar which you have defined.<br/>
In the next two chapters we will take a longer look at the HTML::Parser and XML::<br/>
Parser families of modules; and in chapter 11 we will examine Parse::RecDescent,<br/>in detail, which is the most flexible tool for creating your own parsers in Perl.<br/>
<i><b>8.4</b></i><br/>
<i><b>Further information</b></i><br/>
More information about parsing HTML can be found in the next chapter of this book.<br/>
For additional information about parsing in general: <i>Compilers: Principles, Tech-</i><br/>
<i>niques and Tools</i> (a.k.a. “The Dragon Book”) by Aho, Sethi, and Ullman (Addison-<br/>Wesley) is the definitive guide to the field; <i>The Art of Compiler Design</i> by Pittman<br/>and Peters (Prentice Hall) is, however, a far gentler introduction.<br/>
<i><b>8.5</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
There are often very good reasons for having data that is not strictly in a<br/>record-based format. These reasons can include:<br/>
■<br/>
Including metadata about the data file.<br/>
■<br/>
Including subsidiary records.<br/>
■<br/>
When parsing hierarchical data such as HTML our usual regular expression-based<br/>approach can break down and we need to look for more powerful techniques.<br/>
■<br/>
Parsers work by examining a string of tokens to see if they match the rules<br/>defined in a grammar.<br/>
■<br/>
Parsers can either be bottom-up (scan left, expand rightmost subrule) or top-<br/>down (scan left, expand leftmost subrule).<br/>
<hr/>
<a name=183></a><img class="yflip" src="dmp-183_1.jpg"/><br/>
<i>9HTML</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Getting data from the Internet<br/>
■<br/>
Parsing HTML<br/>
■<br/>
Prebuilt HTML parsers<br/>
■<br/>
Getting a weather forecast <br/>
<i>163</i><br/>
<hr/>
<a name=184></a><b>164</b><br/>
CHAPTER <br/>
<i><b>HTML</b></i><br/>
Since the explosion in interest in the World Wide Web in the 1990s, HTML has<br/>become one of the most popular file formats that we can use for the purpose of<br/>extracting data. At the end of the 1990s it seemed more and more likely that HTML<br/>would be overtaken in terms of popularity by its younger cousin, XML.<br/>
In this chapter we will look at HTML and see how to extract the data that we<br/>
need from HTML documents. <br/>
<i><b>9.1</b></i><br/>
<i><b>Extracting HTML data from the World Wide Web</b></i><br/>
Perl has a set of modules which can be used to read data from the World Wide Web.<br/>This set of modules is called LWP (for Library for WWW Programming in Perl) and<br/>you can find it on the CPAN under the name libwww.1 LWP contains modules for<br/>gleaning data from the WWW under a large number of conditions. Here we will<br/>look at only the simplest module that it contains. If these methods don’t work for<br/>you then you should take a close look at the documentation that comes with LWP.<br/>
The simplest method to use when pulling data down from the web is the<br/>
LWP::Simple module. This module exports a number of functions which can send<br/>an HTTP request and handle the response. The simplest of these is the get func-<br/>tion. This function takes a URL as an argument and returns the data that is returned<br/>when that URL is requested. For example:<br/>
use LWP::Simple;<br/>
my $page = get('http://www.mag-sol.com/index.html');<br/>
will put the contents of the requested page into the variable $page. If there is an<br/>error, then get will return undef.<br/>
Two of the most common steps that you will want to take with the data returned<br/>
will be to print it out or to store it in a file. LWP::Simple has functions that carry<br/>out both of these options with a single call:<br/>
getprint('http://www.mag-sol.com/index.html');<br/>
will print the page directly to STDOUT and <br/>
getstore('http://www.mag-sol.com/index.html', 'index.html');<br/>
will store the data in the (local) file index.html.<br/>
1 If, however, you are using ActiveState’s ActivePerl for Windows, you’ll find that LWP is part of the stan-<br/>
dard installation.<br/>
<hr/>
<a name=185></a><i><b>Parsing HTML</b></i><br/>
<b>165</b><br/>
<i><b>9.2</b></i><br/>
<i><b>Parsing HTML</b></i><br/>
Parsing HTML in Perl is all based around the HTML::Parser CPAN module.2 This<br/>module takes either an HTML file or a chunk of HTML in a variable and splits it into<br/>individual tokens. To use HTML::Parser we need to define a number of <i>handler<br/></i>subroutines which are called by the parser whenever it encounters certain construc-<br/>tions in the document being parsed.<br/>
The HTML that you want to parse can be passed to the parser in a couple of<br/>
ways. If you have it in a file you can use the parse_file method, and if you have it<br/>in a variable you can use the parse method.<br/>
<i><b>9.2.1</b></i><br/>
<i><b>Example: simple HTML parsing</b></i><br/>
Here is a very simple HTML parser that displays all of the HTML tags and attributes<br/>it finds in an HTML page.<br/>
use HTML::Parser;<br/>
use LWP::Simple;<br/>
sub start {<br/>
my ($tag, $attr, $attrseq) = @_;<br/>
print &#34;Found $tag\n&#34;;<br/>
foreach (@$attrseq) {<br/>
print &#34; [$_ -&gt; $attr-&gt;{$_}]\n&#34;;<br/>
}<br/>
}<br/>
my $h = HTML::Parser-&gt;new(start_h =&gt; [\&amp;start, 'tagname,attr,attrseq']);<br/>
my $page = get(shift);<br/>
$h-&gt;parse($page);<br/>
In this example, we define one handler, which is called whenever the parser encoun-<br/>ters the start of an HTML tag. The subroutine start is defined as being a handler<br/>as part of the HTML::Parser-&gt;new call. Notice that we pass new a hash of values.<br/>The keys to the hash are the names of the handlers and the values are references to<br/>arrays that define the associated subroutines. The first element of the referenced<br/>array is a reference to the handler subroutine and the second element is a string that<br/>defines the parameters that the subroutine expects. In this case we require the name<br/>of the tag, a hash of the tag’s attributes, and an array which contains the sequence<br/>
2 Note that what I am describing here is HTML::Parser version 3. In this version, the module was rewritten<br/>
so that it was implemented in C for increased performance. The interface was also changed. Unfortunately,<br/>the version available for ActivePerl on Win32 platforms still seems to be the older, pure Perl version, which<br/>doesn’t support the new interface.<br/>
<hr/>
<a name=186></a><b>166</b><br/>
CHAPTER <br/>
<i><b>HTML</b></i><br/>
in which the attributes were originally defined. All parameters are passed to the han-<br/>dler as scalars. This means that the attribute hash and the attribute sequence array<br/>are actually passed as references.<br/>
In the start subroutine, we simply print out the type of the HTML element that<br/>
we have found, together with a list of its attributes. We use the @$attrseq array to<br/>display the attributes following the same order in which they were defined in the<br/>original HTML. Had we relied on keys %$attr, we couldn’t have guaranteed the<br/>attributes appearing in any particular order.<br/>
<i><b>Testing the simple HTML parser<br/></b></i>In order to test this, here is a simple HTML file:<br/>
&lt;!DOCTYPE HTML PUBLIC &#34;-//IETF//DTD HTML//EN&#34;&gt;<br/>
&lt;html&gt;<br/>
&lt;head&gt;&lt;title&gt;Test HTML Page&lt;/title&gt;&lt;/head&gt;<br/>
&lt;body bgcolor=&#34;#FFDDDD&#34;&gt;<br/>
&lt;h1 ALIGN=center&gt;test HTML Page&lt;/h1&gt;<br/>
&lt;p&gt;This is the first paragraph&lt;/p&gt;<br/>
&lt;p&gt;&lt;font color=&#34;#0000FF&#34;&gt;This&lt;/font&gt; is the 2nd paragraph&lt;/p&gt;<br/>
&lt;p&gt;Here is a list&lt;/p&gt;<br/>
&lt;ol&gt;&lt;li&gt;Item one&lt;/li&gt;<br/>
&lt;li&gt;Item two&lt;/li&gt;&lt;/ul&gt;<br/>
&lt;/body&gt;<br/>
&lt;/html&gt;<br/>
and here is the output we get from running it through our parser:<br/>
<b>Found html</b><br/>
<b>Found head</b><br/>
<b>Found title</b><br/>
<b>Found body</b><br/>
<b>[bgcolor -&gt; #FFDDDD]</b><br/>
<b>Found h1</b><br/>
<b>[align -&gt; center]</b><br/>
<b>Found p</b><br/>
<b>Found p</b><br/>
<b>Found font</b><br/>
<b>[color -&gt; #0000FF]</b><br/>
<b>Found p</b><br/>
<b>Found ol</b><br/>
<b>Found li</b><br/>
<b>Found li</b><br/>
Each time the parser finds an HTML element, it calls start, which displays infor-<br/>mation about the element and its attributes. Notice that none of the actual text of<br/>the document appears in our output. For that to happen we would need to define<br/>a text handler. You would do that by declaring a text_h key/value pair in the<br/>
<hr/>
<a name=187></a><i><b>Prebuilt HTML parsers</b></i><br/>
<b>167</b><br/>
call to HTML::Parser-&gt;new. You would define the handler in the same way, but in<br/>this case you might choose a different set of parameters. Depending on what your<br/>script was doing, you would probably choose the text or dtext parameters. Both<br/>of these parameters give you the text found, but in the dtext version any HTML<br/>entities are decoded.<br/>
You can see how easy it is to build up a good idea of the structure of the docu-<br/>
ment. If you wanted a better picture of the structure of the document, you could<br/>also define an end handler and display information about closing tags as well. One<br/>option might be to keep a global variable, which was incremented each time a start<br/>tag was found, and decremented each time a close tag was found. You could then<br/>use this value to indent the data displayed according to how deeply nested the<br/>element was.<br/>
<i><b>9.3</b></i><br/>
<i><b>Prebuilt HTML parsers</b></i><br/>
HTML::Parser gives you a great deal of flexibility to parse HTML files in any way<br/>that you want. There are, however, a number of tasks that are common enough that<br/>someone has already written an HTML::Parser subclass to carry them out.<br/>
<i><b>9.3.1</b></i><br/>
<i><b>HTML::LinkExtor</b></i><br/>
One of the most popular is HTML::LinkExtor which is used to produce a list of all<br/>of the links in an HTML document. There are two ways to use this module. The<br/>simpler way is to parse the document and then run the links function, which<br/>returns an array of the links found. Each of the elements in this array is a reference<br/>to another array. The first element of this second-level array is the type of element in<br/>which the link is found. The subsequent elements occur in pairs. The first element<br/>in a pair is the name of an attribute which denotes a link, and the second is the value<br/>of that attribute. This should become a bit clearer with an example. <br/>
<i><b>Example: listing links with HTML::LinkExtor<br/></b></i>Here is a program which simply lists all of the links found in an HTML file.<br/>
use HTML::LinkExtor;<br/>
my $file = shift;<br/>
my $p = HTML::LinkExtor-&gt;new;<br/>
$p-&gt;parse_file($file);<br/>
my @links = $p-&gt;links;<br/>
foreach (@links) {<br/>
print 'Type: ', shift @$_, &#34;\n&#34;;<br/>
<hr/>
<a name=188></a><b>168</b><br/>
CHAPTER <br/>
<i><b>HTML</b></i><br/>
while (my ($name, $val) = splice(@$_, 0, 2)) {<br/>
print &#34;<br/>
$name -&gt; $val\n&#34;;<br/>
}<br/>
}<br/>
and here is a sample HTML file which contains a number of links of various kinds:<br/>
&lt;!DOCTYPE HTML PUBLIC &#34;-//IETF//DTD HTML//EN&#34;&gt;<br/>
&lt;html&gt;<br/>
&lt;head&gt;&lt;title&gt;Test HTML Page&lt;/title&gt;<br/>
&lt;link rel=stylesheet type='text/css' href='style.css'&gt;&lt;/head&gt;<br/>
&lt;body background=&#34;back.gif&#34;&gt;<br/>
&lt;h1 ALIGN=center&gt;test HTML Page&lt;/h1&gt;<br/>
&lt;p&gt;This is the first paragraph.<br/>
It contains a &lt;a href=&#34;http://www.perl.com/&#34;&gt;link&lt;/a&gt;&lt;/p&gt;<br/>
&lt;p&gt;&lt;font color=&#34;#0000FF&#34;&gt;This&lt;/font&gt; is the 2nd paragraph.<br/>
It contains an image - &lt;img src=&#34;test.gif&#34;&gt;&lt;/p&gt;<br/>
&lt;p&gt;Here is an image used as a link&lt;br&gt;<br/>
&lt;a href=&#34;http://www.pm.org&#34;&gt;&lt;img src=&#34;pm.gif&#34; lowsrc=&#34;pmsmall.gif&#34;&gt;&lt;/a&gt;&lt;/p&gt;<br/>
&lt;/body&gt;<br/>
&lt;/html&gt;<br/>
When we run this program on this HTML file, the output is as follows:<br/>
<b>Type: link</b><br/>
<b>href -&gt; style.css</b><br/>
<b>Type: body</b><br/>
<b>background -&gt; back.gif</b><br/>
<b>Type: a</b><br/>
<b>href -&gt; http://www.perl.com/</b><br/>
<b>Type: img</b><br/>
<b>src -&gt; test.gif</b><br/>
<b>Type: a</b><br/>
<b>href -&gt; http://www.pm.org</b><br/>
<b>Type: img</b><br/>
<b>src -&gt; pm.gif</b><br/>
<b>lowsrc -&gt; pmsmall.gif</b><br/>
<i><b>Example: listing specific types of links with HTML::LinkExtor<br/></b></i>As you can see, there are a number of different types of links that HTML:LinkExtor<br/>returns. The complete list changes as the HTML specification changes, but basically<br/>any element that can refer to an external file is examined during parsing. If you only<br/>want to look at, say, links within an a tag, then you have a couple of options. You<br/>can either parse the file as we’ve just discussed and only use the links you are inter-<br/>ested in when you iterate over the list of links (using code something like: next<br/>unless $_-&gt;[0] eq 'a'), or you can use the second, more complex, interface to<br/>
HTML::LinkExtor. For this interface, you need to pass the new function a refer-<br/>ence to a function which the parser will call each time it encounters a link. This<br/>
<hr/>
<a name=189></a><i><b>Prebuilt HTML parsers</b></i><br/>
<b>169</b><br/>
function will be passed the name of the element containing the link together with<br/>pairs of parameters indicating the names and values of attributes which contain the<br/>actual links. Here is an example which displays only the a links within a file:<br/>
use HTML::LinkExtor;<br/>
my $file = shift;<br/>
my $p = HTML::LinkExtor-&gt;new(\&amp;check);<br/>
$p-&gt;parse_file($file);<br/>
my @links;<br/>
foreach (@links) {<br/>
print 'Type: ', shift @$_, &#34;\n&#34;;<br/>
while (my ($name, $val) = splice(@$_, 0, 2)) {<br/>
print &#34;<br/>
$name -&gt; $val\n&#34;;<br/>
}<br/>
}<br/>
sub check {<br/>
push @links, [@_] if $_[0] eq 'a';<br/>
}<br/>
Running our test HTML file through this program gives us the following output:<br/>
<b>Type: a</b><br/>
<b>href -&gt; http://www.perl.com/</b><br/>
<b>Type: a</b><br/>
<b>href -&gt; http://www.pm.org</b><br/>
which only lists the links that we are interested in.<br/>
<i><b>9.3.2</b></i><br/>
<i><b>HTML::TokeParser</b></i><br/>
Another useful prebuilt HTML parser module is HTML::TokeParser. This parser effec-<br/>tively turns the standard HTML::Parser interface on its head. HTML::TokeParser<br/>parses the file and stores the contents as a stream of tokens. You can request the next<br/>token from the stream using the get_tag method. This method takes an optional<br/>parameter which is a tag name. If this argument is used then the parser will skip tags<br/>until it reaches a tag of the given type. There is also a get_text function which returns<br/>the text at the current position in the stream. <br/>
<i><b>Example: extracting &lt;h1&gt; elements with HTML::TokeParser<br/></b></i>For example, to extract all of the &lt;h1&gt; elements from an HTML file you could use<br/>code this way:<br/>
use HTML::TokeParser;<br/>
my $file = shift;<br/>
<hr/>
<a name=190></a><b>170</b><br/>
CHAPTER <br/>
<i><b>HTML</b></i><br/>
my $p = HTML::TokeParser-&gt;new($file);<br/>
while ($p-&gt;get_tag('h1')) {<br/>
print $p-&gt;get_text(), &#34;\n&#34;;<br/>
}<br/>
We will use the following HTML file to test this program:<br/>
&lt;!DOCTYPE HTML PUBLIC &#34;-//IETF//DTD HTML//EN&#34;&gt;<br/>
&lt;html&gt;<br/>
&lt;head&gt;&lt;title&gt;Test HTML Page&lt;/title&gt;<br/>
&lt;/head&gt;<br/>
&lt;body&gt;<br/>
&lt;h1&gt;The first major item&lt;/h1&gt;<br/>
&lt;h2&gt;Section 1.1&lt;/h2&gt;<br/>
&lt;p&gt;Some text&lt;p&gt;<br/>
&lt;h2&gt;Section 1.2&lt;/h2&gt;<br/>
&lt;h3&gt;Section 1.2.1&lt;/h3&gt;<br/>
&lt;p&gt;blah&lt;/p&gt;<br/>
&lt;h3&gt;Section 1.2.2&lt;/h3&gt;<br/>
&lt;p&gt;blah&lt;/p&gt;<br/>
&lt;h1&gt;Another major header&lt;/h1&gt;<br/>
&lt;h2&gt;Section 2.1&lt;/h2&gt;<br/>
&lt;h3&gt;Section 2.1.1&lt;/h3&gt;<br/>
&lt;h3&gt;Section 2.1.2&lt;/h3&gt;<br/>
&lt;h2&gt;Section 2.2&lt;/h2&gt;<br/>
&lt;/body&gt;<br/>
&lt;/html&gt;<br/>
and here is the output:<br/>
<b>The first major item</b><br/>
<b>Another major header</b><br/>
<i><b>Example: listing all header tags with HTML::TokeParser<br/></b></i>A more sophisticated approach might be to look at the structure of the document<br/>by examining all of the headers in the document. In this case we need to look a little<br/>more closely at the return value from get_tag. This is a reference to an array, the<br/>elements of which are different for start tags and close tags. For start tags the ele-<br/>ments are: the tag name, a reference to a hash containing attribute names and val-<br/>ues, a reference to an array indicating the original order of the attributes, and the<br/>original HTML text. For an end tag the array contains the name of the tag prefixed<br/>with the character / and the original HTML text.<br/>
We can therefore iterate over all of the tags in a document, checking them to see<br/>
which ones are headers and displaying the structure of the document using code<br/>like this:<br/>
use HTML::TokeParser;<br/>
my $file = shift;<br/>
<hr/>
<a name=191></a><i><b>Prebuilt HTML parsers</b></i><br/>
<b>171</b><br/>
my $p = HTML::TokeParser-&gt;new($file);<br/>
my $tag;<br/>
while ($tag = $p-&gt;get_tag()) {<br/>
next unless $tag-&gt;[0] =~ /^h(\d)/;<br/>
my $level = $1;<br/>
print ' ' x $level, &#34;Head $level: &#34;, $p-&gt;get_text(), &#34;\n&#34;;<br/>
}<br/>
Notice that we only process tags where the name matches the regular expression<br/>/^h(\d)/. This ensures that we only see HTML header tags. We put brackets<br/>around the \d to capture this value in $1. This value indicates the level of the header<br/>we have found and we can use it to calculate how far to indent the output. Running<br/>this program on our previous sample HTML file gives the following output:<br/>
<b>Head 1: The first major item</b><br/>
<b>Head 2: Section 1.1</b><br/>
<b>Head 2: Section 1.2</b><br/>
<b>Head 3: Section 1.2.1</b><br/>
<b>Head 3: Section 1.2.2</b><br/>
<b>Head 1: Another major header</b><br/>
<b>Head 2: Section 2.1</b><br/>
<b>Head 3: Section 2.1.1</b><br/>
<b>Head 3: Section 2.1.2</b><br/>
<b>Head 2: Section 2.2</b><br/>
which is a very useful outline of the structure of the document.<br/>
<i><b>9.3.3</b></i><br/>
<i><b>HTML::TreeBuilder and HTML::Element</b></i><br/>
Another very useful subclass of HTML::Parser is HTML::TreeBuilder. As you can<br/>probably guess from its name, this class builds a parse tree that represents an HTML<br/>document. Each node in the tree is an HTML::Element object. <br/>
<i><b>Example: parsing HTML with HTML::Treebuilder<br/></b></i>Here is a simple script which uses HTML::TreeBuilder to parse an HTML document.<br/>
#!/usr/bin/perl -w<br/>
use strict;<br/>
use HTML::TreeBuilder;<br/>
my $h = HTML::TreeBuilder-&gt;new;<br/>
$h-&gt;parse_file(shift);<br/>
$h-&gt;dump;<br/>
print $h-&gt;as_HTML;<br/>
<hr/>
<a name=192></a><b>172</b><br/>
CHAPTER <br/>
<i><b>HTML</b></i><br/>
In this example we create a new parser object using the HTML::Treebuilder-&gt;new<br/>method. We then parse our file using the new object’s parse_file method.3<br/>Notice that, unlike some other tree-based parsers, this function doesn’t return a<br/>new tree object, rather the parse tree is built within the parser object itself.<br/>
As the example demonstrates, this class has a couple of ways to display the parse<br/>
tree. Both of these are, in fact, inherited from the HTML::Element class. The dump<br/>method prints a simple representation of the element and its descendents and the<br/>as_HTML method prints the element and its descendents as HTML. This might seem<br/>a little less than useful given that we have just created the parse tree <i>from</i> an HTML<br/>file, but there are at least three reasons why this might be useful. First, a great many<br/>HTML files aren’t strictly valid HTML. HTML::TreeBuilder does a good job of<br/>parsing invalid HTML and the as_HTML method can then be used to output valid<br/>HTML. Second, the HTML::Element has a number of methods for changing the<br/>parse tree, so you can alter your page and then use the as_HTML method to produce<br/>the altered page. And third, the tree can be scanned in ways that would be inconve-<br/>nient or impossible with just a token stream.<br/>
Notice that I’ve been saying that you can call HTML::Element methods on an<br/>
HTML::TreeBuilder object. This is because HTML::TreeBuilder inherits from<br/>both HTML::Parser and HTML::Element. An HTML document should always start<br/>with an &lt;HTML&gt; and end with a &lt;/HTML&gt; tag and therefore the whole document can<br/>be viewed as an HTML element, with all of the other elements contained within it. It is,<br/>therefore, valid to call HTML::Element methods on our HTML::TreeBuilder object.<br/>
Both HTML::TreeBuilder and HTML::Element are part of the HTML-Tree<br/>
bundle of modules which can be found on the CPAN.<br/>
<i><b>9.4</b></i><br/>
<i><b>Extended example: getting weather forecasts</b></i><br/>
To finish this section, here is an example demonstrating the extraction of useful data<br/>from web pages. We will get a weather forecast for the Central London area from<br/>Yahoo! The front page to Yahoo!’s U.K. weather service is at weather.yahoo.co.uk<br/>and by following a couple of links we can find that the address of the page contain-<br/>ing the weather forecast for London is at http://uk.weather.yahoo.com/1208/<br/>index_c.html. In order to extract the relevant data from the file we need to examine<br/>the HTML source for the page. You can either use the View Source menu option of<br/>your browser or write a quick Perl script using LWP and getstore to store the<br/>page in a file.<br/>
3 Note that HTML::Treebuilder supports the same parsing interface as HTML::Parser, so you could just as<br/>
easily call $h-&gt;parse, passing it a variable containing HTML to parse.<br/>
<hr/>
<a name=193></a><i><b>Extended example: getting weather forecasts</b></i><br/>
<b>173</b><br/>
Having retrieved a copy of the page we can examine it to find out where in the<br/>
page we can find the data that we want. Looking at the Yahoo! page I found that<br/>the description of the weather outlook was within the first &lt;font&gt; tag after the sixth<br/>&lt;table&gt; tag. The high and low temperature measurements were within the follow-<br/>ing two &lt;b&gt; tags.4 Armed with this knowledge, we can write a program which will<br/>extract the weather forecast and display it to the user. The program looks like this:<br/>
use HTML::TokeParser;<br/>
use LWP::Simple;<br/>
my $addr = 'http://uk.weather.yahoo.com/1208/index_c.html';<br/>
my $page = get $addr;<br/>
my $p = HTML::TokeParser-&gt;new(\$page)<br/>
|| die &#34;Parse error\n&#34;;<br/>
$p-&gt;get_tag('table') !! die &#34;Not enough table tags!&#34; foreach (1 .. 6);<br/>
$p-&gt;get_tag('font');<br/>
my $desc = $p-&gt;get_text, &#34;\n&#34;;<br/>
$p-&gt;get_tag('b');<br/>
my $high = $p-&gt;get_text;<br/>
$p-&gt;get_tag('b');<br/>
my $low = $p-&gt;get_text;<br/>
print &#34;$desc\nHigh: $high, Low: $low\n&#34;;<br/>
You will notice that I’ve used HTML::TokeParser in this example. I could have also<br/>chosen another HTML::Parser subclass or even written my own, but HTML::<br/>TokeParser is a good choice for this task as it is very easy to target specific ele-<br/>ments, such as the sixth &lt;table&gt; tag, and then move to the next &lt;font&gt; tag.<br/>
In the program we use LWP::Simple to retrieve the required page from the web<br/>
site and then parse it using HTML::TokeParser. We then step through the parsed<br/>document looking for &lt;table&gt; tags, until we find the sixth one. At this point we<br/>find the next &lt;font&gt; tag and extract the text within it using the get_text method.<br/>This gives us the brief weather outlook. We then move in turn to each of the next<br/>two &lt;b&gt; tags and for each one extract the text from it. This gives us the forecast<br/>high and low temperatures. We can then format all of this information in a nice way<br/>and present it to the user.<br/>
This has been a particularly simple example, but similar techniques can be used<br/>
to extract just about any information that you can find on the World Wide Web.<br/>
4 You should, of course, bear in mind that web pages change very frequently. By the time you read this,<br/>
Yahoo! may well have changed the design of this page which will render this program useless.<br/>
<hr/>
<a name=194></a><b>174</b><br/>
CHAPTER <br/>
<i><b>HTML</b></i><br/>
<i><b>9.5</b></i><br/>
<i><b>Further information</b></i><br/>
LWP and HTML::Parser together with all of the other modules that we have dis-<br/>cussed in this section are not part of the standard Perl distribution. You will need to<br/>download them from the CPAN (at www.cpan.org).<br/>
A very good place to get help with these modules is the LWP mailing list. To sub-<br/>
scribe, send a blank email to libwww-subscribe@perl.org (but please make sure that<br/>you have read all of the documentation that comes with the module before posting<br/>a question).<br/>
<i><b>9.6</b></i><br/>
<i><b>Summary</b></i><br/>
■<br/>
HTML is one of the most common data formats that you will come across<br/>because of its popularity on the World Wide Web.<br/>
■<br/>
You can retrieve HTML documents from the Internet using the LWP bundle<br/>of modules from the CPAN.<br/>
■<br/>
The main Perl module used for parsing HTML is HTML::Parser, but you<br/>may well never need to use it, because subclasses like HTML::LinkExtor,<br/>HTML::TokeParser, and HTML::TreeBuilder are often more useful for<br/>particular tasks.<br/>
<hr/>
<a name=195></a><img class="yflip" src="dmp-195_1.jpg"/><br/>
<i>10XML</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
What is XML and what’s wrong with HTML?<br/>
■<br/>
Parsing XML<br/>
■<br/>
Using handlers to control the parser<br/>
■<br/>
Parsing XML using the Document <br/>Object Model<br/>
■<br/>
Converting an XML document to POD, <br/>HTML, or plain text <br/>
<i>175</i><br/>
<hr/>
<a name=196></a><b>176</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
Over the next few years, it looks as though XML will become the data exchange for-<br/>mat of choice for a vast number of computer systems. In this chapter we will take a<br/>look at some of the tools available for parsing XML with Perl. <br/>
<i><b>10.1 XML overview</b></i><br/>
One of the problems we had when extracting the weather information from the web<br/>page in the previous chapter was that it was difficult to know where in the page to<br/>find the data we needed. The only way to do it was to closely examine the HTML file<br/>and work out which tags surrounded our required data. This also meant that each<br/>time the design of the page was changed, we would have to rework our program. <br/>
<i><b>10.1.1 What’s wrong with HTML?</b></i><br/>
The reason this was so difficult was that HTML was designed to model the logical<br/>structure of a document, not the meaning of the various elements. For example, an<br/>HTML document makes it easy to recognize headings at various levels, paragraphs,<br/>lists, and various other publishing elements. You can tell when an element should<br/>be printed in bold, but the problem is that you don’t know <i>why</i> that particular ele-<br/>ment was bold. It could be purely for emphasis, it could be because it is a row head-<br/>ing in a table, or it could be because it is the temperature on a weather page.<br/>
Our task would be a lot easier if the mark-up in a document told us more about<br/>
the actual meaning of the data. In our weather example, it would be nice if there was<br/>a &lt;FORECAST&gt; … &lt;/FORECAST&gt; element that surrounded the actual forecast descrip-<br/>tion and perhaps a &lt;TEMPERATURE&gt; … &lt;/TEMPERATURE&gt; element which surrounded<br/>each of the temperature figures in which we were interested. Even better, the<br/>&lt;TEMPERATURE&gt; element could have attributes which told us whether it was a maxi-<br/>mum or minimum temperature and whether it was in degrees Fahrenheit or Celsius.<br/>
<i><b>10.1.2 What is XML?</b></i><br/>
This is exactly the kind of problem that XML was designed to solve. XML is the<br/><i>Extensible Mark-up Language</i>. In fact it isn’t really a mark-up language at all, it is a<br/>method to define new mark-up languages which are better suited to particular tasks.<br/>The way it works is by defining a syntax for <i>Document Type Definitions</i> (DTDs). A<br/>DTD defines the set of elements that are allowed in a document, together with their<br/>attributes and relationships to each other. It will define which elements are manda-<br/>tory or optional, whether there is any defined order, and which elements can (or<br/>must) contain other elements. The exact syntax of DTDs is beyond the scope of this<br/>book, but there are a number of specialized books which cover it in some detail (for<br/>example <i>XML Pocket Reference</i> by Robert Eckstein and published by O’Reilly).<br/>
<hr/>
<a name=197></a><i><b>XML overview</b></i><br/>
<b>177</b><br/>
<i><b>Sample XML file<br/></b></i>Going back to our weather forecast example, we could design a DTD that defined a<br/>file format for weather forecasts. Let’s keep it very simple and say that a sample<br/>would look like this:<br/>
&lt;FORECAST&gt;<br/>
&lt;OUTLOOK&gt;<br/>
Partly Cloudy<br/>
&lt;/OUTLOOK&gt;<br/>
&lt;TEMPERATURE TYPE=&#34;MAX&#34; DEGREES=&#34;C&#34;&gt;12&lt;/TEMPERATURE&gt;<br/>
&lt;TEMPERATURE TYPE=&#34;MIN&#34; DEGREES=&#34;C&#34;&gt;6&lt;/TEMPERATURE&gt;<br/>
&lt;/FORECAST&gt;<br/>
If Yahoo! (or any other information provider) made a file available in this format<br/>then we could download it from the Internet and parse it using Perl to extract the<br/>relevant information. If the parser that we wrote was sophisticated enough, Yahoo!<br/>could reorder the contents of the source file and we would still be able to access the<br/>data. This is because the file is marked up to show what each data element is, not<br/>how it should be displayed.1<br/>
<i><b>Valid vs. well-formed<br/></b></i>It’s worth stopping at this point to discuss a couple of XML concepts. There are two<br/>levels of XML correctness. A correct XML document can be said to be <i>valid</i> or it can<br/>be said to be <i>well-formed</i>. Well-formed is the easier criterion to adhere to. This<br/>means that the document is syntactically correct or, in other words, it follows all of<br/>the general rules for XML documents. Basically, these rules say this:<br/>
■<br/>
The document must have one top-level element.<br/>
■<br/>
All elements must have opening and closing tags (except in the special case of<br/>empty tags where the opening tag is also used as the closing tag).<br/>
■<br/>
Opening and closing tags must be nested correctly (i.e., nested tags must be<br/>closed in the reverse of the order in which they were opened).<br/>
■<br/>
All attributes must be quoted and cannot contain a &lt; or an &amp; (except as the<br/>first character of a reference).<br/>
Our sample weather document fulfills all of these constraints and is, therefore,<br/>
well-formed. It cannot, however, be described as valid. A valid document is one that<br/>follows the rules laid down in a DTD. This means that it must have all of the correct<br/>elements in the right order and any nesting of elements must also be in combina-<br/>tions sanctioned by the DTD. If we wrote a weather DTD and wrote our weather<br/>
1 XML fans have been known to disparage HTML by describing it as a “What You See Is <i>All</i> You Get” language.<br/>
<hr/>
<a name=198></a><b>178</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
document to conform with that DTD then we could call it valid. Currently, we<br/>don’t have such a DTD so there is no way that our document can be valid.<br/>
XML parsers fall into two types. Validating parsers will check the document’s<br/>
structure against its DTD and nonvalidating parsers only check that the document is<br/>well-formed.<br/>
<i><b>10.2 Parsing XML with XML::Parser</b></i><br/>
Of course there are Perl XML parsers available. The most generalized one is the<br/>CPAN module XML::Parser. This module is based on an XML parser called Expat.<br/>Expat is a nonvalidating parser, so in Perl you will generally only be interested in the<br/>well-formedness of documents.2<br/>
XML::Parser works in a similar way to HTML::Parser, but as XML is more com-<br/>
plex than HTML, XML::Parser needs to be more complex than HTML::Parser. <br/>
<i><b>10.2.1 Example: parsing weather.xml</b></i><br/>
As an example of using XML::Parser, here is a simple script to parse our weather<br/>XML file:<br/>
use strict;<br/>
use XML::Parser;<br/>
my %forecast;<br/>
my @curr;<br/>
my $type;<br/>
my $p = XML::Parser-&gt;new(Style =&gt; 'Stream');<br/>
$p-&gt;parsefile(shift);<br/>
print &#34;Outlook: $forecast{outlook}\n&#34;;<br/>
foreach (keys %forecast) {<br/>
next if /outlook/;<br/>
print &#34;$_: $forecast{$_}-&gt;{val} $forecast{$_}-&gt;{deg}\n&#34;;<br/>
}<br/>
sub StartTag {<br/>
my ($p, $tag) = @_;<br/>
push @curr, $tag;<br/>
if ($tag eq 'TEMPERATURE') {<br/>
$type = $_{TYPE};<br/>
$forecast{$type}-&gt;{deg} = $_{DEGREES};<br/>
2 I hope this explains my reluctance to go into the details of DTDs—XML::Parser makes no use of them.<br/>
There is, however, an experimental subclass of XML::Parser, called XML::Checker::Parser, which does<br/>validate an XML document against a DTD. <br/>
<hr/>
<a name=199></a><i><b>Parsing XML with XML::Parser</b></i><br/>
<b>179</b><br/>
}<br/>
}<br/>
sub EndTag {<br/>
pop @curr;<br/>
};<br/>
sub Text {<br/>
my ($p) = shift;<br/>
return unless /\S/;<br/>
s/^\s+//;<br/>
s/\s+$//;<br/>
if ($curr[-1] eq 'OUTLOOK') {<br/>
$forecast{outlook} .= $_;<br/>
} elsif ( $curr[-1] eq 'TEMPERATURE') {<br/>
$forecast{$type}-&gt;{val} = $_;<br/>
}<br/>
}<br/>
Running this script against our sample weather XML document gives the follow-<br/>ing result:<br/>
<b>Outlook: Partly Cloudy</b><br/>
<b>MAX: 12 C</b><br/>
<b>MIN: 6 C</b><br/>
<i><b>10.2.2 Using XML::Parser</b></i><br/>
There are a number of different ways to use XML::Parser. In this example we are<br/>using it in a very similar manner to HTML::Parser. When we create the parser<br/>object we pass it a hash containing various configuration options. In this case, the<br/>hash consists of one key (Style) and an associated value, which is the string<br/>Stream. The Style parameter tells XML::Parser that we want to use one of a<br/>number of built-in parsing methods. The one that we want to use in this example is<br/>called Stream. In this mode XML::Parser works very similarly to HTML::Parser.<br/>There are a number of predefined methods which the parser will call when encoun-<br/>tering various parts of the XML document. For this example we need to define three<br/>of these methods. StartTag is called when the start of an XML tag is found,<br/>EndTag is called when the end of a tag is seen, and Text is called when text data is<br/>encountered. In each case the first parameter to the function will be a reference to<br/>the underlying Expat object which is doing the parsing. In the StartTag and<br/>EndTag functions the second parameter is the name of the tag which is being<br/>started or ended. The complete original tag is stored in $_. Additionally, in the<br/>
<hr/>
<a name=200></a><b>180</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
StartTag function, the list of attributes is stored in %_. In the Text function, the<br/>text that has been found is stored in $_.<br/>
This may all make a bit more sense if we look at the example code in more detail.<br/>The main part of the program defines some global variables, creates the parser,<br/>
parses the file, and displays the information which has been extracted. The global<br/>variables which it defines are: %forecast, which will store the forecast data that we<br/>want to display, @curr which is a list of all of the current elements that we are in,<br/>and $type which stores the current temperature type. All of the real work goes on<br/>in the parsing functions which are called by the parser as it processes the file.<br/>
The StartTag function pushes the new tag on to the end of the @curr array,<br/>
and if the tag starts a TEMPERATURE element, it stores the values of the TYPE and<br/>DEGREES attributes (which it finds in %_).<br/>
The EndTag function simply pops the last element from the @curr array. You<br/>
might think that we should check whether the tag that we are ending is of the same<br/>type as the current end of this list but, if it wasn’t the case, the document wouldn’t<br/>be well-formed and would, therefore, fail the parsing process.3<br/>
The Text function checks whether there is useful data in the text string (which is<br/>
stored in $_) and returns if it can’t find at least one nonspace character. It then<br/>strips leading and trailing spaces from the data. If the current element we are pro-<br/>cessing (given by $curr[-1]) is the OUTLOOK element, then the text must be the<br/>outlook description and we store it in the appropriate place in the %forecast vari-<br/>able. If the current element is a TEMPERATURE element, then the text will be the<br/>temperature data and that is also stored in the %forecast hash (making use of the<br/>current temperature type which is stored in the global $type variable).<br/>
Once the parsing is complete the data is all stored in the %forecast hash and we<br/>
can traverse the hash to display the required data. Notice that the method that we<br/>use for this makes no assumptions about the list of temperature types used. If we<br/>were to add average temperature data to the weather document, our program<br/>would still display this.<br/>
<i><b>Parsing failures</b></i><br/>
XML::Parser (and the other parsers which are based on it) have a somewhat harsh<br/>approach to non-well-formed XML documents. They will always throw a fatal<br/>exception when they encounter non-well-formed XML. Unfortunately, this behav-<br/>ior is defined in the XML specifications, so they have no choice about this, but it can<br/>still take beginners by surprise as they often expect the parse or parsefile<br/>method to return an error code, but instead their entire program is halted.<br/>
3 This always throws a fatal exception, but there are ways to prevent your program from dying if you give it<br/>
non-well-formed XML, as we will see later.<br/>
<hr/>
<a name=201></a><i><b>Parsing XML with XML::Parser</b></i><br/>
<b>181</b><br/>
It’s difficult to see what processing you might want to proceed with if your XML<br/>
document is incorrect, so in many cases dying is the correct approach for a program<br/>to take. If, however, you have a case where you want to recover a little more grace-<br/>fully you can catch the fatal exception. You do this using eval. If the code that is<br/>passed to eval causes an exception, the program does not die, but the error mes-<br/>sage is put in the variable $@. You can therefore parse your XML documents using<br/>code like this:<br/>
eval { $p-&gt;parsefile($file) };<br/>
if ($@) {<br/>
die &#34;Bad XML Document: $file\n&#34;;<br/>
} else {<br/>
print &#34;Good XML!\n&#34;;<br/>
}<br/>
<i><b>10.2.3 Other XML::Parser styles</b></i><br/>
The Stream style is only one of a number of styles which XML::Parser supports.<br/>Depending on your requirements, another style might be better suited to the task.<br/>
<i><b>Debug<br/></b></i>The Debug style simply prints out a stylized version of your XML document. Pars-<br/>ing our weather example file using the Debug style gives us the following output:<br/>
<b>\\ ()</b><br/>
<b>FORECAST || #10;</b><br/>
<b>FORECAST ||</b><br/>
<b>FORECAST \\ ()</b><br/>
<b>FORECAST OUTLOOK || #10;</b><br/>
<b>FORECAST OUTLOOK ||</b><br/>
<b>Partly Cloudy</b><br/>
<b>FORECAST OUTLOOK || #10;</b><br/>
<b>FORECAST OUTLOOK ||</b><br/>
<b>FORECAST //</b><br/>
<b>FORECAST || #10;</b><br/>
<b>FORECAST ||</b><br/>
<b>FORECAST \\ (TYPE MAX DEGREES C)</b><br/>
<b>FORECAST TEMPERATURE || 12</b><br/>
<b>FORECAST //</b><br/>
<b>FORECAST || #10;</b><br/>
<b>FORECAST ||</b><br/>
<b>FORECAST \\ (TYPE MIN DEGREES C)</b><br/>
<b>FORECAST TEMPERATURE || 6</b><br/>
<b>FORECAST //</b><br/>
<b>FORECAST || #10;</b><br/>
<b>//</b><br/>
<hr/>
<a name=202></a><b>182</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
If you look closely, you will see the structure of our weather document in this dis-<br/>play. A line containing the opening tag of a new element contains the character<br/>sequence \\ and the attributes of the element appear in brackets. A line containing<br/>the character sequence // denotes an element’s closing tag, and a line containing<br/>the character sequence || denotes the text contained within an element. The #10<br/>sequences denote the end of each line of text in the original document.<br/>
<i><b>Subs<br/></b></i>The Subs style works in a very similar manner to the Stream style, except that<br/>instead of the same functions being called for the start and end tags of each ele-<br/>ment, a different pair of functions is called for each element type. For example, in<br/>our weather document, the parser would expect to find functions called FORECAST<br/>and OUTLOOK that it would call when it found &lt;FORECAST&gt; and &lt;OUTLOOK&gt; tags.<br/>For the closing tags, it would look for functions called _FORECAST and _OUTLOOK.<br/>This method prevents the program from having to check which element type is<br/>being processed (although this information is still passed to the function as the sec-<br/>ond parameter).<br/>
<i><b>Tree<br/></b></i>All of the styles that we have seen so far have been <i>stream-based</i>. That is, they move<br/>through the document and call certain functions in your code when they come<br/>across particular events in the document. The Tree style does things differently. It<br/>parses the document and builds a data structure containing a logical model of the<br/>document. It then returns a reference to this data structure.<br/>
The data structure generated by our weather document looks like this:<br/>
[ 'FORECAST', [ {}, 0, &#34;\n<br/>
&#34;,<br/>
'OUTLOOK', [ {}, 0, &#34;\n<br/>
Partly Cloudy\n<br/>
&#34;], 0, &#34;\n<br/>
&#34;,<br/>
'TEMPERATURE', [ ( 'DEGREES' =&gt; 'C', 'TYPE' =&gt; 'MAX' }, 0, '12' ], 0, &#34;\n &#34;,<br/>
'TEMPERATURE', [ ( 'DEGREES' =&gt; 'C', 'TYPE' =&gt; 'MAX' }, 0, '6'<br/>
], 0, &#34;\n&#34;<br/>
] ]<br/>
It’s probably a little difficult to follow, so let’s look at it in detail.<br/>
Each element is represented by a list. The first item is the element type and the<br/>
second item is a reference to another list which represents the contents of the ele-<br/>ment. The first element of this second level list is a reference to a hash which con-<br/>tains the attributes for the element. If the element has no attributes then the<br/>reference to the hash still exists, but the hash itself is empty. The rest of the list is a<br/>series of pairs of items, which represent the text, and elements that are contained<br/>within the element. These pairs of items have the same structure as the original two-<br/>item list, with the exception that a text item has a special element type of 0.<br/>
<hr/>
<a name=203></a><i><b>Parsing XML with XML::Parser</b></i><br/>
<b>183</b><br/>
If you’re the sort of person who thinks that a picture is worth a thousand words,<br/>
then figure 10.1 might have saved me a lot of typing.<br/>
$doc<br/>
0<br/>
'FORECAST'<br/>
1<br/>
listref<br/>
0<br/>
hashref<br/>
empty<br/>
1<br/>
'0'<br/>
2<br/>
&#34;\n&#34;<br/>
3<br/>
'OUTLOOK'<br/>
4<br/>
listref<br/>
0<br/>
hashref<br/>
empty<br/>
5<br/>
'0'<br/>
1<br/>
'0'<br/>
6<br/>
&#34;\n&#34;<br/>
2<br/>
&#34;\nPartly Cloudy\n&#34;<br/>
7<br/>
'TEMPERATURE'<br/>
8<br/>
listref<br/>
0<br/>
hashref<br/>
degrees<br/>
'C'<br/>
9<br/>
'0'<br/>
1<br/>
'0'<br/>
type<br/>
'MAX'<br/>
10<br/>
&#34;\n&#34;<br/>
2<br/>
'12'<br/>
11<br/>
'TEMPERATURE'<br/>
12<br/>
listref<br/>
0<br/>
hashref<br/>
degrees<br/>
'C'<br/>
13<br/>
'0'<br/>
1<br/>
'0'<br/>
type<br/>
'MIN'<br/>
14<br/>
&#34;\n&#34;<br/>
2<br/>
'12'<br/>
<b>Figure 10.1</b><br/>
<b>Output from XML::Parser Tree style</b><br/>
In the figure the variable $doc is returned from the parser. You can also see the<br/>
arrays which contain the definitions of the XML content and the hashes which con-<br/>tain the attributes.<br/>
<i><b>Example: using XML::Parser in Tree style<br/></b></i>This may become clearer still if we look at some sample code for dealing with one of<br/>these structures. The following program will print out the structure of an XML doc-<br/>ument. Using it to process our weather document will give us the following output:<br/>
<b>FORECAST []</b><br/>
<b>OUTLOOK []</b><br/>
<b>Partly Cloudy</b><br/>
<b>TEMPERATURE [DEGREES: C, TYPE: MAX]</b><br/>
<b>12</b><br/>
<b>TEMPERATURE [DEGREES: C, TYPE: MIN]</b><br/>
<b>6</b><br/>
Here is the code:<br/>
use strict;<br/>
use XML::Parser;<br/>
<hr/>
<a name=204></a><b>184</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
my $p = XML::Parser-&gt;new(Style =&gt; 'Tree');<br/>
my $doc = $p-&gt;parsefile(shift);<br/>
my $level = 0;<br/>
process_node(@$doc);<br/>
sub process_node {<br/>
my ($type, $content) = @_;<br/>
my $ind = ' ' x $level;<br/>
if ($type) { # element<br/>
my $attrs = shift @$content;<br/>
print $ind, $type, ' [';<br/>
print join(', ', map { &#34;$_: $attrs-&gt;{$_}&#34; } keys %{$attrs});<br/>
print &#34;]\n&#34;;<br/>
++$level;<br/>
while (my @node = splice(@$content, 0, 2)) {<br/>
process_node(@node); # Recursively call this subroutine<br/>
}<br/>
--$level;<br/>
} else { # text<br/>
$content =~ s/\n/ /g;<br/>
$content =~ s/^\s+//;<br/>
$content =~ s/\s+$//;<br/>
print $ind, $content, &#34;\n&#34;;<br/>
}<br/>
}<br/>
Let’s look at the code in more detail.<br/>
The start of the program looks similar to any number of other parsing programs<br/>
that we’ve seen in this chapter. The only difference is that we create our XML:Parser<br/>object with the Tree style. This means that the parsefile method returns us a ref-<br/>erence to our tree structure.<br/>
As we’ve seen above, this is a reference to a list with two items in it. We’ll call one<br/>
of these two-item lists a <i>node</i> and write a function called process_node which will<br/>handle one of these lists. Before calling process_node, we initialize a global vari-<br/>able to keep track of the current element nesting level.<br/>
In the process_node function, the first thing that we do is determine the type of<br/>
node we are dealing with. If it is an element, then the first item in the node list will<br/>have a true value. Text nodes have the value 0 in this position, which will evaluate<br/>as false.<br/>
<hr/>
<a name=205></a><i><b>Parsing XML with XML::Parser</b></i><br/>
<b>185</b><br/>
If we are dealing with an element, then shifting the first element off of the con-<br/>
tent list will give us a reference to the attribute hash. We can then print out the ele-<br/>ment type and attribute list indented to the correct level.<br/>
Having dealt with the element and its attributes we can process its contents. One<br/>
advantage of using shift to get the attribute hash reference is that it now leaves<br/>the content list with an even number of items in it. Each pair of items is another<br/>node. We can simply use splice to pull the nodes off the array one at a time and<br/>pass them recursively to process_node, pausing only to increment the level before<br/>processing the content and decrementing it again when finished.<br/>
If the node is text, then the second item in the node list will be the actual text. In<br/>
this case we just clean it up a bit and print it out.<br/>
<i><b>Example: parsing weather.xml using the Tree style<br/></b></i>This program will work with any tree structure that is generated by XML::Parser<br/>using the Tree style. However, more often you will want to do something a little<br/>more specific to the document with which you are dealing. In our case, this will be<br/>printing out a weather forecast. Here is a Tree-based program for printing the fore-<br/>cast in our usual format.<br/>
use strict;<br/>
use XML::Parser;<br/>
my $p = XML::Parser-&gt;new(Style =&gt; 'Tree');<br/>
my $doc = $p-&gt;parsefile(shift);<br/>
process_node(@$doc);<br/>
sub process_node {<br/>
my ($type, $content) = @_;<br/>
if ($type eq 'OUTLOOK') {<br/>
print 'Outlook: ', trim($content-&gt;[2]), &#34;\n&#34;;<br/>
} elsif ($type eq 'TEMPERATURE') {<br/>
my $attrs = $content-&gt;[0];<br/>
my $temp = trim($content-&gt;[2]);<br/>
print &#34;$attrs-&gt;{TYPE}: $temp $attrs-&gt;{DEGREES}\n&#34;;<br/>
}<br/>
if ($type) {<br/>
while (my @node = splice @$content, 1, 2) {<br/>
process_node(@node)<br/>
}<br/>
}<br/>
}<br/>
sub trim {<br/>
<hr/>
<a name=206></a><b>186</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
local $_ = shift;<br/>
s/\n/ /g;<br/>
s/^\s+//;<br/>
s/\s+$//;<br/>
return $_;<br/>
}<br/>
The basic structure of this program is quite similar to the previous one. All of the<br/>work is still done in the process_node function. In this version, however, we are<br/>on the lookout for particular element types which we know we want to process.<br/>When we find an OUTLOOK element or a TEMPERATURE element we know exactly<br/>what we need to do. All other elements are simply ignored. In the case of an<br/>OUTLOOK element we simply extract the text from the element and print it out.<br/>Notice that the text contained within the element is found at $content-&gt;[2], the<br/>third item in the content array. This is true for any element that only contains text,<br/>as the first two items in the content list will always be a reference to the attribute<br/>hash and the character 0.<br/>
The processing for the TEMPERATURE element type is only slightly more complex<br/>
as we need to access the attribute hash to find out the type of the temperature (min-<br/>imum or maximum) and the kind of degrees in which is it measured.<br/>
Notice that we still need to process any child elements and that this is still done in<br/>
the same way as in the previous program—by removing nodes from the @$content<br/>list. In this case we haven’t removed the attribute hash from the front of the list, so we<br/>start the splice from the second item in the list (the second item has the index 0).<br/>
<i><b>Objects<br/></b></i>The Objects style works very much like the Tree style, except that instead of arrays<br/>and hashes, the document tree is presented as a collection of objects. Each element<br/>type becomes a different object class. The name of the class is created by appending<br/>main:: to the front of the element’s name.4 Text data is turned into an object of<br/>class main::Characters. The value that is returned by the parse method is a ref-<br/>erence to an array of such objects. As a well-formed XML object can only have one<br/>top-level element, this array will only have one element. <br/>
4 This is the default behavior. You can create your objects within other packages by using the Pkg option<br/>
to XML::Parser-&gt;new. For example:<br/>
my $p = XML::Parser-&gt;new(Style =&gt; 'Objects', Pkg =&gt; 'Some_Other_Package');<br/>
<hr/>
<a name=207></a><i><b>Parsing XML with XML::Parser</b></i><br/>
<b>187</b><br/>
Attributes of the element are stored in the element hash. This hash also contains<br/>
a special key, Kids. The value associated with this key is a reference to an array<br/>which contains all of the children of the element.<br/>
<i><b>Example: parsing XML with XML::Parser using the Objects style<br/></b></i>Here is a program that displays the structure of any given XML document using the<br/>Objects style:<br/>
use strict;<br/>
use XML::Parser;<br/>
my $p = XML::Parser-&gt;new(Style =&gt; 'Objects');<br/>
my $doc = $p-&gt;parsefile(shift);<br/>
my $level = 0;<br/>
process_node($doc-&gt;[0]);<br/>
sub process_node {<br/>
my ($node) = @_;<br/>
my $ind = ' ' x $level;<br/>
my $type = ref $node;<br/>
$type =~ s/^.*:://;<br/>
if ($type ne 'Characters') {<br/>
my $attrs = {%$node};<br/>
delete $attrs-&gt;{Kids};<br/>
print $ind, $type, ' [';<br/>
print join(', ', map { &#34;$_: $attrs-&gt;{$_}&#34; } keys %{$attrs});<br/>
print &#34;]\n&#34;;<br/>
++$level;<br/>
foreach my $node (@{$node-&gt;{Kids}}) {<br/>
process_node($node);<br/>
}<br/>
--$level;<br/>
} else {<br/>
my $content = $node-&gt;{Text};<br/>
$content =~ s/\n/ /g;<br/>
$content =~ s/^\s+//;<br/>
$content =~ s/\s+$//;<br/>
print $ind, $content, &#34;\n&#34; if $content =~ /\S/;<br/>
}<br/>
}<br/>
This program is very similar to the example that we wrote using the Tree style.<br/>Once again, most of the processing is carried out in the process_node function. In<br/>
<hr/>
<a name=208></a><b>188</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
this case each node is represented by a single reference rather than a two-item list.<br/>The first thing that we do in process_node is to work out the type of element with<br/>which we are dealing. We do this by using the standard Perl function ref. This<br/>function takes one parameter, which is a reference, and returns a string containing<br/>the type of object that the reference refers to. For example, if you pass it a reference<br/>to an array, it will return the string ARRAY. This is a good way to determine the<br/>object type a reference has been blessed into. In our case, each reference that we<br/>pass to it will be of type main::Element, where Element is the name of one of our<br/>element types. We remove the main:: from the front of the string to leave us with<br/>the specific element with which we are dealing.<br/>
If we are dealing with an element (rather than character data) we then take a<br/>
copy of the object hash which we will use to get the list of attributes. Notice that<br/>we don’t use the more obvious $attrs = $node as this only copies the reference<br/>and still leaves it pointing to the same original hash. As the next line of the code<br/>deletes the Kids array reference from this hash, we use the slightly more complex<br/>$attrs = {%$node} as this takes a copy of the original hash and returns a refer-<br/>ence to the new copy. We can then delete the Kids reference without doing any<br/>lasting damage to the original object.<br/>
Having retrieved the attribute hash, we display the element type along with its<br/>
attributes. We then need to process all of the element’s children. We do this by iter-<br/>ating across the Kids array (which is why it’s a good idea that we didn’t delete the<br/>original earlier), passing each object in turn to process_node.<br/>
If the object with which we are dealing is of the class Characters then it contains<br/>
character data and we can access the actual text by using the special Text key.<br/>
<i><b>Choosing between Tree and Object styles<br/></b></i>The Tree and Object styles can both be used to address the same set of problems.<br/>You would usually use one of these two styles when your document processing<br/>requires multiple passes over the document structure. Whether you choose the Tree<br/>or Objects style for your tree-based parsing requirements is simply a matter of per-<br/>sonal taste.<br/>
<i><b>10.2.4 XML::Parser handlers</b></i><br/>
The XML::Parser styles that we have been discussing are a series of prebuilt meth-<br/>ods for parsing XML documents in a number of popular ways. If none of these<br/>styles meet your requirements, there is another way that you can use XML::Parser<br/>which gives even more control over the way it works. This is accomplished by set-<br/>ting up a series of <i>handlers</i> which can respond to various events that are triggered<br/>while parsing a document. This is very similar to the way we used HTML::Parser<br/>or the Stream style of XML::Parser.<br/>
<hr/>
<a name=209></a><i><b>Parsing XML with XML::Parser</b></i><br/>
<b>189</b><br/>
Handlers can be set to process a large number of XML constructs. The most obvi-<br/>
ous ones are the start and end of an XML element or character data, but you can also<br/>set handlers for the XML declaration, various DTD definitions, XML comments, proc-<br/>essing instructions, and any other construct that you find in an XML document.<br/>
You set handlers either by using the Handlers parameter when you create a parser<br/>
object, or by using the setHandlers method later on. If you use the Handlers<br/>parameter then the value associated with the parameter should be a reference to a<br/>hash. In this hash the keys will be handler names, and each value will be a reference<br/>to the appropriate function. <br/>
Different handler functions receive different sets of parameters. The full set of<br/>
handlers and their parameters can be found in the XML::Parser documentation,<br/>but here is a brief summary of the most frequently used ones:<br/>
■<br/>
<i>Init</i><b>—</b>Called before parsing of a document begins. It is passed a reference to<br/>the Expat parser object.<br/>
■<br/>
<i>Final</i><b>—</b>Called after parsing of a document is complete. It is passed a reference<br/>to the Expat parser object.<br/>
■<br/>
<i>Start</i><b>—</b>Called when the opening tag of an XML element is encountered. It is<br/>passed a reference to the Expat parser object, the name of the element, and<br/>a series of pairs of values which represents the name and value of the ele-<br/>ment’s attributes.<br/>
■<br/>
<i>End</i><b>—</b>Called when the closing tag of an XML element is encountered. It is<br/>passed a reference to the Expat parser object and the name of the element.<br/>
■<br/>
<i>Char</i><b>—</b>Called when character data is encountered. It is passed a reference to<br/>the Expat parser object and the string of characters that has been found.<br/>
All of these subroutines are passed a reference to the Expat parser object. This is<br/>
the actual object that XML::Parser uses to parse your XML document. It is useful<br/>in some more complex parsing techniques, but at this point you can safely ignore it.<br/>
<i><b>Example: parsing XML using XML::Parser handlers<br/></b></i>Here is an example of our usual program for displaying the document structure,<br/>rewritten to use handlers.<br/>
use strict;<br/>
use XML::Parser;<br/>
my $p = XML::Parser-&gt;new(Handlers =&gt; {Init<br/>
=&gt; \&amp;init,<br/>
Start =&gt; \&amp;start,<br/>
End<br/>
=&gt; \&amp;end,<br/>
Char<br/>
=&gt; \&amp;char});<br/>
my ($level, $ind);<br/>
<hr/>
<a name=210></a><b>190</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
my $text;<br/>
$p-&gt;parsefile(shift);<br/>
sub init {<br/>
$level = 0;<br/>
$text = '';<br/>
}<br/>
sub start {<br/>
my ($p, $tag) = (shift, shift);<br/>
my %attrs = @_ if @_;<br/>
print $ind, $tag, ' [';<br/>
print join ', ', map { &#34;$_: $attrs{$_}&#34; } keys %attrs;<br/>
print &#34;]\n&#34;;<br/>
$level++;<br/>
$ind = ' ' x $level;<br/>
}<br/>
sub end {<br/>
print $ind, $text, &#34;\n&#34;;<br/>
$level--;<br/>
$ind = ' ' x $level;<br/>
$text = '';<br/>
}<br/>
sub char {<br/>
my ($p, $str) = (shift, shift);<br/>
return unless $str =~ /\S/;<br/>
$str =~ s/^\s+//;<br/>
$str =~ s/\s+$//;<br/>
$text .= $str;<br/>
}<br/>
In this case we only need to define four handlers for Init, Start, End, and Char.<br/>The Init handler only exists to allow us to set $level and $text to initial values.<br/>
In the Start handler we do very similar processing to the previous examples.<br/>
That is, we print the element’s name and attributes. In this case it is very easy to get<br/>these values as they are passed to us as parameters. We also increment $level and<br/>use the new value to calculate an indent string which we will print before any output.<br/>
In the End handler we print out any text that has been built up in $text, decre-<br/>
ment $level, recalculate $ind, and reset $text to an empty string.<br/>
In the Char handler we do the usual cleaning that strips any leading and trailing<br/>
white space and appends the string to $text. Notice that it is possible that because<br/>
<hr/>
<a name=211></a><i><b>XML::DOM</b></i><br/>
<b>191</b><br/>
of the way the parser works, any particular sequence of character data can be split up<br/>and processed in a number of calls to this handler. This is why we build up the<br/>string and print it out only when we find the closing element tag. This would be<br/>even more important if we were applying some kind of formatting to the text before<br/>displaying it.<br/>
<i><b>10.3 XML::DOM</b></i><br/>
As we have seen, XML::Parser is a very powerful and flexible module, and one that<br/>can be used to handle just about any XML processing requirement. However, it’s<br/>well known that one of the Perl mottoes is that there’s more than one way to do it,<br/>and one of the cardinal virtues of a programmer is laziness.5 It should not therefore<br/>come as a surprise that there are many other XML parser modules available from the<br/>CPAN. Some of these are specialized to deal with XML that conforms to a particular<br/>DTD (we will look at one of these a bit later), but many others present yet more<br/>ways to handle general XML parsing tasks. Probably the most popular of these is<br/>XML::DOM. This is a tree-based parser which returns a radically different view of an<br/>XML document.<br/>
XML::DOM implements the Document Object Model. DOM is a way to access<br/>
arbitrary parts of an XML document. DOM has been defined by the World Wide<br/>Web Consortium (W3C), and is rapidly becoming a standard method to parse and<br/>access XML documents.<br/>
XML::DOM is a subclass of XML::Parser, so all XML::Parser methods are still<br/>
available, but on top of these methods, XML::DOM implements a whole new set of<br/>methods which allow you to walk the document tree. <br/>
<i><b>10.3.1 Example: parsing XML using XML::DOM</b></i><br/>
As an example of XML::DOM in use, here is our usual document structure script rewrit-<br/>ten to use it.<br/>
use strict;<br/>
use XML::DOM;<br/>
my $p = XML::DOM::Parser-&gt;new;<br/>
my $doc = $p-&gt;parsefile(shift);<br/>
my $level = 0;<br/>
process_node($doc-&gt;getFirstChild);<br/>
sub process_node {<br/>
5 The other two being impatience and hubris, according to Larry Wall.<br/>
<hr/>
<a name=212></a><b>192</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
my ($node) = @_;<br/>
my $ind = ' ' x $level;;<br/>
my $nodeType = $node-&gt;getNodeType;<br/>
if ($nodeType == ELEMENT_NODE) {<br/>
my $type = $node-&gt;getTagName;<br/>
my $attrs = $node-&gt;getAttributes;<br/>
print $ind, $type, ' [';<br/>
my @attrs;<br/>
foreach (0 .. $attrs-&gt;getLength - 1) {<br/>
my $attr = $attrs-&gt;item($_);<br/>
push @attrs, $attr-&gt;getNodeName . ': ' . $attr-&gt;getValue;<br/>
}<br/>
print join (', ', @attrs);<br/>
print &#34;]\n&#34;;<br/>
my $nodelist = $node-&gt;getChildNodes;<br/>
++$level;<br/>
for (0 .. $nodelist-&gt;getLength - 1) {<br/>
process_node($nodelist-&gt;item($_));<br/>
}<br/>
--$level;<br/>
} elsif ($nodeType == TEXT_NODE) {<br/>
my $content = $node-&gt;getData;<br/>
$content =~ s/\n/ /g;<br/>
$content =~ s/^\s+//;<br/>
$content =~ s/\s+$//;<br/>
print $ind, $content, &#34;\n&#34; if $content =~ /\S/;<br/>
}<br/>
}<br/>
A lot of the structure of this program will be very familiar by now, so we will look at<br/>only the differences between this version and the Tree style version.<br/>
You should first notice that the value returned by parsefile is a reference to an<br/>
object that represents the whole document. To get the single element which con-<br/>tains the whole document, we need to call this object’s getFirstChild method.<br/>We can then pass this reference to the process_node function.<br/>
Within the process_node function we still do exactly the same things that we<br/>
have been doing in previous versions of this script; it is only the way that we access<br/>the data which is different. To work out the type of the current node, we call its<br/>getNodeType method. This returns an integer defining the type. The XML::DOM<br/>module exports constants which make these values easier to interpret. In this<br/>
<hr/>
<a name=213></a><i><b>Specialized parsers—XML::RSS</b></i><br/>
<b>193</b><br/>
simplified example we only check for ELEMENT_NODE or TEXT_NODE, but there are a<br/>number of other values listed in the module’s documentation.<br/>
Having established that we are dealing with an element node, we get the tag’s<br/>
name using the getTagName method and a reference to its list of attributes using the<br/>getAttributes method. The value returned by getAttributes is a reference to a<br/>NodeList<i> </i>object. We can get the number of nodes in the list with the getLength<br/>method and retrieve each node in the list in turn, using the item method. For each of<br/>the nodes returned we can get the attribute name and value using the getNodeName<br/>and getValue methods, respectively.<br/>
Having retrieved and displayed the node attributes we can deal with the<br/>
node’s children. The getChildNodes method returns a NodeList of child nodes<br/>which we can iterate over (using getLength and item again), recursively passing<br/>each node to process_node.<br/>
If the node that we are dealing with is a text node, we get the actual text using the<br/>
getData method, and process the text in exactly the same way we have before.<br/>
This description has barely scratched the surface of XML::DOM, but it is some-<br/>
thing that you will definitely come across if you process XML data.<br/>
<i><b>10.4 Specialized parsers—XML::RSS</b></i><br/>
Some of the subclasses of XML::Parser are specialized to deal with particular types<br/>of XML documents, i.e., documents which conform to a particular DTD. As an<br/>example we will look at one of the most popular of these parsers, XML::RSS.<br/>
<i><b>10.4.1 What is RSS?</b></i><br/>
As you can probably guess, XML::RSS parses rich site summary (RSS) files. The RSS<br/>format has become very popular among web sites that want to exchange ideas<br/>about the information they are currently displaying. This is most often used by<br/>news-based sites, as they can create an RSS file containing their current headlines<br/>and other sites can grab the file and create a list of the headlines on a web page. <br/>
Quite a community of RSS-swapping has built up around these files. My Netscape<br/>
and Slashdot are two of the biggest sites using this technology. Chris Nandor has<br/>built a web site called My Portal which demonstrates a web page which users can<br/>configure to show news stories from the sources which interest them.<br/>
<i><b>10.4.2 A sample RSS file</b></i><br/>
Here is an example of an RSS file for a fictional news site called Dave’s news.<br/>
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;<br/>
&lt;!DOCTYPE rss PUBLIC &#34;//Netscape Communications//DTD RSS 0.91//EN&#34;<br/>
<hr/>
<a name=214></a><b>194</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
&#34;http://my.netscape.com/publish/formats/rss-0.91.dtd&#34;&gt;<br/>
&lt;rss version=&#34;0.91&#34;&gt;<br/>
&lt;channel&gt;<br/>
&lt;title&gt;Dave's News&lt;/title&gt;<br/>
&lt;link&gt;http://daves.news&lt;/link&gt;<br/>
&lt;description&gt;All the news that's unfit to print!&lt;/description&gt;<br/>
&lt;language&gt;en&lt;/language&gt;<br/>
&lt;pubDate&gt;Wed May 10 21:06:38 2000&lt;/pubDate&gt;<br/>
&lt;managingEditor&gt;ed@daves.news&lt;/managingEditor&gt;<br/>
&lt;webMaster&gt;webmaster@daves.news&lt;/webMaster&gt;<br/>
&lt;image&gt;<br/>
&lt;title&gt;Dave's News&lt;/title&gt;<br/>
&lt;url&gt;http://daves.news/images/logo.gif&lt;/url&gt;<br/>
&lt;link&gt;http://daves.news&lt;/link&gt;<br/>
&lt;/image&gt;<br/>
&lt;item&gt;<br/>
&lt;title&gt;Data Munging Book tops best sellers list&lt;/title&gt;<br/>
&lt;link&gt;http://daves.news/cgi-bin/read.pl?id=1&lt;/link&gt;<br/>
&lt;/item&gt;<br/>
&lt;item&gt;<br/>
&lt;title&gt;Microsoft abandons ASP for Perl&lt;/title&gt;<br/>
&lt;link&gt;http://daves.news/cgi-bin/read.pl?id=2&lt;/link&gt;<br/>
&lt;/item&gt;<br/>
&lt;item&gt;<br/>
&lt;title&gt;Gates offers job to Torvalds&lt;/title&gt;<br/>
&lt;link&gt;http://daves.news/cgi-bin/read.pl?id=3&lt;/link&gt;<br/>
&lt;/item&gt;<br/>
&lt;/channel&gt;<br/>
&lt;/rss&gt;<br/>
I hope you can see that the structure is very simple. The first thing to notice is that<br/>because the file could potentially be processed using a validating parser, it needs a<br/>reference to a DOCTYPE (or DTD). This is given on the second line and points to<br/>version 0.91 of the DTD (which, you’ll notice, was defined by Netscape). After the<br/>DOCTYPE definition, the next line opens the top-level element, which is called<br/>&lt;rss&gt;. Within one RSS file you can define multiple channels; however, most RSS<br/>files will contain only one channel.<br/>
With the channel element you can define a number of data items which define<br/>
the channel. Only a subset of the possible items is used in this example. The next<br/>complex data item is the &lt;image&gt; element. This element defines an image which a<br/>client program can display to identify your channel. You can define a URL to fetch<br/>the image from, a title, and a link. It is obviously up to the client program how this<br/>
<hr/>
<a name=215></a><i><b>Specialized parsers—XML::RSS</b></i><br/>
<b>195</b><br/>
information is used, but if the channel was being displayed in a browser, it might be<br/>useful to display the image as a hot link to the given URL and to use the title as the<br/>ALT text for the image.<br/>
After the image element comes a list of the items which the channel contains.<br/>
Once more, the exact use of this information is up to the client application, but<br/>browsers often display the title as a hot link to the given URL. Notice that the URLs<br/>in the list of items are to individual news stories, whereas the earlier URLs were to<br/>the main page of the site.<br/>
<i><b>10.4.3 Example: creating an RSS file with XML::RSS</b></i><br/>
XML::RSS differs from other XML parsers that we have seen as it can also be used to<br/>create an RSS file. Here is the script that I used to create the file given above:<br/>
#!/usr/bin/perl -w<br/>
use strict;<br/>
use XML::RSS;<br/>
my $rss = XML::RSS-&gt;new;<br/>
$rss-&gt;channel(title =&gt; &#34;Dave's News&#34;,<br/>
link =&gt; 'http://daves.news',<br/>
language =&gt; 'en',<br/>
description =&gt; &#34;All the news that's unfit to print!&#34;,<br/>
pubDate =&gt; scalar localtime,<br/>
managingEditor =&gt; 'ed@daves.news',<br/>
webMaster =&gt; 'webmaster@daves.news');<br/>
$rss-&gt;image(title =&gt; &#34;Dave's News&#34;,<br/>
url =&gt; 'http://daves.news/images/logo.gif',<br/>
link =&gt; 'http://daves.news');<br/>
$rss-&gt;add_item(title=&gt;'Data Munging Book tops best sellers list',<br/>
link=&gt;'http://daves.news/cgi-bin/read.pl?id=1');<br/>
$rss-&gt;add_item(title=&gt;'Microsoft abandons ASP for Perl',<br/>
link=&gt;'http://daves.news/cgi-bin/read.pl?id=2');<br/>
$rss-&gt;add_item(title=&gt;'Gates offers job to Torvalds',<br/>
link=&gt;'http://daves.news/cgi-bin/read.pl?id=3');<br/>
$rss-&gt;save('news.rss');<br/>
As you can see, XML::RSS makes the creation of RSS files almost trivial. You create<br/>an RSS object using the class’s new method and then add a channel using the<br/>channel method. The named parameters to the channel method are the various<br/>subelements of the &lt;channel&gt; element in the RSS file. I’m only using a subset here.<br/>The full set is described in the documentation for the XML::RSS which you can<br/>
<hr/>
<a name=216></a><b>196</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
access by typing perldoc XML::RSS from your command line once you have<br/>installed the module.<br/>
The image method is used to add image information to the RSS object. Once<br/>
more, the various subelements of the &lt;image&gt; element are passed as named param-<br/>eters to the method. For each item that you wish to add to the RSS file, you call the<br/>add_item method. Finally, to write the RSS object to a file you use the save<br/>method. You could also use the as_string method, which will return the XML<br/>that your RSS object generates.<br/>
<i><b>10.4.4 Example: parsing an RSS file with XML::RSS</b></i><br/>
Interpreting an RSS file using XML::RSS is just as simple. Here is a script which dis-<br/>plays some of the more useful data from an RSS file.<br/>
use strict;<br/>
use XML::RSS;<br/>
my $rss = XML::RSS-&gt;new;<br/>
$rss-&gt;parsefile(shift);<br/>
print $rss-&gt;channel('title'), &#34;\n&#34;;<br/>
print $rss-&gt;channel('description'), &#34;\n&#34;;<br/>
print $rss-&gt;channel('link'), &#34;\n&#34;;<br/>
print 'Published: ', $rss-&gt;channel('pubDate'), &#34;\n&#34;;<br/>
print 'Editor: ', $rss-&gt;channel('managingEditor'), &#34;\n\n&#34;;<br/>
print &#34;Items:\n&#34;;<br/>
foreach (@{$rss-&gt;items}) {<br/>
print $_-&gt;{title}, &#34;\n\t&lt;&#34;, $_-&gt;{link}, &#34;&gt;\n&#34;;<br/>
}<br/>
The file is parsed using the parsefile method (which XML::RSS overrides from its<br/>parent XML::Parser). This method adds data structures modeling the RSS file to<br/>the RSS parser object. This data can be accessed using various accessor methods.<br/>The channel method gives you access to the various parts of the &lt;channel&gt; ele-<br/>ment, and the items method returns a list of the items in the file. Each element in<br/>the items list is a reference to a hash containing the various attributes of one item<br/>from the file.<br/>
If we run this script on our sample RSS file, here is the output that we get.<br/>
<b>Dave's News</b><br/>
<b>All the news that's unfit to print!</b><br/>
<b>http://daves.news</b><br/>
<b>Published: Wed May 10 21:06:38 2000</b><br/>
<b>Editor: ed@daves.news</b><br/>
<b>Items:</b><br/>
<hr/>
<a name=217></a><i><b>Producing different document formats</b></i><br/>
<b>197</b><br/>
<b>Data Munging Book tops best sellers list</b><br/>
<b>&lt;http://daves.news/cgi-bin/read.pl?id=1&gt;</b><br/>
<b>Microsoft abandons ASP for Perl</b><br/>
<b>&lt;http://daves.news/cgi-bin/read.pl?id=2&gt;</b><br/>
<b>Gates offers job to Torvalds</b><br/>
<b>&lt;http://daves.news/cgi-bin/read.pl?id=3&gt;</b><br/>
This example script only displays very basic information about the RSS file, but it<br/>should be simple to expand it to display more details and to produce an HTML page<br/>instead of text. There are a number of example scripts in the XML::RSS distribution<br/>which you can use as a basis for your scripts.<br/>
<i><b>10.5 Producing different document formats</b></i><br/>
One of the best uses of XML is producing different outputs from the same input<br/>file. As an example of this kind of processing, in this section we will look at produc-<br/>ing a number of different document formats from a single XML document. The<br/>example that we will look at is the documentation for Perl modules. Traditionally,<br/>when a Perl module is released to the CPAN the accompanying documentation is<br/>written in <i>plain old documentation</i> (POD). POD is a very simple markup language<br/>which can be embedded within Perl code. The Perl interpreter knows to ignore it,<br/>and there are a number of documentation tools which can be used to extract the<br/>POD from a Perl script and present it in a number of formats.6<br/>
In this example we will put the documentation for a Perl module in an XML file<br/>
and use a Perl script to convert this XML document to POD, HTML, or plain text.<br/>
<i><b>10.5.1 Sample XML input file</b></i><br/>
Here is an example of the XML document we will use.<br/>
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;<br/>
&lt;README&gt;<br/>
&lt;NAME&gt;Test README File&lt;/NAME&gt;<br/>
&lt;SYNOPSIS&gt;<br/>
This is a summary of the file.<br/>
It should appear in PRE tags<br/>
&lt;/SYNOPSIS&gt;<br/>
&lt;DESCRIPTION&gt;<br/>
&lt;TEXT&gt;This is the full description of the file&lt;/TEXT&gt;<br/>
&lt;SUBSECTION&gt;<br/>
&lt;HEAD&gt;Subsection Title&lt;/HEAD&gt;<br/>
&lt;TEXT&gt;Subsection text&lt;/TEXT&gt;<br/>
6 You can find out a lot more about POD by reading the <i>perlpod</i> manual page.<br/>
<hr/>
<a name=218></a><b>198</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
&lt;/SUBSECTION&gt;<br/>
&lt;SUBSECTION&gt;<br/>
&lt;HEAD&gt;Another Subsection Title&lt;/HEAD&gt;<br/>
&lt;TEXT&gt;More Subsection text&lt;/TEXT&gt;<br/>
&lt;LIST TYPE='bullet'&gt;<br/>
&lt;ITEM&gt;List item 1&lt;/ITEM&gt;<br/>
&lt;ITEM&gt;List item 2&lt;/ITEM&gt;<br/>
&lt;/LIST&gt;<br/>
&lt;/SUBSECTION&gt;<br/>
&lt;/DESCRIPTION&gt;<br/>
&lt;AUTHOR&gt;<br/>
&lt;ANAME&gt;Dave Cross&lt;/ANAME&gt;<br/>
&lt;EMAIL&gt;dave@mag-sol.com&lt;/EMAIL&gt;<br/>
&lt;/AUTHOR&gt;<br/>
&lt;SEE_ALSO&gt;<br/>
&lt;LIST TYPE='bullet'&gt;<br/>
&lt;ITEM&gt;Something&lt;/ITEM&gt;<br/>
&lt;ITEM&gt;Something else&lt;/ITEM&gt;<br/>
&lt;/LIST&gt;<br/>
&lt;/SEE_ALSO&gt;<br/>
&lt;/README&gt;<br/>
This file supports most of the headings that you will see in a Perl module’s README file. <br/>
<i><b>10.5.2 XML document transformation script</b></i><br/>
Here is the script that we will use to transform it into other formats.<br/>
1: #!/usr/bin/perl -w<br/>
2:<br/>
3: use strict;<br/>
4:<br/>
5: use XML::Parser;<br/>
6: use Getopt::Std;<br/>
7: use Text::Wrap;<br/>
8:<br/>
9: my %formats = (h =&gt; {name =&gt; 'html'},<br/>
10:<br/>
p =&gt; {name =&gt; 'pod'},<br/>
11:<br/>
t =&gt; {name =&gt; 'text'});<br/>
12:<br/>
13: my %opts;<br/>
14: (getopts('f:', \%opts) &amp;&amp; @ARGV)<br/>
15:<br/>
|| die &#34;usage: format_xml.pl -f h|p|t xml_file\n&#34;;<br/>
16:<br/>
17: die &#34;Invalid format: $opts{f}\n&#34; unless exists $formats{$opts{f}};<br/>
18:<br/>
19: warn &#34;Formatting file as $formats{$opts{f}}-&gt;{name}\n&#34;;<br/>
20:<br/>
<hr/>
<a name=219></a><i><b>Producing different document formats</b></i><br/>
<b>199</b><br/>
21: my $p = XML::Parser-&gt;new(Style =&gt; 'Tree');<br/>
22: my $tree = $p-&gt;parsefile(shift);<br/>
23:<br/>
24: my $level = 0;<br/>
25: my $ind = '';<br/>
26: my $head = 1;<br/>
27:<br/>
28: top($tree);<br/>
29:<br/>
30: process_node(@$tree);<br/>
31:<br/>
32: bot();<br/>
33:<br/>
34: sub process_node {<br/>
35:<br/>
my ($type, $content) = @_;<br/>
36:<br/>
37:<br/>
$ind = ' ' x $level;<br/>
38:<br/>
39:<br/>
if ($type) {<br/>
40:<br/>
41:<br/>
local $_ = $type;<br/>
42:<br/>
43:<br/>
my $attrs = shift @$content;<br/>
44:<br/>
45:<br/>
/^NAME$/ &amp;&amp; name($content);<br/>
46:<br/>
/^SYNOPSIS$/ &amp;&amp; synopsis($content);<br/>
47:<br/>
/^DESCRIPTION$/ &amp;&amp; description();<br/>
48:<br/>
/^TEXT$/ &amp;&amp; text($content);<br/>
49:<br/>
/^CODE$/ &amp;&amp; code($content);<br/>
50:<br/>
/^HEAD$/ &amp;&amp; head($content);<br/>
51:<br/>
/^LIST$/ &amp;&amp; do {list($attrs, $content); @$content = ()};<br/>
52:<br/>
/^AUTHOR$/ &amp;&amp; author();<br/>
53:<br/>
/^ANAME$/ &amp;&amp; aname($content);<br/>
54:<br/>
/^EMAIL$/ &amp;&amp; email($content);<br/>
55:<br/>
/^SEE_ALSO$/ &amp;&amp; see_also($content);<br/>
56:<br/>
57:<br/>
while (my @node = splice @$content, 0, 2) {<br/>
58:<br/>
++$level;<br/>
59:<br/>
++$head if $type eq 'SUBSECTION';<br/>
60:<br/>
process_node(@node);<br/>
61:<br/>
--$head if $type eq 'SUBSECTION';<br/>
62:<br/>
--$level;<br/>
63:<br/>
}<br/>
64:<br/>
}<br/>
65: }<br/>
66:<br/>
67: sub top {<br/>
68:<br/>
$tree = shift;<br/>
69:<br/>
70:<br/>
if ($opts{f} eq 'h') {<br/>
71:<br/>
print &#34;&lt;html&gt;\n&#34;;<br/>
<hr/>
<a name=220></a><b>200</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
72:<br/>
print &#34;&lt;head&gt;\n&#34;;<br/>
73:<br/>
print &#34;&lt;title&gt;$tree-&gt;[1]-&gt;[4]-&gt;[2]&lt;/title&gt;\n&#34;;<br/>
74:<br/>
print &#34;&lt;/head&gt;\n&lt;body&gt;\n&#34;;<br/>
75:<br/>
} elsif ($opts{f} eq 'p') {<br/>
76:<br/>
print &#34;=pod\n\n&#34;;<br/>
77:<br/>
} elsif ($opts{f} eq 't') {<br/>
78:<br/>
print &#34;\n&#34;, $tree-&gt;[1]-&gt;[4]-&gt;[2], &#34;\n&#34;;<br/>
79:<br/>
print '-' x length($tree-&gt;[1]-&gt;[4]-&gt;[2]), &#34;\n\n&#34;;<br/>
80:<br/>
}<br/>
81: }<br/>
82:<br/>
83: sub bot {<br/>
84:<br/>
if ($opts{f} eq 'h') {<br/>
85:<br/>
print &#34;&lt;/body&gt;\n&lt;/html&gt;\n&#34;;<br/>
86:<br/>
} elsif ($opts{f} eq 'p') {<br/>
87:<br/>
print &#34;=cut\n\n&#34;;<br/>
88:<br/>
} elsif ($opts{f} eq 't') {<br/>
89:<br/>
# do nothing<br/>
90:<br/>
}<br/>
91: }<br/>
92:<br/>
93: sub name {<br/>
94:<br/>
my $content = shift;<br/>
95:<br/>
96:<br/>
if ($opts{f} eq 'h') {<br/>
97:<br/>
print &#34;&lt;h1&gt;NAME&lt;/h1&gt;\n&#34;;<br/>
98:<br/>
print &#34;&lt;p&gt;$content-&gt;[1]&lt;/p&gt;\n&#34;<br/>
99:<br/>
} elsif ($opts{f} eq 'p') {<br/>
100:<br/>
print &#34;=head1 NAME\n\n&#34;;<br/>
101:<br/>
print &#34;$content-&gt;[1]\n\n&#34;;<br/>
102:<br/>
} elsif ($opts{f} eq 't') {<br/>
103:<br/>
print &#34;NAME\n\n&#34;;<br/>
104:<br/>
print $ind, &#34;$content-&gt;[1]\n\n&#34;;<br/>
105:<br/>
}<br/>
106: }<br/>
107:<br/>
108: sub synopsis {<br/>
109:<br/>
my $content = shift;<br/>
110:<br/>
111:<br/>
if ($opts{f} eq 'h') {<br/>
112:<br/>
print &#34;&lt;h1&gt;SYNOPSIS&lt;/h1&gt;\n&#34;;<br/>
113:<br/>
print &#34;&lt;pre&gt;$content-&gt;[1]&lt;/pre&gt;\n&#34;<br/>
114:<br/>
} elsif ($opts{f} eq 'p') {<br/>
115:<br/>
print &#34;=head1 SYNOPSIS\n\n&#34;;<br/>
116:<br/>
print &#34;$content-&gt;[1]\n&#34;;<br/>
117:<br/>
} elsif ($opts{f} eq 't') {<br/>
118:<br/>
print &#34;SYNOPSIS\n&#34;;<br/>
119:<br/>
print &#34;$content-&gt;[1]\n&#34;;<br/>
120:<br/>
}<br/>
121: }<br/>
122:<br/>
<hr/>
<a name=221></a><i><b>Producing different document formats</b></i><br/>
<b>201</b><br/>
123: sub description {<br/>
124:<br/>
125:<br/>
if ($opts{f} eq 'h') {<br/>
126:<br/>
print &#34;&lt;h1&gt;DESCRIPTION&lt;/h1&gt;\n&#34;;<br/>
127:<br/>
} elsif ($opts{f} eq 'p') {<br/>
128:<br/>
print &#34;=head1 DESCRIPTION\n\n&#34;;<br/>
129:<br/>
} elsif ($opts{f} eq 't') {<br/>
130:<br/>
print &#34;DESCRIPTION\n\n&#34;;<br/>
131:<br/>
}<br/>
132: }<br/>
133:<br/>
134: sub text {<br/>
135:<br/>
my $content = shift;<br/>
136:<br/>
137:<br/>
if ($opts{f} eq 'h') {<br/>
138:<br/>
print &#34;&lt;p&gt;$content-&gt;[1]&lt;/p&gt;\n&#34;<br/>
139:<br/>
} elsif ($opts{f} eq 'p') {<br/>
140:<br/>
print wrap('', '', trim($content-&gt;[1])), &#34;\n\n&#34;;<br/>
141:<br/>
} elsif ($opts{f} eq 't') {<br/>
142:<br/>
print wrap($ind, $ind, trim($content-&gt;[1])), &#34;\n\n&#34;;<br/>
143:<br/>
}<br/>
144: }<br/>
145:<br/>
146: sub code {<br/>
147:<br/>
my $content = shift;<br/>
148:<br/>
149:<br/>
if ($opts{f} eq 'h') {<br/>
150:<br/>
print &#34;&lt;pre&gt;$content-&gt;[1]&lt;/pre&gt;\n&#34;<br/>
151:<br/>
} elsif ($opts{f} eq 'p') {<br/>
152:<br/>
print &#34;$content-&gt;[1]\n&#34;;<br/>
153:<br/>
} elsif ($opts{f} eq 't') {<br/>
154:<br/>
print &#34;$content-&gt;[1]\n&#34;;<br/>
155:<br/>
}<br/>
156: }<br/>
157:<br/>
158: sub head {<br/>
159:<br/>
my $content = shift;<br/>
160:<br/>
161:<br/>
if ($opts{f} eq 'h') {<br/>
162:<br/>
print &#34;&lt;h$head&gt;&#34;, trim($content-&gt;[1]), &#34;&lt;/h$head&gt;\n&#34;<br/>
163:<br/>
} elsif ($opts{f} eq 'p') {<br/>
164:<br/>
print &#34;=head$head &#34;, trim($content-&gt;[1]), &#34;\n\n&#34;;<br/>
165:<br/>
} elsif ($opts{f} eq 't') {<br/>
166:<br/>
print trim($content-&gt;[1]), &#34;\n\n&#34;;<br/>
167:<br/>
}<br/>
168: }<br/>
169:<br/>
170: sub list {<br/>
171:<br/>
my ($attrs, $content) = @_;<br/>
172:<br/>
173:<br/>
my %list = (bullet =&gt; 'ul', numbered =&gt; 'ol');<br/>
<hr/>
<a name=222></a><b>202</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
174:<br/>
175:<br/>
my $type = $attrs-&gt;{TYPE};<br/>
176:<br/>
177:<br/>
if ($opts{f} eq 'h') {<br/>
178:<br/>
print &#34;&lt;$list{$type}&gt;\n&#34;;<br/>
179:<br/>
while (my @node = splice @$content, 0, 2) {<br/>
180:<br/>
if ($node[0] eq 'ITEM') {<br/>
181:<br/>
print &#34;&lt;li&gt;$node[1]-&gt;[2]&lt;/li&gt;\n&#34;;<br/>
182:<br/>
}<br/>
183:<br/>
}<br/>
184:<br/>
print &#34;&lt;/$list{$type}&gt;\n&#34;;<br/>
185:<br/>
} elsif ($opts{f} eq 'p') {<br/>
186:<br/>
print &#34;=over 4\n&#34;;<br/>
187:<br/>
while (my @node = splice @$content, 0, 2) {<br/>
188:<br/>
my $cnt = 1;<br/>
189:<br/>
if ($node[0] eq 'ITEM') {<br/>
190:<br/>
print &#34;=item *\n$node[1]-&gt;[2]\n\n&#34;;<br/>
191:<br/>
}<br/>
192:<br/>
}<br/>
193:<br/>
print &#34;=back\n\n&#34;;<br/>
194:<br/>
} elsif ($opts{f} eq 't') {<br/>
195:<br/>
while (my @node = splice @$content, 0, 2) {<br/>
196:<br/>
my $cnt = 1;<br/>
197:<br/>
if ($node[0] eq 'ITEM') {<br/>
198:<br/>
print $ind, &#34;* $node[1]-&gt;[2]\n&#34;;<br/>
199:<br/>
}<br/>
200:<br/>
}<br/>
201:<br/>
print &#34;\n&#34;;<br/>
202:<br/>
}<br/>
203: }<br/>
204:<br/>
205: sub author {<br/>
206:<br/>
if ($opts{f} eq 'h') {<br/>
207:<br/>
print &#34;&lt;h1&gt;AUTHOR&lt;/h1&gt;\n&#34;;<br/>
208:<br/>
} elsif ($opts{f} eq 'p') {<br/>
209:<br/>
print &#34;=head1 AUTHOR\n\n&#34;;<br/>
210:<br/>
} elsif ($opts{f} eq 't') {<br/>
211:<br/>
print &#34;AUTHOR\n\n&#34;;<br/>
212:<br/>
}<br/>
213: }<br/>
214:<br/>
215: sub aname {<br/>
216:<br/>
my $content = shift;<br/>
217:<br/>
218:<br/>
if ($opts{f} eq 'h') {<br/>
219:<br/>
print &#34;&lt;p&gt;$content-&gt;[1]\n&#34;<br/>
220:<br/>
} elsif ($opts{f} eq 'p') {<br/>
221:<br/>
print trim($content-&gt;[1]), ' ';<br/>
222:<br/>
} elsif ($opts{f} eq 't') {<br/>
223:<br/>
print $ind, trim($content-&gt;[1]), ' ';<br/>
224:<br/>
}<br/>
<hr/>
<a name=223></a><i><b>Producing different document formats</b></i><br/>
<b>203</b><br/>
225: }<br/>
226:<br/>
227: sub email {<br/>
228:<br/>
my $content = shift;<br/>
229:<br/>
230:<br/>
if ($opts{f} eq 'h') {<br/>
231:<br/>
print '&amp;lt;', trim($content-&gt;[1]), &#34;&amp;gt;&lt;/p&gt;\n&#34;<br/>
232:<br/>
} elsif ($opts{f} eq 'p') {<br/>
233:<br/>
print '&lt;', trim($content-&gt;[1]), &#34;&gt;\n\n&#34;;<br/>
234:<br/>
} elsif ($opts{f} eq 't') {<br/>
235:<br/>
print '&lt;', trim($content-&gt;[1]), &#34;&gt;\n\n&#34;;<br/>
236:<br/>
}<br/>
237: }<br/>
238:<br/>
239: sub see_also {<br/>
240:<br/>
241:<br/>
if ($opts{f} eq 'h') {<br/>
242:<br/>
print &#34;&lt;h1&gt;SEE ALSO&lt;/h1&gt;\n&#34;;<br/>
243:<br/>
} elsif ($opts{f} eq 'p') {<br/>
244:<br/>
print &#34;=head1 SEE ALSO\n\n&#34;;<br/>
245:<br/>
} elsif ($opts{f} eq 't') {<br/>
246:<br/>
print &#34;SEE ALSO\n\n&#34;;<br/>
247:<br/>
}<br/>
248: }<br/>
249:<br/>
250: sub trim {<br/>
251:<br/>
local $_ = shift;<br/>
252:<br/>
253:<br/>
s/\n/ /g;<br/>
254:<br/>
s/^\s+//;<br/>
255:<br/>
s/\s+$//;<br/>
256:<br/>
257:<br/>
$_;<br/>
258: }<br/>
This is the longest script that we have looked at so far, so let’s review it a section at<br/>a time.<br/>
Lines 1 to 3 should be the standard way that you start a Perl script.<br/>Lines 5 to 7 bring in the modules which we will be using. XML::Parser will be<br/>
used to parse the XML input, Getopt::Std is used to process command line<br/>options, and Text::Wrap is used to reformat lines of text.<br/>
Lines 9 to 11 define the types of formatting that the script can handle in a hash.<br/>
Each value is another hash containing information about the format. Currently, it<br/>only lists the name of the format, but if there are other attributes of a format that<br/>are useful, this would be a good place to store them.<br/>
<hr/>
<a name=224></a><b>204</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
Lines 13 to 19 use the function getops from Getopt::Std to process the com-<br/>
mand line flags. In this case there is just one flag that indicates the chosen output<br/>type. This is stored in $opts{f}. If we are passed an unknown format we warn the<br/>user and die. On line 19 we let the user know what format we are using.<br/>
Line 21 creates an XML parser using the Tree style and line 22 uses this object to<br/>
parse the XML document, returning the document tree data structure which we<br/>store in $tree.<br/>
Lines 24 to 26 define some global variables: $level will store the nesting level<br/>
of the current element, $ind will store a string of spaces which will be used to<br/>indent text, and $head will store the current header level.<br/>
Line 28 calls the top function which is defined in lines 67 to 81. This function<br/>
prints header information for the chosen format. For HTML, this is all of the<br/>&lt;HEAD&gt; … &lt;/HEAD&gt; section, for POD it is simply the text =pod, and for text it is the<br/>title of the document underlined. Notice that we use the expression $tree-&gt;[1]-<br/>&gt;[4]-&gt;[2] to get the title of the document. We can take this kind of shortcut<br/>because we know the structure of our document. $tree-&gt;[1] is the content of the<br/>first node in the tree (i.e., everything within the &lt;README&gt; element). $tree-&gt;[1]-<br/>&gt;[4] is the content of the second node contained within the &lt;README&gt; element.<br/>The first node within this element is the text node containing the newline character<br/>immediately after the &lt;README&gt; tag.7 The second node is the &lt;NAME&gt; element.<br/>$tree-&gt;[1]-&gt;[4]-&gt;[2] is the content of the first node within the &lt;NAME&gt; ele-<br/>ment, i.e., the name text, which we will use as a title.<br/>
Line 30 calls the process_node function which is defined in lines 34 to 65. This<br/>
function is where most of the work goes on. The basic structure should be familiar<br/>from the previous tree-based parsing scripts that we have discussed. The function is<br/>passed the type of a node together with a reference to its content. If the node is an<br/>element (remember the value of $type is the name of the element or zero if it is a<br/>text node), we extract the attributes and call the relevant subroutine to process each<br/>type of element. In most cases we pass the element content to the subroutine, but<br/>there are two exceptions. The &lt;DESCRIPTION&gt; element has no useful content<br/>(other than, of course, its contained elements, which will be handled elsewhere).<br/>The &lt;LIST&gt; element is more complex. First, it is the only element with an attribute<br/>list which needs to be passed on to the subroutine and, second, as the list subrou-<br/>tine processes all of the element’s content, we need to set the content to an empty<br/>list to prevent it being processed again.<br/>
7 Of course, the script now relies on this newline character always being there. Relying on the presence of<br/>
this ignorable white space is a serious limitation of this script, and if you wanted to use a script like this in<br/>earnest you would need to design something a little more robust.<br/>
<hr/>
<a name=225></a><i><b>Producing different document formats</b></i><br/>
<b>205</b><br/>
Having processed the element, we need to process any child elements. This is<br/>
accomplished in much the same way as we have in previous examples. We simply<br/>walk the @$content list a node at a time (where a node is represented by two items<br/>in the array), passing the nodes one at a time to process_node. We pause only to<br/>increment the $level and $head variables before starting to process the list and to<br/>decrement them after we have finished.<br/>
Once the script returns from the main call to process_node, the final action<br/>
(line 32) is to call the function bot. The function is defined in lines 83 to 91 and<br/>simply finishes off the file in that same way that top started it (except that in this<br/>case the processing is much simpler).<br/>
The rest of the script consists of definitions of the functions which handle the<br/>
various element types. Most of these are very similar and simple. All they do is print<br/>out the content of the element surrounded by various fixed strings. It is, however,<br/>worth taking a closer look at the head and list functions.<br/>
head is the function which prints out header sections. In its POD and HTML sec-<br/>
tions it needs to know which level of header to display. It accomplishes this by using the<br/>global $head variable which is incremented each time a &lt;SUBSECTION&gt; element is<br/>encountered. Like many of the other element functions, head also makes use of a helper<br/>function called trim which removes all of the excess white space from a text string.<br/>
list is the most complex of the element functions as it builds up a complete list<br/>
rather than relying on the usual subelement handling which we have used for other<br/>elements. This is because in the future we may well want to support numbered lists,<br/>and it will be far easier if the list numbers can all be calculated within the same func-<br/>tion. This function therefore traverses the @$content array in much the same way<br/>as the process_node function.<br/>
<i><b>10.5.3 Using the XML document transformation script</b></i><br/>
Having described the script in detail, let’s run it in the various modes on our sample<br/>document and see what output we get. The script takes the input file as an argu-<br/>ment and writes its output to STDOUT. We can, therefore, call the script like this:<br/>
format_xml.pl -f p doc.xml &gt; doc.pod<br/>
format_xml.pl -f h doc.xml &gt; doc.html<br/>
format_xml.pl -f t doc.xml &gt; doc.txt<br/>
to get the POD, HTML, and text outputs. Here are the results.<br/>
<i><b>POD file</b></i><br/>
<b>=pod</b><br/>
<b>=head1 NAME</b><br/>
<hr/>
<a name=226></a><b>206</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
<b>Test README File</b><br/>
<b>=head1 SYNOPSIS</b><br/>
<b>This is a summary of the file.</b><br/>
<b>It should appear in PRE tags</b><br/>
<b>=head1 DESCRIPTION</b><br/>
<b>This is the full description of the file</b><br/>
<b>=head2 Subsection Title</b><br/>
<b>Subsection text</b><br/>
<b>=head2 Another Subsection Title</b><br/>
<b>More Subsection text</b><br/>
<b>=over 4</b><br/>
=item *<br/>
<b>List item 1</b><br/>
=item *<br/>
<b>List item 2</b><br/>
=back<br/>
<b>=head1 AUTHOR</b><br/>
<b>Dave Cross &lt;dave@mag-sol.com&gt;</b><br/>
<b>=head1 SEE_ALSO</b><br/>
<b>=over 4</b><br/>
=item *<br/>
<b>Something</b><br/>
=item *<br/>
<b>Something else</b><br/>
=back<br/>
<b>=cut</b><br/>
<i><b>HTML file</b></i><br/>
<b>&lt;html&gt;</b><br/>
<b>&lt;head&gt;</b><br/>
<b>&lt;title&gt;Test README File&lt;/title&gt;</b><br/>
<b>&lt;/head&gt;</b><br/>
<b>&lt;body&gt;</b><br/>
<b>&lt;h1&gt;NAME&lt;/h1&gt;</b><br/>
<b>&lt;p&gt;Test README File&lt;/p&gt;</b><br/>
<b>&lt;h1&gt;SYNOPSIS&lt;/h1&gt;</b><br/>
<b>&lt;pre&gt;</b><br/>
<hr/>
<a name=227></a><i><b>Producing different document formats</b></i><br/>
<b>207</b><br/>
<b>This is a summary of the file.</b><br/>
<b>It should appear in PRE tags</b><br/>
<b>&lt;/pre&gt;</b><br/>
<b>&lt;h1&gt;DESCRIPTION&lt;/h1&gt;</b><br/>
<b>&lt;p&gt;This is the full description of the file&lt;/p&gt;</b><br/>
<b>&lt;h2&gt;Subsection Title&lt;/h2&gt;</b><br/>
<b>&lt;p&gt;Subsection text&lt;/p&gt;</b><br/>
<b>&lt;h2&gt;Another Subsection Title&lt;/h2&gt;</b><br/>
<b>&lt;p&gt;More Subsection text&lt;/p&gt;</b><br/>
<b>&lt;ul&gt;</b><br/>
<b>&lt;li&gt;List item 1&lt;/li&gt;</b><br/>
<b>&lt;li&gt;List item 2&lt;/li&gt;</b><br/>
<b>&lt;/ul&gt;</b><br/>
<b>&lt;h1&gt;AUTHOR&lt;/h1&gt;</b><br/>
<b>&lt;p&gt;Dave Cross</b><br/>
<b>&amp;lt;dave@mag-sol.com&amp;gt;&lt;/p&gt;</b><br/>
<b>&lt;h1&gt;SEE_ALSO&lt;/h1&gt;</b><br/>
<b>&lt;ul&gt;</b><br/>
<b>&lt;li&gt;Something&lt;/li&gt;</b><br/>
<b>&lt;li&gt;Something else&lt;/li&gt;</b><br/>
<b>&lt;/ul&gt;</b><br/>
<b>&lt;/body&gt;</b><br/>
<b>&lt;/html&gt;</b><br/>
<i><b>Text file</b></i><br/>
<b>Test README File</b><br/>
<b>----------------</b><br/>
<b>NAME</b><br/>
<b>Test README File</b><br/>
<b>SYNOPSIS</b><br/>
<b>This is a summary of the file.</b><br/>
<b>It should appear in PRE tags</b><br/>
<b>DESCRIPTION</b><br/>
<b>This is the full description of the file</b><br/>
<b>Subsection Title</b><br/>
<b>Subsection text</b><br/>
<b>Another Subsection Title</b><br/>
<b>More Subsection text</b><br/>
<b>* List item 1</b><br/>
<b>* List item 2</b><br/>
<b>AUTHOR</b><br/>
<hr/>
<a name=228></a><b>208</b><br/>
CHAPTER <br/>
<i><b>XML</b></i><br/>
<b>Dave Cross &lt;dave@mag-sol.com&gt;</b><br/>
<b>SEE_ALSO</b><br/>
<b>* Something</b><br/>
<b>* Something else</b><br/>
<i><b>10.6 Further information</b></i><br/>
The XML and Perl world is a very exciting place at the moment. Things are chang-<br/>ing all the time. The best way to keep abreast of the latest news is to read the Perl-<br/>XML mailing list. You can subscribe via the web interface at:<br/>
http://listserv.ActiveState.com/mailman/listinfo/perl-xml.<br/>
None of the modules that we have discussed in this chapter are installed as part<br/>
of the standard Perl installation. You will need to get them from the CPAN and<br/>install them yourself.<br/>
<i><b>10.7 Summary</b></i><br/>
■<br/>
XML is becoming a very common data format, particularly for exchanging<br/>data between different computer systems.<br/>
■<br/>
XML documents can be either valid or well-formed. Currently, no Perl XML<br/>parser checks for validity.<br/>
■<br/>
XML parsing in Perl is very easy using XML::Parser and its various subclasses.<br/>
■<br/>
XML::Parser has a number of different styles which can be used to solve par-<br/>ticular types of parsing tasks. If none of the standard styles suit your require-<br/>ments, you can use handlers for even more control over how the parser works.<br/>
■<br/>
XML::DOM brings the industry-standard Document Object Model to the<br/>Perl/XML community.<br/>
■<br/>
Specialized parsers such as XML::RSS can be used to parse documents con-<br/>forming to specific DTDs.<br/>
<hr/>
<a name=229></a><img class="yflip" src="dmp-229_1.jpg"/><br/>
<i>11</i><br/>
<i>Building your</i><br/>
<i>own parsers</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Creating your own parser<br/>
■<br/>
Returning parsed data<br/>
■<br/>
Matching grammar rules<br/>
■<br/>
Building a data structure to return<br/>
■<br/>
Parsing complex file formats into complex <br/>data structures <br/>
<i>209</i><br/>
<hr/>
<a name=230></a><b>210</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
The prebuilt parsers that we have looked at in the two previous chapters are, of<br/>course, very useful, but there are many times when you need to parse data in a<br/>format for which a prebuilt parser does not exist. In these cases you can create<br/>your own parser using a number of Perl modules. The most flexible of these is<br/>Parse::RecDescent, and in this chapter we take a detailed look at its use. <br/>
<i><b>11.1 Introduction to Parse::RecDescent</b></i><br/>
Parse::RecDescent is a tool for building top-down parsers which was written by<br/>Damian Conway. It doesn’t form a part of the standard Perl distribution, so you will<br/>need to get it from the CPAN. It can be found at http://www.cpan.org/modules/<br/>by-module/Parse/. The module comes with copious documentation and more<br/>example code than anyone would ever want to read. <br/>
Using Parse::RecDescent is quite simple. In summary you define a grammar<br/>
for the parser to use, create a parser object to process the grammar, and then pass<br/>the text to be parsed to the parser. We’ll see more specific examples later, but all the<br/>programs will have a basic structure which looks like this:<br/>
use Parse::RecDescent;<br/>
my $grammar = q(<br/>
# Text that define your grammar<br/>
);<br/>
my $parser = Parse::RecDescent-&gt;new($grammar);<br/>
my $text = q(<br/>
# Scalar which contains the text to be parsed<br/>
);<br/>
# top_rule is the name of the top level rule in you grammar.<br/>
$parser-&gt;top_rule($text);<br/>
<i><b>11.1.1 Example: parsing simple English sentences</b></i><br/>
For example, if we go back to the example of simple English sentences which we<br/>used in chapter 8, we could write code like this in order to check for valid sentences.<br/>
use Parse::RecDescent;<br/>
my $grammar = q(<br/>
sentence: subject verb object<br/>
subject: noun_phrase<br/>
object: noun_phrase<br/>
verb: 'wrote' | 'likes' | 'ate'<br/>
noun_phrase: pronoun | proper_noun | article noun<br/>
article: 'a' | 'the' | 'this'<br/>
pronoun: 'it' | 'he'<br/>
proper_noun: 'Perl' | 'Dave' | 'Larry'<br/>
<hr/>
<a name=231></a><i><b>Introduction to Parse::RecDescent</b></i><br/>
<b>211</b><br/>
noun: 'book' | 'cat'<br/>
);<br/>
my $parser = Parse::RecDescent-&gt;new($grammar);<br/>
while (&lt;DATA&gt;) {<br/>
chomp;<br/>
print &#34;'$_' is &#34;;<br/>
print 'NOT ' unless $parser-&gt;sentence($_);<br/>
print &#34;a valid sentence\n&#34;;<br/>
}<br/>
__END__<br/>
Larry wrote Perl<br/>
Larry wrote a book<br/>
Dave likes Perl<br/>
Dave likes the book<br/>
Dave wrote this book<br/>
the cat ate the book<br/>
Dave got very angry<br/>
Notice that we have expanded the terminals to actually represent a (very limited)<br/>subset of English words. The output of this script is a follows:<br/>
<b>'Larry wrote Perl' is a valid sentence</b><br/>
<b>'Larry wrote a book' is a valid sentence</b><br/>
<b>'Dave likes Perl' is a valid sentence</b><br/>
<b>'Dave likes the book' is a valid sentence</b><br/>
<b>'Dave wrote this book' is a valid sentence</b><br/>
<b>'the cat ate the book' is a valid sentence</b><br/>
<b>'Dave got very angry' is NOT a valid sentence</b><br/>
Which shows that “Dave got very angry” is the only text in our data, which is not a<br/>valid sentence.1<br/>
<i><b>Explaining the code<br/></b></i>The only complex part of this script is the definition of the grammar. The syntax of<br/>this definition is similar to one that we used in chapter 8. The only major difference<br/>is that we have replaced the arrow -&gt; with a colon. If you read the rules, replacing<br/>the colon with the phrase “is made up of” and the vertical bar with the word “or”,<br/>then these rules are easy to understand.<br/>
In this example all of our terminals are fixed strings. As we shall see later in the<br/>
chapter, it is quite possible to match Perl regular expressions instead.<br/>
Having defined our grammar, we simply create a parser object using this gram-<br/>
mar and use that object to see if our sentences are valid. Notice that we use the<br/>
1 By the rules of our grammar of course—not by the real rules of English.<br/>
<hr/>
<a name=232></a><b>212</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
method sentence to validate each sentence in turn. This method was created by<br/>the Parse::RecDescent object as it read our grammar. The sentence method<br/>returns true or false depending on whether or not the parser object successfully<br/>parsed the input data.<br/>
<i><b>11.2 Returning parsed data</b></i><br/>
The previous example is all very well if you just want to know whether your data<br/>meets the criteria of a given grammar, but it doesn’t actually produce any useful<br/>data structures which represent the parsed data. For that we have to look a little<br/>deeper into Parse::RecDescent.<br/>
<i><b>11.2.1 Example: parsing a Windows INI file</b></i><br/>
Let’s look at parsing a Windows INI file.<br/>
<b>Section name</b><br/>
[files]<br/>
These files contain a number of named<br/>
input=data_in<br/>
<b>Key</b><br/>
<b>Value</b><br/>
sections. Each of these sections contain a<br/>
output = data_out<br/>
number of assignment statements. Fig-<br/>
ext=dat<br/>
ure 11.1 shows an example INI together<br/>
[rules]<br/>
with the various parts that make up the<br/>
<b>Section</b><br/>
quotes=double<br/>
file structure.<br/>
sep=comma<br/>spaces=trim<br/>
In this example we have sections called<br/>
“files” and “rules.” The files section lists<br/>
<b>Figure 11.1</b><br/>
<b>INI file structure.</b><br/>
the names of the input and output files<br/>together with their extension; the rules<br/>
section lists a number of configuration options. This file might be used to control the<br/>configuration of a text-processing program.<br/>
quotes double<br/>
Before looking at how we would get the data<br/>
sep<br/>
comma<br/>
out, it is a good idea to decide what data struc-<br/>
spaces trim<br/>
rules<br/>
hashref<br/>
ture we are going to use to store the parsed<br/>
files<br/>
hahgref<br/>
input<br/>
data_in<br/>
data. In this case it seems fairly obvious that a<br/>
ext<br/>
ext<br/>
hash of hashes would be most useful. Each key<br/>
output data_out<br/>
within the first hash would be a section name<br/>and the value would be a reference to another<br/>
<b>Figure 11.2</b><br/>
<b>INI file data structure.</b><br/>
hash. Within these second-level hashes the keys<br/>
would be the left-hand side of the assignment statement and the values would be the<br/>right-hand side. Figure 11.2 shows this data structure.<br/>
This means that you can get an individual value very easily using code like:<br/>
$input_file = $Config{files}{input};<br/>
<hr/>
<a name=233></a><i><b>Returning parsed data</b></i><br/>
<b>213</b><br/>
<i><b>11.2.2 Understanding the INI file grammar</b></i><br/>
Let’s take a look at a grammar that defines an INI file. We’ll use the syntax found<br/>in Parse::RecDescent.<br/>
file: section(s)<br/>
section: header assign(s)<br/>
header: '[' /\w+/ ']'<br/>
assign: /\w+/ '=' /\w+/<br/>
The grammar can be explained in English like this:<br/>
■<br/>
An INI file consists of one or more sections.<br/>
■<br/>
Each section consists of a header followed by one or more assignments.<br/>
■<br/>
The header consists of a [ character, one or more word characters, and a ]<br/>character.<br/>
■<br/>
An assignment consists of a sequence of one or more word characters, an =<br/>character, and another sequence of one or more word characters.<br/>
<i><b>Using subrule suffixes<br/></b></i>There are a couple of new features to notice here. First, we have used (s) after the<br/>names of some of our subrules. This means that the subrule can appear one or more<br/>times in the rule. There are a number of other suffixes which can control the num-<br/>ber of times that a subrule can appear, and the full list is in table 11.1. In this case<br/>we are saying that a file can contain one or more sections and that each section can<br/>contain one or more assignment statements.<br/>
Table 11.1<br/>
Optional and repeating subrules<br/>
Subrule<br/>
Meaning<br/>
suffix<br/>
(?)<br/>
Optional subrule. Appears zero or one time.<br/>
(s)<br/>
Mandatory repeating subrule. Appears one or more times.<br/>
(s?)<br/>
Optional repeating subrule. Appears zero or more times.<br/>
(N)<br/>
Repeating subgroup. Must appear exactly <i>N</i> times.<br/>
(N..M)<br/>
Repeating subgroup. Must appear between <i>N</i> and <i>M</i> times.<br/>
(..M)<br/>
Repeating subgroup. Must appear between 1 and <i>M</i> times.<br/>
(N..)<br/>
Repeating subgroup. Must appear at least <i>N</i> times.<br/>
<hr/>
<a name=234></a><b>214</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
<i><b>Using regular expressions<br/></b></i>The other thing to notice is that we are using regular expressions in many places to<br/>match our terminals. This is useful because the names of the sections and the keys<br/>and values in each section can be any valid word. In this example we are saying that<br/>they must all be a string made up of Perl’s word characters.2<br/>
<i><b>11.2.3 Parser actions and the @item array</b></i><br/>
0<br/>
header<br/>
In order to extract data, we can make use of parser actions. These are<br/>
1<br/>
[<br/>
pieces of code that you write and then attach to any rule in a gram-<br/>
2<br/>
files<br/>
mar. Your code is then executed whenever that rule is matched.<br/>
3<br/>
]<br/>
Within the action code a number of special variables are available.<br/>
<b>Figure 11.3</b><br/>
The most useful of these is probably the @item array which contains<br/>
<b>The @item array </b><br/>
a list of the values that have been matched in the current rule. The<br/>
<b>after matching </b><br/>
value in $item[0] is always the name of the rule which has matched.<br/>
<b>the header rule </b><br/>
For example, when our header rule is matched, the @item array will<br/>
<b>for the first time</b><br/>
contain “header”, “[”, the name of the section, and “]” with ele-<br/>ments 0 to 33 (figure 11.3).<br/>
In order to see what values are being matched, you could put action code on<br/>
each of the rules in the grammar like the following code. All this code does is print<br/>out the contents of the @item array each time a rule is matched.<br/>
file: section(s) { print &#34;$item[0]: $item[1]\n&#34;; }<br/>
section: header assign(s) { print &#34;$item[0]: $item[1] $item[2]\n&#34;; }<br/>
header: '[' /\w+/ ']' { print &#34;$item[0]: $item[1] $item[2] $item[3]\n&#34;; }<br/>
assign: /\w+/ '=' /\w+/<br/>
{ print &#34;$item[0]: $item[1] $item[2] $item[3]\n&#34;; }<br/>
However, Parse::RecDescent provides an easier way to achieve the same result,<br/>by providing a way to assign a default action to all rules in a grammar. If you assign<br/>a string containing code to the variable $::RD_AUTOACTION, then that code will be<br/>assigned to every rule which doesn’t have an explicit action. <br/>
<i><b>11.2.4 Example: displaying the contents of @item</b></i><br/>
Here is a sample program which reads an INI file and displays the contents of @item<br/>for each matched rule.<br/>
use Parse::RecDescent;<br/>
my $grammar = q(<br/>
2 That is, alphanumeric characters and the underbar character.<br/>3 The same information is also available in a hash called %item, but I’ll use @item in these examples. For<br/>
more details on %item see perldoc Parse::RecDescent.<br/>
<hr/>
<a name=235></a><i><b>Returning parsed data</b></i><br/>
<b>215</b><br/>
file: section(s)<br/>
section: header assign(s)<br/>
header: '[' /\w+/ ']'<br/>
assign: /\w+/ '=' /\w+/<br/>
);<br/>
$::RD_AUTOACTION = q { print &#34;$item[0]: @item[1..$#item]\n&#34;; 1 } ;<br/>
$parser = Parse::RecDescent-&gt;new($grammar);<br/>
my $text;<br/>
{<br/>
$/ = undef;<br/>
$text = &lt;STDIN&gt;;<br/>
}<br/>
$parser-&gt;file($text);<br/>
The general structure of the code and the grammar should be familiar. The only<br/>thing new here is the code assigned to $::RD_AUTOACTION. This code will be run<br/>whenever a rule that doesn’t have its own associated action code is matched. When<br/>you run this program using our earlier sample INI file as input, the resulting output<br/>is as follows:<br/>
<b>header: [ files ]</b><br/>
<b>assign: input = data_in</b><br/>
<b>assign: output = data_out</b><br/>
<b>assign: ext = dat</b><br/>
<b>section: 1 ARRAY(0x8adc868)</b><br/>
<b>header: [ rules ]</b><br/>
<b>assign: quotes = double</b><br/>
<b>assign: sep = comma</b><br/>
<b>assign: spaces = trim</b><br/>
<b>section: 1 ARRAY(0x8adc844)</b><br/>
<b>file: ARRAY(0x8adc850)</b><br/>
<i><b>How rule matching works<br/></b></i>The previous example shows us a couple of interesting things about the way that<br/>Parse::RecDescent works. Look at the order in which the rules have been<br/>matched and recall what we saw about the workings of top-down parsers in<br/>chapter 8. Here you can clearly see that a rule doesn’t match until all of its subrules<br/>have been matched successfully.<br/>
Secondly, look at the output for the section and file rules. Where you have<br/>
matched a repeating subrule, @item contains a reference to an array, and where you<br/>have matched a nonrepeating subrule, @item contains the value 1. This shows us<br/>something about what a matched rule returns. Each matched rule returns a true<br/>value. By default this is the number 1, but you can change this in the associated<br/>
<hr/>
<a name=236></a><b>216</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
action code. Be sure that your code has a true return value, or else the parser will<br/>think that the match has failed.<br/>
<i><b>11.2.5 Returning a data structure</b></i><br/>
The value that is returned from the top-level rule will be the value returned by the<br/>top-level rule method when called by our script. We can use this fact to ensure that<br/>the data structure that we want is returned. Here is the script that will achieve this:<br/>
use Parse::RecDescent;<br/>
my $grammar = q(<br/>
file: section(s)<br/>
{ my %file;<br/>
foreach (@{$item[1]}) {<br/>
$file{$_-&gt;[0]} = $_-&gt;[1];<br/>
}<br/>
\%file;<br/>
}<br/>
section: header assign(s)<br/>
{ my %sec;<br/>
foreach (@{$item[2]}) {<br/>
$sec{$_-&gt;[0]} = $_-&gt;[1];<br/>
}<br/>
[ $item[1], \%sec]<br/>
}<br/>
header: '[' /\w+/ ']' { $item[2] }<br/>
assign: /\w+/ '=' /\w+/<br/>
{ [$item[1], $item[3]] }<br/>
);<br/>
$parser = Parse::RecDescent-&gt;new($grammar);<br/>
my $text;<br/>
{<br/>
$/ = undef;<br/>
$text = &lt;STDIN&gt;;<br/>
}<br/>
my $tree = $parser-&gt;file($text);<br/>
foreach (keys %$tree) {<br/>
print &#34;$_\n&#34;;<br/>
foreach my $key (keys %{$tree-&gt;{$_}}) {<br/>
print &#34;\t$key: $tree-&gt;{$_}{$key}\n&#34;;<br/>
}<br/>
}<br/>
<hr/>
<a name=237></a><i><b>Another example: the CD data file</b></i><br/>
<b>217</b><br/>
The code that has been added to the previous script is in two places. First (and most<br/>importantly) in the parser actions and, secondly, at the end of the script to display<br/>the returned data structure and demonstrate what is returned.<br/>
The action code might look a little difficult, but it’s probably a bit easier if you<br/>
read it in reverse order and see how the data structure builds up.<br/>
The assign rule now returns a reference to a two-element list. The first element<br/>
is the left-hand side of the assignment and the second element is the right-hand<br/>side. The header rule simply returns the name of the section.<br/>
The section rule creates a new hash called %sec. It then iterates across the list<br/>
returned by the assign subrule. Each element in this list is the return value from<br/>one assign rule. As we saw in the previous paragraph, this is a reference to a two-<br/>element list. We convert each of these lists to a key/value pair in the %sec hash.<br/>Finally, the rule returns a reference to a two-element hash. The first element of this<br/>list is the return value from the header rule (which is the section name), and the<br/>second element is a reference to the section hash.<br/>
The file rule uses a very similar technique to take the list of sections and convert<br/>
them into a hash called %file. It then returns the %file hash.<br/>
This means that the file method returns a reference to a hash. The keys to the<br/>
hash are the names of the sections in the file and the values are references to<br/>hashes. The keys to the second level hashes are the text from the left-hand side of<br/>the assignments, and the values are the associated strings from the right-hand side<br/>of the assignment.<br/>
The code at the end of the script prints out the values in the returned data struc-<br/>
ture. Running this script against our sample INI file gives us the following result:<br/>
<b>rules</b><br/>
<b>quotes: double</b><br/>
<b>sep: comma</b><br/>
<b>spaces: trim</b><br/>
<b>files</b><br/>
<b>input: data_in</b><br/>
<b>ext: dat</b><br/>
<b>output: data_out</b><br/>
which demonstrates that we have built up the data structure that we wanted.<br/>
<i><b>11.3 Another example: the CD data file</b></i><br/>
Let’s take a look at another example of parsing a data file with Parse::RecDescent.<br/>We’ll take a look at how we’d parse the CD data file that we discussed in chapter 8.<br/>What follows is the data file we were discussing:<br/>
<hr/>
<a name=238></a><b>218</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
Dave's CD Collection<br/>
16 Sep 1999<br/>
Artist<br/>
Title<br/>
Label<br/>
Released<br/>
--------------------------------------------------------<br/>
Bragg, Billy<br/>
Workers' Playtime<br/>
Cooking Vinyl<br/>
1988<br/>
+She's Got A New Spell<br/>
+Must I Paint You A Picture<br/>
Bragg, Billy<br/>
Mermaid Avenue<br/>
EMI<br/>
1998<br/>
+Walt Whitman's Niece<br/>
+California Stars<br/>
Black, Mary<br/>
The Holy Ground<br/>
Grapevine<br/>
1993<br/>
+Summer Sent You<br/>
+Flesh And Blood<br/>
Black, Mary<br/>
Circus<br/>
Grapevine<br/>
1995<br/>
+The Circus<br/>
+In A Dream<br/>
Bowie, David<br/>
Hunky Dory<br/>
RCA<br/>
1971<br/>
+Changes<br/>
+Oh You Pretty Things<br/>
Bowie, David<br/>
Earthling<br/>
EMI<br/>
1997<br/>
+Little Wonder<br/>
+Looking For Satellites<br/>
6 Records<br/>
In chapter 8 we came up with a rather unsatisfying way to extract the data from this<br/>file and put it into a data structure. Now that Parse::RecDescent is in our tool-<br/>kit, we should be able to come up with something far more elegant.<br/>
As with the last example, the best approach is to start with a grammar for the<br/>
data file.<br/>
<i><b>11.3.1  Understanding the CD grammar</b></i><br/>
Here is the grammar that I have designed for parsing the CD data file.<br/>
file: header body footer<br/>
header: /.+/ date<br/>
date: /\d\d?\s+\w+\s+\d{4}/<br/>
body: col_heads /-+/ cd(s)<br/>
col_heads: col_head(s)<br/>
col_head: /\w+/<br/>
cd: cd_line track_line(s)<br/>
cd_line: /.{14}/ /.{19}/ /.{15}/ /\d{4}/<br/>
track_line: '+' /.*/<br/>
footer: /\d+/ 'CDs'<br/>
Let’s take a closer look at the individual rules. Like the parser, we’ll take a top-<br/>down approach.<br/>
■<br/>
A data file is made up of three sections—a header, a body, and a footer.<br/>
■<br/>
The file header is made up of a string of any characters followed by a date.<br/>
<hr/>
<a name=239></a><i><b>Another example: the CD data file</b></i><br/>
<b>219</b><br/>
■<br/>
A date is one or two digits followed by at least one space, any number of<br/>word characters, at least one space and four digits. Note that we are assuming<br/>that all dates will appear in the same format as the one in our sample file.<br/>
■<br/>
The file body contains the column headers followed by a number of - charac-<br/>ters and one or more CD records.<br/>
■<br/>
The column headers are made up of one or more headers per individual column.<br/>
■<br/>
A column header consists of a number of word characters.<br/>
■<br/>
A CD record consists of a CD line followed by at least one track record.<br/>
■<br/>
A CD line consists of a number of records, each of which is a particular num-<br/>ber of characters long. We have to match in this way, as the CD record is in<br/>fixed width format.<br/>
■<br/>
A track record contains a + character followed by at least one other character.<br/>
■<br/>
A footer record consists of at least one digit followed by the text “CDs”.<br/>
<i><b>11.3.2 Testing the CD file grammar</b></i><br/>
Having defined our grammar, one of the best ways to test it is to write a brief pro-<br/>gram like the one that we used to test the English sentences. The program would<br/>look like this:<br/>
use Parse::RecDescent;<br/>
use vars qw(%datas @cols);<br/>
my $grammar = q(<br/>
file: header body footer<br/>
header: /.+/ date<br/>
date: /\d+\s+\w+\s+\d{4}/<br/>
body: col_heads /-+/ cd(s)<br/>
col_heads: col_head(s)<br/>
col_head: /\w+/<br/>
cd: cd_line track_line(s)<br/>
cd_line: /.{14}/ /.{19}/ /.{15}/ /\d{4}/<br/>
track_line: '+' /.+/ { $item[2] }<br/>
footer: /\d+/ 'CDs'<br/>
);<br/>
$parser = Parse::RecDescent-&gt;new($grammar);<br/>
my $text;<br/>
{<br/>
local $/ = undef;<br/>
$text = &lt;STDIN&gt;;<br/>
}<br/>
print $parser-&gt;file($text) ? &#34;valid&#34; : &#34;invalid&#34;;<br/>
<hr/>
<a name=240></a><b>220</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
This program will print valid or invalid depending on whether or not the file<br/>passed to it on STDIN parses correctly against the given grammar. In this case it<br/>does, but if it doesn’t and you want to find out where the errors are, there are two<br/>useful variables which Parse::RecDescent uses to help you follow what it is doing. <br/>
<i><b>Debugging the grammar with $::RD_TRACE and $::RD_HINT<br/></b></i>Setting $::RD_TRACE to true will display a trace of the parsing process as it<br/>progresses, allowing you to see where your grammar and the structure of the file<br/>disagree. If the problems are earlier in the process and there are syntax errors in<br/>your grammar, then setting $::RD_HINT to true will provide hints on how you<br/>could fix the problems. Setting $::RD_AUTOACTION to a snippet of code which<br/>prints out the values in @item can also be a useful debugging tool.<br/>
<i><b>11.3.3 Adding parser actions</b></i><br/>
Having established that our grammar does what we want, we can proceed with<br/>writing the rest of the program. As previously, most of the interesting code is in the<br/>parser actions. Here is the complete program:<br/>
use strict;<br/>
use Parse::RecDescent;<br/>
use Data::Dumper;<br/>
use vars qw(@cols);<br/>
my $grammar = q(<br/>
file: header body footer<br/>
{<br/>
my %rec =<br/>
(%{$item[1]}, list =&gt; $item[2], %{$item[3]});<br/>
\%rec;<br/>
}<br/>
header: /.+/ date<br/>
{ { title =&gt; $item[1], date =&gt; $item[2] } }<br/>
date: /\d+\s+\w+\s+\d{4}/ { $item[1] }<br/>
body: col_heads /-+/ cd(s) { $item[3] }<br/>
col_heads: col_head(s) { @::cols = @{$item[1]} }<br/>
col_head: /\w+/ { $item[1] }<br/>
cd: cd_line track_line(s)<br/>
{ $item[1]-&gt;{tracks} = $item[2]; $item[1] }<br/>
cd_line: /.{14}/ /.{19}/ /.{15}/ /\d{4}/<br/>
{ my %rec; @rec{@::cols} = @item[1 .. $#item]; \%rec }<br/>
track_line: '+' /.+/ { $item[2] }<br/>
footer: /\d+/ 'CDs'<br/>
{ { count =&gt; $item[1] } }<br/>
);<br/>
my $parser = Parse::RecDescent-&gt;new($grammar);<br/>
<hr/>
<a name=241></a><i><b>Another example: the CD data file</b></i><br/>
<b>221</b><br/>
my $text;<br/>
{<br/>
local $/ = undef;<br/>
$text = &lt;DATA&gt;;<br/>
}<br/>
my $CDs = $parser-&gt;file($text);<br/>
print Dumper($CDs);<br/>
As is generally the case, the parser actions will be easier to follow if we examine<br/>them bottom up.<br/>
The footer rule returns a reference to a hash with only one value. The key to<br/>
this hash is count and the value is $item[1], which is the number that is matched<br/>on the footer line. As we’ll see when we get to the file rule, I chose to return this<br/>as a hash reference since it makes it easier to combine parts into a data structure.<br/>
The track rule returns the name of the track.<br/>The cd_line rule builds a hash where the keys are the column headings and the<br/>
values are the associated values from the CD line in the file. In order to do this, it<br/>makes use of the global @cols array which is created by the col_heads rule.<br/>
The cd rule takes the hash reference which is returned by the cd_line rule and<br/>
creates another element in the same hash where the key is tracks, and the value is<br/>a reference to the array of multiple track records which is returned by the track(s)<br/>subrule. The rule then returns this hash reference.<br/>
The col_head rule matches one individual column heading and returns that value.<br/>The col_heads rule takes the array which is returned by the col_head(s) sub-<br/>
rule and assigns this array to the global array @cols, so that it can later be used by<br/>the cd_line rule.<br/>
The body rule returns the array returned by the cd(s) subrule. Each element of<br/>
this array is the hash returned by one occurrence of the cd rule.<br/>
The date rule returns the date that was matched.<br/>The header rule works similarly to the footer rule. It returns a reference to a<br/>
two-element hash. The keys in this hash are “title” and “date” and the values are<br/>the respective pieces of matched text.<br/>
The file rule takes the three pieces of data returned by the header, body, and<br/>
footer rules and combines them into a single hash. It then returns a reference to<br/>this hash.<br/>
<hr/>
<a name=242></a><b>222</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
<i><b>Checking the output with Data::Dumper<br/></b></i>The program uses the Data::Dumper module to print out a data dump of the data<br/>structure that we have built. For our sample CD data file, the output from this pro-<br/>gram look like this:<br/>
$VAR1 = {<br/>
'list' =&gt; [<br/>
{<br/>
'Released' =&gt; '1988',<br/>
'Artist' =&gt; 'Bragg, Billy<br/>
',<br/>
'Title' =&gt; 'Workers\' Playtime<br/>
',<br/>
'Label' =&gt; 'Cooking Vinyl<br/>
',<br/>
'tracks' =&gt; [<br/>
'She\'s Got A New Spell',<br/>
'Must I Paint You A Picture'<br/>
]<br/>
},<br/>
{<br/>
'Released' =&gt; '1998',<br/>
'Artist' =&gt; 'Bragg, Billy<br/>
',<br/>
'Title' =&gt; 'Mermaid Avenue<br/>
',<br/>
'Label' =&gt; 'EMI<br/>
',<br/>
'tracks' =&gt; [<br/>
'Walt Whitman\'s Niece',<br/>
'California Stars'<br/>
]<br/>
},<br/>
{<br/>
'Released' =&gt; '1993',<br/>
'Artist' =&gt; 'Black, Mary<br/>
',<br/>
'Title' =&gt; 'The Holy Ground<br/>
',<br/>
'Label' =&gt; 'Grapevine<br/>
',<br/>
'tracks' =&gt; [<br/>
'Summer Sent You',<br/>
'Flesh And Blood'<br/>
]<br/>
},<br/>
{<br/>
'Released' =&gt; '1995',<br/>
'Artist' =&gt; 'Black, Mary<br/>
',<br/>
'Title' =&gt; 'Circus<br/>
',<br/>
'Label' =&gt; 'Grapevine<br/>
',<br/>
'tracks' =&gt; [<br/>
'The Circus',<br/>
'In A Dream'<br/>
]<br/>
},<br/>
{<br/>
'Released' =&gt; '1971',<br/>
'Artist' =&gt; 'Bowie, David<br/>
',<br/>
<hr/>
<a name=243></a><i><b>Other features of Parse::RecDescent</b></i><br/>
<b>223</b><br/>
'Title' =&gt; 'Hunky Dory<br/>
',<br/>
'Label' =&gt; 'RCA<br/>
',<br/>
'tracks' =&gt; [<br/>
'Changes',<br/>
'Oh You Pretty Things'<br/>
]<br/>
},<br/>
{<br/>
'Released' =&gt; '1997',<br/>
'Artist' =&gt; 'Bowie, David<br/>
',<br/>
'Title' =&gt; 'Earthling<br/>
',<br/>
'Label' =&gt; 'EMI<br/>
',<br/>
'tracks' =&gt; [<br/>
'Little Wonder',<br/>
'Looking For Satellites'<br/>
]<br/>
}<br/>
],<br/>
'title' =&gt; 'Dave\'s CD Collection',<br/>
'count' =&gt; '6',<br/>
'date' =&gt; '16 Sep 1999'<br/>
};<br/>
You can see that this structure is the same as the one that we built in chapter 8. The<br/>main part of the structure is a hash, the keys of which are “list,” “title,” “count,”<br/>and “date.” Of these, all but “list” is associated with a scalar containing data from<br/>the header or the footer of the file. The key “list” is associated with a reference to<br/>an array. Each element of that array contains the details of one CD in a hash. This<br/>includes a reference to a further list that contains the tracks from each CD.<br/>
<i><b>11.4 Other features of Parse::RecDescent</b></i><br/>
That completes our detailed look at using Parse::RecDescent. It should give<br/>you enough information to parse some rather complex file formats into equally<br/>complex data structures. We have, however, only scratched the surface of what<br/>Parse::RecDescent can do. Here is an overview of some of its other features.<br/>For further details see the documentation that comes with the module.<br/>
■<br/>
<i>Autotrees—</i>This is a method by which you can get the parser to automatically<br/>build a parse tree for your input data. If you don’t have a specific requirement<br/>for your output data structure, then this functionality might be of use to you.<br/>
■<br/>
<i>Lookahead rules—</i>Sometimes the data that you are parsing can be more complex<br/>than the examples that we have covered. In particular, if a token can change its<br/>meaning depending on what follows it, you should make use of lookahead<br/>
<hr/>
<a name=244></a><b>224</b><br/>
CHAPTER <br/>
<i><b>Building your own parsers</b></i><br/>
rules. These allow you to specify text in the rule which must be matched, but is<br/>not consumed by the match. This is very similar to the (?= …) construct in Perl<br/>regular expressions.<br/>
■<br/>
<i>Error handling—</i>Parse::RecDescent has a powerful functionality to allow<br/>you to output error messages when a rule fails to match.<br/>
■<br/>
<i>Dynamic rules—</i>Because terminals are either text strings or regular expressions<br/>and both of these can contain variables which are evaluated at run time, it is<br/>possible to create rules which change their meaning as the parse progresses.<br/>
■<br/>
<i>Subrule argument—</i>It is possible for a rule to pass arguments down into its<br/>subrule and, therefore, alter the way that they work.<br/>
■<br/>
<i>Incremental parsing—</i>It is possible to change the definition of a grammar<br/>which a program is running, using two methods called Extend and Replace.<br/>
■<br/>
<i>Precompiling parsers—</i>Using the Precompile method it is possible to create<br/>a new module that will parse a particular grammar. This new module can then<br/>be used in programs without Parse::RecDescent being present.<br/>
<i><b>11.5 Further information</b></i><br/>
The best place to get more information about Parse::RecDescent is in the man-<br/>ual pages that come with the module. Typing perldoc Parse::RecDescent at any<br/>command line will show you this documentation. The distribution also contains<br/>almost forty demo programs and an HTML version of Damian Conway’s article for<br/>the Winter 1998 issue of <i>The Perl Journal</i> titled “The man of descent,” which is a<br/>useful introduction to parsing in general and Parse::RecDescent in particular.<br/>
<i><b>11.6 Summary</b></i><br/>
■<br/>
Parse::RecDescent is a Perl module for building recursive descent parsers.<br/>
■<br/>
Parsers are created by passing the new method the definition of a grammar.<br/>
■<br/>
The parser is run by passing the text to be parsed to a method named after<br/>the top-level rule in the grammar.<br/>
■<br/>
Parser action code can be associated with grammar rules. The associated code<br/>is called when the rule matches.<br/>
■<br/>
The  @item array contains details of the tokens which have matched in a<br/>given rule.<br/>
■<br/>
Parser actions can change the value that will be returned by a rule. This is<br/>how you can build up parse tree data structures.<br/>
<hr/>
<a name=245></a><i>Part IV</i><br/>
<i>The big picture</i><br/>
At the end of the tale, our heroes return home determined to<br/>
spread the news to the general population about the tools and tech-<br/>niques they have learned. Nevermore will the people be terrified by the<br/>data munging beast. <br/>
This is obviously a cause for much celebration.  <br/>
<hr/>
<a name=246></a><hr/>
<a name=247></a><img class="yflip" src="dmp-247_1.jpg"/><br/>
<i>12</i><br/>
<i>Looking back—</i><br/>
<i>and ahead</i><br/>
<i><b>What this chapter covers:</b></i><br/>
■<br/>
Why munge data?<br/>
■<br/>
Just how useful is Perl?<br/>
■<br/>
Where can I find Perl support?<br/>
■<br/>
Where can I find more information?<br/>
<i>227</i><br/>
<hr/>
<a name=248></a><b>228</b><br/>
CHAPTER <br/>
<i><b>Looking back—and ahead</b></i><br/>
The received wisdom for giving a presentation is that you should “tell them what<br/>you’re going to tell them, tell them, and then tell them what you’ve told them.” A<br/>book is no different in principle to a presentation, so in this chapter we’ll review<br/>what we’ve covered and discuss where you can go for more information.<br/>
<i><b>12.1 The usefulness of things</b></i><br/>
A brief reminder of why you munge data and, more importantly, why you should<br/>munge it using Perl.<br/>
<i><b>12.1.1 The usefulness of data munging</b></i><br/>
In chapter 1 I said that data munging lived in the “interstices between computer<br/>systems.” I hope that you can now see just how all-pervasive it is. There are very<br/>few computing tasks that don’t involve munging data to some degree. From the<br/>run-once command line script which loads data files into a new database, to the<br/>many-thousand lines of code which run bank’s accounting systems, they are all<br/>munging data in one way or another.<br/>
<i><b>12.1.2 The usefulness of Perl</b></i><br/>
The next aim of the book was to demonstrate how well Perl fits into the data<br/>munging problem space. By allowing programmers to define a problem in a way<br/>that is closer to the way that their thought processes work and further from the way<br/>that computer CPUs work, many programmers find that using Perl makes them far<br/>more productive.<br/>
In a recent article on www.perl.com, Mark-Jason Dominus talks about the differ-<br/>
ence between “natural” code and “synthetic” code. Natural code is the code which<br/>is fundamentally tied in with solving the problem at hand. Synthetic code is code<br/>which is merely a side effect of the programming constructs that you use to solve<br/>the problem. A good example of synthetic code is a loop counter. In many pro-<br/>gramming languages, if you wanted to iterate across an array you would need to<br/>write code similar to this:<br/>
for ($i = 0; $i &lt;= $#arr; $i++) {<br/>
some_function($arr[$i]);<br/>
}<br/>
You can, of course, write code like this in Perl (as the sample demonstrates), but a<br/>far more Perlish way to write it is like this:<br/>
foreach (@arr) {<br/>
some_function($_);<br/>
}<br/>
<hr/>
<a name=249></a><i><b>Things to know</b></i><br/>
<b>229</b><br/>
Because the second version removes all of the synthetic code required to iterate<br/>across an array, it is far easier for a programmer to follow exactly what is happening.<br/>
Synthetic code only gets in the way of a programmer’s understanding of a pro-<br/>
gram so the goal must always be to eliminate as much of it as possible. Because Perl<br/>is particularly good at allowing programmers to model the problem exactly, it fol-<br/>lows that you end up with a far smaller amount of synthetic code than in many<br/>other languages.<br/>
If you’re interested in reading more (and you <i>should </i>be), Dominus’ article is at<br/>
http://www.perl.com/pub/2000/06/commify.html.<br/>
<i><b>12.1.3 The usefulness of the Perl community</b></i><br/>
One of the best things about using Perl is the community that goes with it. It<br/>seems to attract people who are only too happy to help others—whether by sub-<br/>mitting their code to the CPAN, answering a technical question in a newsgroup<br/>such as comp.lang.perl.misc, or on a website like Perl Monks, or even writing arti-<br/>cles for <i>The Perl Journal</i>.<br/>
If you are going to use Perl, I would certainly encourage you to become part of<br/>
the Perl community. There are a number of ways to do this:<br/>
■<br/>
Join your local Perl Mongers group. These are users’ groups. You can find<br/>the contact for your local group at www.pm.org. If there isn’t one for your<br/>area, why not form one?<br/>
■<br/>
Visit comp.lang.perl.misc regularly. This is the main Perl newsgroup. As long<br/>as you follow the rules of Netiquette, you will be very welcome there.<br/>
■<br/>
Read <i>The Perl Journal</i>. This is the only printed magazine dedicated to Perl.<br/>You can subscribe at www.tpj.com.<br/>
■<br/>
Submit your code to the CPAN. If you have written code which could be of<br/>use to others, why not put it in a place where everyone can find it? Details on<br/>becoming a CPAN author can be found at www.cpan.org.<br/>
<i><b>12.2 Things to know</b></i><br/>
A brief list of things that you should know to make your data munging work as easy<br/>as possible.<br/>
<i><b>12.2.1 Know your data</b></i><br/>
When munging data, the more that you know about your source and your sink, the<br/>better you will be able to design your program and, perhaps more importantly, your<br/>intermediate data structures. You need to know as much as possible about not only<br/>
<hr/>
<a name=250></a><b>230</b><br/>
CHAPTER <br/>
<i><b>Looking back—and ahead</b></i><br/>
the format of the data, but also what it will be used for, as this will help you to build<br/>flexibility into your program. Always design your program to be as flexible as possi-<br/>ble. This includes designing intermediate data structures carefully and using the<br/>UNIX filter model to remove any assumptions about input and output channels.<br/>
Know whether your data inputs or outputs are liable to change. If so, can you<br/>
design your program so that it makes no assumptions about input and output for-<br/>mats? Can your program work out the format from the actual input data? Or can<br/>the input and output formats be driven from configuration files? Can you have<br/>some input into the design of these formats? If so, can you make them flexible<br/>enough that one output format can go to more than one sink? Or can more than<br/>one source provide data in the same format? If not, can you munge the formats in a<br/>preprocessing program to make them all the same?<br/>
You may also need to know about the operating system that data was produced<br/>
on or will be used on, as this may affect the format of the data. Is it in ASCII,<br/>EBCDIC or Unicode? Is binary data big-endian or little-endian? What is the line<br/>end character sequence?<br/>
<i><b>12.2.2 Know your tools</b></i><br/>
Ensure that you are as comfortable as possible with Perl and its features. Buy and<br/>read Perl books. All Perl programmers should have read <i>Programming Perl, The<br/>Perl Cookbook</i>, <i>Mastering Regular Expressions</i>, and<i> Object Oriented Perl. </i>Read the<br/>documentation that comes with Perl—it will be more up-to-date than any book.<br/>Know what questions are answered in perldoc perlfaq (and know their answers).<br/>Subscribe to <i>The Perl Journal</i> (and consider buying a complete set of back issues).<br/>
Understand common Perl methods such as complex sorting techniques. Learn<br/>
how to benchmark your programs. Find the best performing solution to the prob-<br/>lem (but know when your solution is fast enough).<br/>
Visit the CPAN often enough to have an overview of what is there. If a module<br/>
will solve your problem then install it and save yourself writing more code than is<br/>necessary. If a module will almost solve your problem then consider contacting the<br/>author and suggest improvements. Even better, supply patches.<br/>
<i><b>12.2.3 Know where to go for more information</b></i><br/>
Here is a list of sources for information about Perl. Most of them have been men-<br/>tioned at some point in the book, but I thought it would be useful to gather them<br/>together in one place.<br/>
■<br/>
<i>The Perl Home Page</i>—Definitive source for all things Perl: www.perl.com<br/>
■<br/>
<i>comp.lang.perl.misc</i>—The most active Perl newsgroup.<br/>
<hr/>
<a name=251></a><i><b>Things to know</b></i><br/>
<b>231</b><br/>
■<br/>
perldoc<i> </i>perl<i> (and others)</i>—The best Perl documentation installed right on<br/>your computer.<br/>
■<br/>
<i>Programming Perl</i> (O’Reilly), Larry Wall, Tom Christiansen, and Jon<br/>Orwant—The essential Perl book. Make sure you get the 3rd edition.<br/>
■<br/>
<i>The Perl Cookbook</i> (O’Reilly), Tom Christiansen and Nathan Torkington—<br/>The essential Perl book (volume 2).<br/>
■<br/>
<i>Mastering Regular Expressions</i> (O’Reilly), Jeffrey Friedl—Everything you<br/>ever wanted to know about regexes.<br/>
■<br/>
<i>Object Oriented Perl</i> (Manning), Damian Conway—Everything you ever<br/>wanted to know about programming with objects in Perl.<br/>
■<br/>
<i>The Perl Journal</i>—The only Perl magazine.<br/>
■<br/>
<i>The Perl Mongers</i>—Friendly Perl people in your town. www.pm.org.<br/>
■<br/>
<i>Perl Monks</i>—A web site where Perl programmers help each other with Perl<br/>problems. http://www.perlmonks.org.<br/>
<hr/>
<a name=252></a><i>A</i><br/>
<i>Modules reference</i><br/>
<i>232</i><br/>
<hr/>
<a name=253></a><i><b>DBI</b></i><br/>
<b>233</b><br/>
In this book, we have looked at a number of Perl modules. Some of them are stan-<br/>dard modules that come bundled with your Perl distribution; others can be<br/>obtained from the CPAN.  <br/>
In order to avoid interrupting the flow of the narrative chapters, I have not given<br/>
detailed descriptions of the modules earlier in the book. Instead, I have gathered all<br/>of that information in this appendix. In all cases, this is not a complete reference for<br/>the module, but should be enough to take you beyond the examples in the book.<br/>Full references will come with the module and can be accessed by typing perldoc<br/>&lt;module_name&gt; at your command line. For example, typing <br/>
perldoc DBI<br/>
will give you a full description of DBI.pm.<br/>
<i><b>A.1</b></i><br/>
<i><b>DBI</b></i><br/>
The following is a brief list of the most useful DBI functions.<br/>
<i><b>A.1.1</b></i><br/>
<i><b>Functions called on the DBI class</b></i><br/>
These functions are called via the DBI class itself.<br/>
■<br/>
DBI-&gt;available_drivers<br/>Returns a list of the available DBD modules.<br/>
■<br/>
DBI-&gt;connect($data_source, $user, $password [, \%attributes])<br/>Creates a connection to a database and returns a handle which you use to<br/>carry out further actions on this connection.<br/>
■<br/>
$data_source will always start with “dbi:driver_name:”. The rest of the<br/>string is driver dependent.<br/>
■<br/>
$user and $password are passed unchanged to the database driver. They<br/>will usually be a valid database user and associated password.<br/>
■<br/>
\%attributes is a reference to an optional hash of attribute values. Cur-<br/>rently supported attributes are PrintError, RaiseError, and AutoCommit.<br/>These attributes are the keys of the hash and the associated values should<br/>be Boolean expressions (e.g., 0 or 1). The default values are the equiva-<br/>lents of setting the parameter to <br/>{PrintError =&gt; 1, RaiseError =&gt; 0, AutoCommit =&gt; 1}.<br/>
■<br/>
DBI-&gt;data_sources($driver)<br/>Returns a list of data sources available for the given driver.<br/>
<hr/>
<a name=254></a><b>234</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
■<br/>
DBI-&gt;trace($level [, $file])<br/>Controls the amount of trace information to be displayed (or written to the<br/>optional file). Calling trace via the DBI class will enable tracing on all handles.<br/>It is also possible to control trace levels at the handle level. The trace levels<br/>are described in detail in the DBI documentation. Full instructions on how to<br/>install CPAN modules can be found in perldoc perlmodinstall.<br/>
<i><b>A.1.2</b></i><br/>
<i><b>Attributes of the DBI class</b></i><br/>
The following attribute can be accessed through the DBI class.<br/>
■<br/>
$DBI::err, $DBI::errstr<br/>Returns the most recent database driver error encountered. A numeric error<br/>code is returned by $DBI::err and a text string is returned by $DBI::errstr.<br/>
<i><b>A.1.3</b></i><br/>
<i><b>Functions called on any DBI handle</b></i><br/>
The following functions are called via any valid DBI handle (usually a database han-<br/>dle or a statement handle).<br/>
■<br/>
$h-&gt;err, $h-&gt;errstr<br/>Returns the most recent database driver error encountered by this handle.<br/>A numeric error code is returned by $h-&gt;err and a text string is returned<br/>by $h-&gt;errstr.<br/>
■<br/>
$h-&gt;trace($level [, $file])<br/>Similar to DBI-&gt;trace, but works at the handle level.<br/>
<i><b>A.1.4</b></i><br/>
<i><b>Attributes of any DBI handle</b></i><br/>
The following attributes can be accessed via any DBI handle.<br/>
■<br/>
$h-&gt;{warn}<br/>Set to a Boolean value which determines whether warnings are raised for cer-<br/>tain bad practices.<br/>
■<br/>
$h-&gt;{Kids}<br/>Returns the number of statement handles that have been created from it and<br/>not destroyed.<br/>
■<br/>
$h-&gt;{PrintError}<br/>Set to a Boolean value which determines whether errors are printed to STDERR<br/>rather than just returning error codes. The default for this attribute is on.<br/>
■<br/>
$h-&gt;{RaiseError}<br/>Set to a Boolean value which determines whether errors cause the program to<br/>die rather than just returning error codes. The default for this attribute is off.<br/>
<hr/>
<a name=255></a><i><b>DBI</b></i><br/>
<b>235</b><br/>
■<br/>
$h-&gt;{Chopblanks}<br/>Set to a Boolean value which determines whether trailing blanks are removed<br/>from fixed-width character fields. The default for this value is off.<br/>
■<br/>
$h-&gt;{LongReadLen}<br/>Determines the amount of data that a driver will read when reading a large<br/>field from the database. These fields are often known by such names as text,<br/>binary, or blob. The default value is 0, which means that long data fields are<br/>not returned.<br/>
■<br/>
$h-&gt;{LongTruncOk}<br/>Set to a Boolean value which determines whether a fetch should fail if it attempts<br/>to fetch a long column that is larger than the current value of LongReadLen.<br/>The default value is 0 which means that truncated fetches raise an error.<br/>
<i><b>A.1.5</b></i><br/>
<i><b>Functions called on a database handle</b></i><br/>
The following functions are called on a valid database handle.<br/>
■<br/>
$dbh-&gt;selectrow_array($statement [, \%attr [, @bind_values]])<br/>Combines the prepare, execute, and fetchrow_array functions into one<br/>function call. When it is called in a list context it returns the first row of data<br/>returned by the query. When it is called in a scalar context it returns the first field<br/>of the first row. See the separate functions for more details on the parameters.<br/>
■<br/>
$dbh-&gt;selectall_arrayref($statement [, \%attr<br/>
[, @bind_values]])<br/>
Combines the prepare, execute, and fetchall_arrayref functions into a<br/>single function call. It returns a reference to an array. Each element of the<br/>array contains a reference to an array containing the data returned. See the<br/>separate functions for more details on the parameters.<br/>
■<br/>
$dbh-&gt;prepare($statement [, \%attr])<br/>Prepares an SQL statement for later execution against the database and returns<br/>a statement handle. This handle can later be used to invoke the execute func-<br/>tion. Most database drivers will, at this point, pass the statement to the data-<br/>base to ensure that it compiles correctly. If there is a problem, prepare will<br/>return undef.<br/>
■<br/>
$dbh-&gt;do($statement, \%attr, @bind_values)<br/>Prepares and executes an SQL statement. It returns the number of rows<br/>affected (–1 if the database driver doesn’t support this) or undef if there is an<br/>error. This is useful for executing statements that have no return sets, such as<br/>updates or deletes.<br/>
<hr/>
<a name=256></a><b>236</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
■<br/>
$dbh-&gt;commit, $dbh-&gt;rollback<br/>Will commit or rollback the current database transaction. They are only effec-<br/>tive if the AutoCommit attribute is set to 0.<br/>
■<br/>
$dbh-&gt;disconnect<br/>Disconnects the database handle from the database and frees any associ-<br/>ated memory.<br/>
■<br/>
$dbh-&gt;quote<br/>Applies whatever transformations are required to quote dangerous characters<br/>in a string, so that the string can be passed to the database safely. For exam-<br/>ple, many database systems use single quotes to delimit strings so that any<br/>apostrophes in a string can cause a syntax error. Passing the string through<br/>the quote function will escape the apostrophe in a database-specific manner.<br/>
<i><b>A.1.6</b></i><br/>
<i><b>Database handle attributes</b></i><br/>
The following attribute can be accessed through a database handle.<br/>
■<br/>
$dbh-&gt;{AutoCommit}<br/>Set to a Boolean value which determines whether or not each statement is<br/>committed as it is executed. The default value is 1, which means that it is<br/>impossible to roll back transactions. If you want to be able to roll back data-<br/>base changes then you must change this attribute to 0.<br/>
<i><b>A.1.7</b></i><br/>
<i><b>Functions called on a statement handle</b></i><br/>
The following functions are all called via a valid statement handle.<br/>
■<br/>
$sth-&gt;bind_param($p_num, $bind_value[, $bind_type])<br/>Used to bind a value to a placeholder in a prepared SQL statement. Place-<br/>holders are marked with the question mark character (?). The $p_num param-<br/>eter indicates which placeholder to use (placeholders are numbered from 1)<br/>and the $bind_values is the actual data to use. For example:<br/>
my %data = (LON =&gt; 'London', MAN =&gt; 'Manchester', BIR =&gt; 'Birmingham');<br/>
my $sth = $dbh-&gt;prepare('insert into city (code, name) values (?, ?)');<br/>
foreach (keys %data) {<br/>
$sth-&gt;bind_param(1, $_);<br/>
$sth-&gt;bind_param(2, $data{$_});<br/>
$sth-&gt;execute;<br/>
}<br/>
■<br/>
$sth-&gt;bind_param_inout($p_num, \$bind_value, $max_len <br/>
[, $bindtype])<br/>
Like bind_param but it also enables variables to be updated by the results of<br/>the statement. This function is often used when the SQL statement is a call to<br/>
<hr/>
<a name=257></a><i><b>DBI</b></i><br/>
<b>237</b><br/>
a stored procedure. Note that the $bind_value must be passed as a refer-<br/>ence to the variable to be used. The $max_len parameter is used to allocate<br/>the correct amount of memory to store the returned value.<br/>
■<br/>
$sth-&gt;execute([@bind_values])<br/>Executes the prepared statement on the database. If the statement is an<br/>insert, delete, or update then when this function returns, the insert,<br/>delete, or update will be complete. If the statement was a select statement,<br/>then you will need to call one of the fetch functions to get access to the result<br/>set. If any parameters are passed to this function, then bind_param will be<br/>run for each value before the statement is executed.<br/>
■<br/>
$sth-&gt;fetchrow_arrayref, $sth-&gt;fetch <br/>(fetch is an alias for fetchrow_arrayref)<br/>Fetches the next row of data from the result set and returns a reference to an<br/>array that holds the data values. Any NULL data items are returned as undef.<br/>When there are no more rows to be returned, the function returns undef.<br/>
■<br/>
$sth-&gt;fetchrow_array<br/>Similar to fetchrow_arrayref, except that it returns an array containing<br/>the row data. When there are no more rows to return, fetchrow_array<br/>returns an empty array.<br/>
■<br/>
$sth-&gt;fetchrow_hashref<br/>Similar to fetchrow_arrayref, except that it returns a hash containing the<br/>row data. The keys of the hash are the column names and the values are the data<br/>items. When there are no more rows to return, this function returns undef.<br/>
■<br/>
$sth-&gt;fetchall_arrayref<br/>Returns all of the data from a result set at one time. The function returns a<br/>reference to an array. Each element of the array is a reference to another. Each<br/>of these second-level arrays represents one row in the result set and each ele-<br/>ment contains a data item. This function returns an empty array if there is no<br/>data returned by the statement.<br/>
■<br/>
$sth-&gt;finish<br/>Disposes of the statement handle and frees up any memory associated with it.<br/>
■<br/>
$sth-&gt;bind_col($column_number, \$var_to_bind)<br/>Binds a column in a return set to a Perl variable. Note that you must pass a ref-<br/>erence to the variable. This means that each time a row is fetched, the variable<br/>is automatically updated to contain the value of the bound column in the newly<br/>fetched row. See the code example under bind_columns for more details.<br/>
<hr/>
<a name=258></a><b>238</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
■<br/>
$sth-&gt;bind_columns(@list_of_refs_to_vars)<br/>Binds each variable in the list to a column in the result set (the first variable in<br/>the list is bound to the first column in the result set, and so on). Note that<br/>the list must contain references to the variables. For example:<br/>
my ($code, $name);<br/>
my $sth = $dbh-&gt;prepare(‘select code, name from city’);<br/>
$sth-&gt;execute;<br/>
$sth-&gt;bind_columns(\$code, \$name);<br/>
while ($sth-&gt;fetch) {<br/>
print “$code: $name\n&#34;;<br/>
}<br/>
<i><b>A.1.8</b></i><br/>
<i><b>Statement handle attributes</b></i><br/>
The following attributes can be accessed through a statement handle.<br/>
■<br/>
$sth-&gt;{NUM_OF_FIELDS}<br/>Contains the number of fields (columns) that the statement will return.<br/>
■<br/>
$sth-&gt;{NAME}<br/>Contains a reference to an array which contains the names of the fields that<br/>will be returned by the statement.<br/>
■<br/>
$sth-&gt;{TYPE}<br/>Contains a reference to an array which contains an integer for each field in<br/>the result set. This integer indicates the data type of the field using an inter-<br/>national standard.<br/>
■<br/>
$sth-&gt;{NULLABLE}<br/>Contains a reference to an array which contains a value for each field that<br/>indicates whether the field can contain NULL values. The valid values are<br/>0 = no, 1 = yes, and 2 = don’t know.<br/>
<i><b>A.2</b></i><br/>
<i><b>Number::Format</b></i><br/>
The following is a brief reference to Number::Format.<br/>
<i><b>A.2.1</b></i><br/>
<i><b>Attributes</b></i><br/>
These are the attributes that can be passed to the new method.<br/>
■<br/>
THOUSANDS_SEP<br/>The character which is inserted between groups of three digits. The default is<br/>a comma.<br/>
<hr/>
<a name=259></a><i><b>Number::Format</b></i><br/>
<b>239</b><br/>
■<br/>
DECIMAL_POINT<br/>The character which separates the integer and fractional parts of a number.<br/>The default is a decimal point.<br/>
■<br/>
MON_THOUSANDS_SEP<br/>The same as THOUSANDS_SEP, but used for monetary values (formatted using<br/>format_price). The default is a comma.<br/>
■<br/>
MON_DECIMAL_POINT<br/>The same as DECIMAL_POINT, but used for monetary values (formatted using<br/>format_price). The default is a decimal point.<br/>
■<br/>
INT_CURR_SYMBOL<br/>The character(s) used to denote the currency. The default is USD .<br/>
■<br/>
DECIMAL_DIGITS<br/>The number of decimal digits to display. The default is two.<br/>
■<br/>
DECIMAL_FILL<br/>A Boolean flag indicating whether or not the formatter should add zeroes to<br/>pad out decimal numbers to DECIMAL_DIGITS places. The default is off.<br/>
■<br/>
NEG_FORMAT<br/>The format to use when displaying negative numbers. An 'x' marks where the<br/>number should be inserted. The default is -x.<br/>
■<br/>
KILO_SUFFIX<br/>The letter to append when format_bytes is formatting a value in kilobytes.<br/>The default is K.<br/>
■<br/>
MEGA_SUFFIX<br/>The letter to append when format_bytes is formatting a value in mega-<br/>bytes. The default is M.<br/>
<i><b>A.2.2</b></i><br/>
<i><b>Methods</b></i><br/>
These are the methods that you can call to format your data.<br/>
■<br/>
round($number, $precision)<br/>Rounds the given number to the given precision. If no precision is given, then<br/>DECIMAL_DIGITS is used. A negative precision will decrease the precision<br/>before the decimal point. This method doesn’t make use of the DECIMAL_<br/>POINT or THOUSANDS_SEP values.<br/>
■<br/>
format_number($number, $precision, $trailing_zeroes)<br/>Formats the given number to the given precision and pads with trailing zeroes if<br/>$trailing_zeroes is true. If neither $precision nor $trailing_zeroes<br/>
<hr/>
<a name=260></a><b>240</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
are given then the values in DECIMAL_DIGITS and DECIMAL_FILL are used<br/>instead. This method inserts the value of THOUSANDS_SEP every three digits<br/>and replaces the decimal point with the value of DECIMAL_POINT.<br/>
■<br/>
format_negative($number, $picture)<br/>Formats the given number using the given picture. If a picture is not given<br/>then the value of NEG_FORMAT is used instead. In the picture, the character<br/>“x” should be used to mark the place where the number should go.<br/>
■<br/>
format_picture($number, $picture)<br/>Formats the given number using the given picture. The picture should con-<br/>tain the character # wherever you want a digit from $number to appear. If<br/>there are fewer digits in $number than there are # characters, then the out-<br/>put is left-padded with spaces and any occurrences of THOUSANDS_SEP to the<br/>left of the number are removed. If there are more digits in $number than<br/>there are # characters in $picture then all of the # characters are replaced<br/>with * characters.<br/>
■<br/>
format_price($number, $precision)<br/>Works like format_number, except that the values of MON_THOUSANDS_SEP<br/>and MON_DECIMAL_POINT are used, and the value of INT_CURR_SYMBOL is<br/>prepended to the result.<br/>
■<br/>
format_bytes($number, $precision)<br/>Works like format_number except that numbers larger than 1024 will be<br/>divided by 1024 and he value of KILO_SUFFIX will be appended and numbers<br/>larger than 10242 will be divided by 10242 and the value of MEGA_SUFFIX will<br/>be appended.<br/>
■<br/>
unformat_number($formatted_number)<br/>The parameter $formatted_number must be a number that has been format-<br/>ted by format_number, format_price or format_picture. The formatting<br/>is removed and an unformatted number is returned.<br/>
<i><b>A.3</b></i><br/>
<i><b>Date::Calc</b></i><br/>
The most useful functions in Date::Calc include:<br/>
■<br/>
$days = Days_in_Month($year, $month)<br/>Returns the number of days in the given month in the given year.<br/>
■<br/>
$days = Days_in_Year($year, $month)<br/>Returns the number of days in the given year up to the end of the given month.<br/>Thus, Days_in_Year(2000, 1) returns 31, and Days_in_Year(2000, 2)<br/>returns 60.<br/>
<hr/>
<a name=261></a><i><b>Date::Calc</b></i><br/>
<b>241</b><br/>
■<br/>
$is_leap = leap_year($year)<br/>Returns 1 if the given year is a leap year and 0 if it isn’t.<br/>
■<br/>
$is_data = check_date($year, $month, $day)<br/>Checks whether or not the given combination of year, month, and day con-<br/>stitute a valid date. Therefore check_date(2000, 2, 29) returns true, but<br/>check_date(2000, 2, 2001) returns false.<br/>
■<br/>
$doy = Day_of_Year($year, $month, $day)<br/>Takes a given date in the year and returns the number of the day in the year<br/>that the date falls. Therefore Day_of_Year(1962, 9, 7) prints 250 as Sep-<br/>tember 7 was the 250th day of 1962.<br/>
■<br/>
$dow = Day_of_Week($year, $month, $day)<br/>Returns the day of the week that the given date fell on. This will be 1 for<br/>Monday and 7 for Sunday. Therefore Day_of_Week(1962, 9, 7) returns 5<br/>as September 7, 1962, was a Friday.<br/>
■<br/>
$week = Week_Number($year, $month, $day)<br/>Returns the week number of the year that the given date falls in. Week one is<br/>defined as the week that January 4 falls in, so it is possible for the number to<br/>be zero. It is also possible for the week number to be 53.<br/>
■<br/>
($year, $month, $day) = Monday_of_Week($week, $year)<br/>Returns the date of the first day (i.e., Monday) of the given week in the<br/>given year.<br/>
■<br/>
($year, $month, $day)<i> </i>=<i> </i>Nth_Weekday_of_Month_Year($year,<br/>
$month,<i> <br/></i>$dow,<i> </i>$n)<br/>
Returns the <i>n</i>th week day in the given month in the given year. For example<br/>if you wanted to find the third Sunday (day seven of the week) in November<br/>1999 you would call it as Nth_Weekday_of_Month_Year(1999, 11, 7, 3)<br/>which would return the November 21, 1999.<br/>
■<br/>
$days = Delta_Days($year1, $month1, $day1, <br/>
$year2, $month2, $day2)<br/>
Calculates the number of days between the two given dates.<br/>
■<br/>
($days, $hours, $mins, $secs) =<br/>        Delta_DHMS($year1, $month1,$day1, $hour1, $min1, $sec1,<br/>                             $year2, $month2, $day2, $hour2, $min2, $sec2)<br/>Returns the number of days, hours, minutes, and seconds between the two<br/>given dates and times.<br/>
■<br/>
($year, $month, $day) = Add_Delta_Days($year, $month,<br/>
$day, $days)<br/>
<hr/>
<a name=262></a><b>242</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
Adds the given number of days to the given date and returns the resulting<br/>date. If $days is negative then it is subtracted from the given date. There are<br/>other functions that allow you to add days, hours, minutes, and seconds<br/>(Add_Delta_DHMS) and years, months, and days (Add_Delta_YMD).<br/>
■<br/>
($year, $month, $day, $hour, $min, $sec,<br/>  $doy, $dow, $dst) =System_Clock<br/>Returns the same set of values as Perl’s own internal localtime function,<br/>except that the values have been converted into the values recognized by<br/>Date::Calc. Specifically, this means the ranges of the month and day of<br/>week have been shifted and the year has had 1900 added to it. There are<br/>also functions to get the current date (Today), time (Now) and date and<br/>time (Today_and_Now).<br/>
■<br/>
($year, $month, $day) = Easter_Sunday($year)<br/>Calculates the date of Easter Sunday in the given year.<br/>
■<br/>
$month = Decode_Month($string)<br/>Parses the string and attempts to recognize it as a valid month name. If a<br/>month is found then the corresponding month number is returned. There is a<br/>similar function (Decode_Day_of_Week) for working with days of the week.<br/>
■<br/>
$string = Date_to_Text($year, $month, $day)<br/>Returns a string which is a textual representation of the data that was passed<br/>to the function. For example Date_to_Text(1999, 12, 25) returns Sat 25-<br/>Dec-1999. There is also a Date_to_Text_Long function which for the same<br/>input would return Saturday 25 December 1999.<br/>
This is only a sample of the most useful functions in the module. In particular, I<br/>
have ignored the multilanguage support in the module.<br/>
<i><b>A.4</b></i><br/>
<i><b>Date::Manip</b></i><br/>
This is a brief list of some of the more important functions in Date::Manip.<br/>
■<br/>
$date=ParseDateString($string)<br/>Takes a string and attempts to parse a valid date out of it. The function will<br/>handle just about all common date and time formats and many other surprising<br/>ones like “today,” “tomorrow,” or in “two weeks” on Friday. This function<br/>returns the date in a standardized format, which is YYYYMMDDHH:MM:SS. You<br/>can convert it into a more user-friendly format using the UnixDate function<br/>described below. This is the most useful function in the module and you should<br/>think about installing this module simply to get access to this functionality.<br/>
<hr/>
<a name=263></a><i><b>Date::Manip</b></i><br/>
<b>243</b><br/>
■<br/>
$date = UnixDate($date, $format)<br/>Takes the given date (which can be in any format that is understood by<br/>ParseDateString) and formats it using the value of $format. The format<br/>string can handle any of the character sequences used by POSIX::strftime,<br/>but it defines a number of new sequences as well. These are all defined in the<br/>Date::Manip documentation.<br/>
■<br/>
$delta = ParseDelta($string)<br/>As well as dates (which indicate a fixed point in time), Date::Manip deals<br/>with date <i>deltas</i>. These are a number of years, months, days, hours, minutes,<br/>or seconds that you can add or subtract from a date in order to get another<br/>date. This function attempts to recognize deltas in the string that is passed to<br/>it and returns a standardized delta in the format Y:M:W:D:H:MN:S. The func-<br/>tion recognizes strings like +3Y 4M 2D to add three years, four months and<br/>two days. It also recognizes more colloquial terms like “ago” (e.g., 4 years<br/>ago) and “in” (e.g., in three weeks).<br/>
■<br/>
@dates = ParseRecur($recur, [$base, $start, $end, $flags])<br/>Returns a list of dates for a recurring event. The rules that govern how the<br/>event recurs are defined in $recur. The syntax is a little complex, but it is<br/>based loosely on the syntax of a UNIX crontab file and is defined in detail in<br/>the Date::Manip documentation.<br/>
■<br/>
$diff = Date_Cmp($date1, $date2)<br/>Compares two dates and returns the same values as Perl’s internal Cmp and<br/>&lt;=&gt; operators do for strings and numbers respectively; i.e., –1 if $date &lt;<br/>$date1, 0 if $date1 == $date2, and 1 if $date1 &gt; $date2. This means that<br/>this function can be used as a sort routine.<br/>
■<br/>
$d = DateCalc($d1, $d2)<br/>Takes two dates (or two deltas or one of each) and performs an appropriate<br/>calculation with them. Two deltas yield a third delta; a date and a delta yield<br/>the result of applying the delta to the date; and two dates yield a delta which<br/>is the time between the two dates. There are additional parameters that give<br/>you finer control over the calculation.<br/>
■<br/>
$date = Date_GetPrev($date, $dow, $curr, $time)<br/>Given a date, this function will calculate the previous occurrence of the given<br/>day of the week. If the given date falls on the given day of the week, then the<br/>behavior depends on the setting of the $curr flag. If $curr is non-zero then<br/>the current date is returned. If $curr is zero then the date a week earlier is<br/>returned. If the optional parameter $time is passed to the function, then the<br/>
<hr/>
<a name=264></a><b>244</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
time in the returned date is set to that value. There is also a very similar<br/>Date_GetNext function.<br/>
■<br/>
$day = Date_DayOfWeek($month, $day, $year)<br/>Returns the day of the week that the given date fell on (1 for Monday, 7 for<br/>Sunday). Note the nonstandard order of the arguments to this function.<br/>
■<br/>
$day = Date_DayOfYear($month, $day, $year)<br/>Returns the day of the year (1 to 366) that the given date falls on. Note the<br/>nonstandard order of the arguments to this function.<br/>
■<br/>
$days = Date_DaysInYear($year)<br/>Returns the number of days in the given year.<br/>
■<br/>
$days = Date_DaysInMonth($month, $year)<br/>Returns the number of days in the given month in the given year.<br/>
■<br/>
$flag = Date_LeapYear($year)<br/>Returns 1 if the given year is a leap year and 0 otherwise.<br/>
■<br/>
$day = Date_DaySuffix($day)<br/>Calculates the suffix that should be applied to the day number and appends it<br/>to the number; e.g., Date_DaySuffix returns “1st.”<br/>
This only scratches the surface of what Date::Manip is capable of. In particular,<br/>
it has very good support for working with business days and holidays and allows<br/>you to configure it to work with local holidays.<br/>
<i><b>A.5</b></i><br/>
<i><b>LWP::Simple</b></i><br/>
In chapter 9 we took a brief look at the LWP::Simple module. Here is a slightly less<br/>brief look at the functions that this module provides. For more information on<br/>using this module see the lwpcook manual page which comes with the LWP bundle<br/>of modules.<br/>
■<br/>
$page = get($url)<br/>Returns the document which is found at the given URL. It returns only the<br/>document without any of the HTTP headers. Returns undef if the request fails.<br/>
■<br/>
($content_type, $document_len, $mod_time, $expiry_time,<br/>  $server) = head($url)<br/>Returns various information from the HTTP header that is returned when the<br/>given URL is requested. Returns an empty list if the request fails.<br/>
■<br/>
$http_code = getprint($url)<br/>Gets the document from the given URL and prints it to STDOUT. If the<br/>
<hr/>
<a name=265></a><i><b>HTML::Parser</b></i><br/>
<b>245</b><br/>
request fails, it prints the status code and error message. The return value is<br/>the HTTP response code.<br/>
■<br/>
$http_code = getstore($url, $file)<br/>Gets the document from the given URL and stores it in the given file. The<br/>return value is the HTTP response code.<br/>
■<br/>
$http_response = mirror($url, $file)<br/>Mirrors the document at the given URL into the given file. If the document<br/>hasn’t changed since the file was created then no action is taken. Returns the<br/>HTTP response code.<br/>
<i><b>A.6</b></i><br/>
<i><b>HTML::Parser</b></i><br/>
Here is a brief guide to the methods of the HTML::Parser object. As I mentioned<br/>briefly in chapter 9, this describes version 3.x of HTML::Parser. In older versions<br/>you had to subclass HTML::Parser in order to do any useful work with it. Unfortu-<br/>nately, as I write this, the version of HTML::Parser available from the ActiveState<br/>module repository for use with ActivePerl is still a 2.x version.1 For further detail on<br/>using an older version, see the documentation that comes with the module.<br/>
■<br/>
$parser = HTML::Parser-&gt;new(%options_and_handlers)<br/>Creates an instance of the HTML parser object. For details of the various<br/>options and handlers that can be passed to this method, see the description<br/>later in this section. Returns the new parser object or undef on failure.<br/>
■<br/>
$parser-&gt;parse($html)<br/>Parses a piece of HTML text. Can be called multiple times.<br/>
■<br/>
$parser-&gt;eof<br/>Tells the parser the you have finished calling parse.<br/>
■<br/>
$parser-&gt;parse_file($file_name)<br/>Parses a file containing HTML.<br/>
■<br/>
$parser-&gt;strict_comment($boolean)<br/>Many popular browsers (including Netscape Navigator and Microsoft Inter-<br/>net Explorer) parse HTML comments in a way which is subtly different than<br/>the HTML standard. Calling this function and passing it a true value will<br/>switch on strict (i.e., in line with the HTML specification) comment handling.<br/>
1 As I was completing the final edits of this book, there were some moves towards correcting this discrepancy.<br/>
<hr/>
<a name=266></a><b>246</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
■<br/>
$parser-&gt;strict_names($boolean)<br/>This method has similar functionality to strict_comment, but deals with<br/>certain browsers’ ability to understand broken tag and attribute names.<br/>
■<br/>
$parser-&gt;xml_mode($boolean)<br/>When xml_mode is switched on, the parser handles certain XML constructs<br/>which aren’t allowed in HTML. These include combined start and end tags<br/>(e.g., &lt;br/&gt;) and XML processing instructions.<br/>
■<br/>
$parser-&gt;handler(%hash)<br/>Allows you to change handler functions. The arguments are similar to those<br/>in the handler arguments optionally passed to the new method. These are dis-<br/>cussed in the next section.<br/>
<i><b>A.6.1</b></i><br/>
<i><b>Handlers</b></i><br/>
To do anything useful with HTML::Parser, you need to define handlers which are<br/>called when the parser encounters certain constructs in the HTML document. You<br/>can define handlers for the events shown in table A.1.<br/>
Table A.1<br/>
<b>HTML::Parser</b> handlers<br/>
Handler<br/>
Called when …<br/>
declaration<br/>
an HTML DOCTYPE declaration is found<br/>
start<br/>
the start of an HTML tag is found<br/>
end<br/>
the end of an HTML tag is found<br/>
text<br/>
plain text is found<br/>
comment<br/>
an HTML comment is found<br/>
process<br/>
a processing instruction is found<br/>
Each of these handlers can be defined in two ways. Either you can pass details of<br/>
the handler to the new method or you can use the handler method after creating<br/>the parser object, but before parsing the document. Here are examples of both uses.<br/>
my $parser = HTML::Parser-&gt;new(start_h =&gt; [\&amp;start, 'tagname,attr']);<br/>
$parser-&gt;handler(start =&gt; [\&amp;start, 'tagname,attr']);<br/>
In both examples we have set the start handler to be a function called start which<br/>must be defined somewhere within our program. The only difference between the<br/>two versions is that when using new, the event name (i.e., start) must have the<br/>string _h appended to it. In both examples the actual subroutine to be called is<br/>
<hr/>
<a name=267></a><i><b>HTML::LinkExtor</b></i><br/>
<b>247</b><br/>
defined in a two-element array. The first element of the array is a reference to the<br/>subroutine to be called and the second element is a string defining the arguments<br/>which the subroutine expects. The various values that this string can contain are<br/>listed in table A.2.<br/>
Table A.2<br/>
Argument specification strings<br/>
Name<br/>
Description<br/>
Data type<br/>
self<br/>
The current parser object<br/>
Reference to the object<br/>
tokens<br/>
The list of tokens which makes up the current event<br/>
Reference to an array<br/>
tokenpos<br/>
A list of the positions of the tokens in the original text. Each token <br/>
Reference to an array<br/>
has two numbers; the first is the offset of the start of the token, <br/>and the second is the length of the token.<br/>
token0<br/>
The text of the first token (this is the same as $tokens-&gt;[0])<br/>
Scalar value<br/>
tagname<br/>
The name of the current tag<br/>
Scalar value<br/>
attr<br/>
The name and values of the attributes of the current tag<br/>
Reference to a hash<br/>
attrseq<br/>
A list of the names of the attributes of the current tag in the order <br/>
Reference to an array<br/>
that they appear in the original document<br/>
text<br/>
The source text for this event<br/>
Scalar value<br/>
dtest<br/>
The same as “text” but with any HTML entities (e.g., &amp;amp;) decoded<br/>
Scalar value<br/>
is_cdata<br/>
True if event is in a CDATA section<br/>
Scalar value<br/>
offset<br/>
The offset (in bytes) of the start of the current event from the start <br/>
Scalar value<br/>
of the HTML document<br/>
length<br/>
Length (in bytes) of the original text which constitutes the event<br/>
Scalar value<br/>
event<br/>
The name of the current event<br/>
Scalar value<br/>
line<br/>
The number of the line in the document where this event started<br/>
Scalar value<br/>
'   '<br/>
Any literal string is passed to the handler unchanged<br/>
Scalar value<br/>
undef<br/>
An undef value<br/>
Scalar value<br/>
<i><b>A.7</b></i><br/>
<i><b>HTML::LinkExtor</b></i><br/>
HTML::LinkExtor is a subclass of HTML::Parser and, therefore, all of that class’s<br/>methods are available. Here is a list of extra methods together with methods that<br/>have a different interface.<br/>
<hr/>
<a name=268></a><b>248</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
■<br/>
$parser = $HTML::LinkExtor-&gt;new($callback, $base)<br/>Creates an HTML::LinkExtor object. Both of its parameters are optional.<br/>The first parameter is a reference to a function which will be called each time<br/>a link is found in the document being parsed. This function will be called<br/>with the tag name in lower case as the first argument followed by a list of<br/>attributes and values. Only link attributes will be included. The second<br/>parameter is a base URL used to convert relative URLs to absolute ones (you<br/>will need the URI::URL module installed in order to use this functionality).<br/>
■<br/>
@links = $parser-&gt;links<br/>Having parsed a document, this method returns a list of all of the links found.<br/>Each element of the array returned is a reference to another array. This sec-<br/>ond level array contains the same values as would have been passed to the<br/>links callback if you had defined one in the call to new. If you do provide a<br/>link callback function, then links will return an empty array.<br/>
<i><b>A.8</b></i><br/>
<i><b>HTML::TokeParser</b></i><br/>
HTML::TokeParser is another subclass of HTML::Parser; however, it is not rec-<br/>ommended that you call any of the methods from the superclass. You should only<br/>use the methods defined by HTML::TokeParser.<br/>
■<br/>
$parser = HTML::TokeParser-&gt;new($document)<br/>Creates an HTML::TokeParser object. The single parameter defines the doc-<br/>ument to be parsed in one of a number of possible ways. If the method is<br/>passed a plain scalar then it is taken as the name of a file to open and read. If<br/>the method is passed a reference to a scalar then it assumes that the scalar<br/>contains the entire text of the document. If it is passed any other type of<br/>object (for example, a file handle) then it assumes that it can read data from<br/>the object as it is required.<br/>
■<br/>
$token = $parser-&gt;get_token<br/>Returns the next token from the document (or undef when there are no<br/>more tokens). A token consists of a reference to an array. The first element in<br/>the array is a character indicating the type of the token (S for start tag, E for<br/>end tag, T for text, C for comment, and D for a declaration). The remaining<br/>elements are the same as the parameters to the appropriate method of the<br/>HTML::Parser object.<br/>
■<br/>
$parser-&gt;unget_token<br/>You can’t know what kind of token you will get next until you have received<br/>it. If you find that you don’t need it yet, you can call this method to return it<br/>to the token stack to be given to you again the next time you call get_token.<br/>
<hr/>
<a name=269></a><i><b>HTML::TreeBuilder</b></i><br/>
<b>249</b><br/>
■<br/>
$tag = $parser-&gt;get_tag($tag)<br/>Returns the next start or end tag in the document. The parameter is optional<br/>and, if it is used, the method will return the next tag of the given type. The<br/>method returns undef if no more tokens (or no more tokens of the given<br/>type) are found. The tag is returned as a reference to an array. The elements<br/>of the array are similar to the elements in the array returned from the<br/>get_token method, but the character indicating the token type is missing<br/>and the name of an end tag will have a / character prepended.<br/>
■<br/>
$text = $parser-&gt;get_text($endtag)<br/>Returns all text at the current position of the document. If the optional<br/>parameter is omitted it returns the text up to the next tag. If an end tag is<br/>given then it returns all text up to the next end tag of the given type.<br/>
■<br/>
$text = $parser-&gt;get_trimmed_text($endtag)<br/>Works in the same way as the get_text method, except that any sequences<br/>of white space characters are collapsed to a single space, and any leading or<br/>trailing white space is removed.<br/>
<i><b>A.9</b></i><br/>
<i><b>HTML::TreeBuilder</b></i><br/>
HTML::TreeBuilder inherits all of the methods from HTML::Parser and HTML::<br/>Element. It builds an HTML parse tree when each node is an HTML::Element object.<br/>It only has a few methods of its own, and here is a list of them.<br/>
■<br/>
$parser-&gt;implicit_tags($boolean)<br/>If the boolean value is true then the parser will try to deduce where missing<br/>elements and tags should be.<br/>
■<br/>
$parser-&gt;implicit_body_p_tag($boolean)<br/>If the boolean value is true, the parser will force there to be a &lt;p&gt; element<br/>surrounding any elements which should not be immediately contained within<br/>a &lt;body&gt; tag.<br/>
■<br/>
$parser-&gt;ignore_unknown($boolean)<br/>Controls what the parser does with unknown HTML tags. If the boolean<br/>value is true then they are simply ignored.<br/>
■<br/>
$parser-&gt;ignore_text($boolean)<br/>If the boolean value is true then the parser will not represent any of the text<br/>of the document within the parser tree. This can be used (and save a lot of<br/>storage space) if you are only interested in the structure of the document.<br/>
<hr/>
<a name=270></a><b>250</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
■<br/>
$parser-&gt;ignore_ignorable_whitespace($boolean)<br/>If the boolean value is true then the parser will not build nodes for white<br/>space which can be ignored without affecting the structure of the document.<br/>
■<br/>
$parser-&gt;p_strict($boolean)<br/>If the boolean value is true then the parser will be very strict about the type<br/>of elements that can be contained within a &lt;p&gt; element and will insert a clos-<br/>ing &lt;/p&gt; tag if it is necessary.<br/>
■<br/>
$parser-&gt;store_comments($boolean),<br/>
$parser-&gt;store_declarations($boolean),<br/>
$parser-&gt;store_pis($boolean)<br/>These control whether or not comments, declarations, and processing<br/>instructions are stored in the parser tree.<br/>
■<br/>
$parser-&gt;warn($boolean)<br/>Controls whether or not warnings are displayed when syntax errors are found<br/>in the HTML document.<br/>
<i><b>A.10 XML::Parser</b></i><br/>
XML::Parser is one of the most complex modules that is covered in this book.<br/>Here is a brief reference to its most commonly used methods.<br/>
■<br/>
$parser = XML::Parser-&gt;new(Style =&gt; $style, <br/>
Handlers =&gt; \%handlers, <br/>Pkg =&gt; $package)<br/>
Creates an XML::Parser object. It takes a number of optional named param-<br/>eters. The Style parameter indicates which of a number of canned parsing<br/>styles you would like to use. Table A.3 lists the available styles along with the<br/>results of choosing a particular style.<br/>
Table A.3<br/>
<b>XML::Parser</b> Styles<br/>
Style <br/>
Results<br/>
name<br/>
Debug<br/>
Prints out a stylized version of the document outline.<br/>
Subs<br/>
When the start of an XML tag is found, the parser calls a subroutine with the same name as <br/>the tag. When the end of an XML tag is found, the parser calls a subroutine with the same <br/>names as the tag with an underscore character prepended. Both of these subroutines are <br/>presumed to exist in the package denoted by the Pkg parameter. The parameters passed to <br/>these subroutines are the same as those passed to the Start and End handler routines.<br/>
<hr/>
<a name=271></a><i><b>XML::Parser</b></i><br/>
<b>251</b><br/>
Table A.3<br/>
<b>XML::Parser</b> Styles (continued)<br/>
Style <br/>
Results<br/>
name<br/>
Tree<br/>
The parse method will return a parse tree representing the document. Each node is repre-<br/>sented by a reference to a two-element array. The first element in the list is either the tag <br/>name or “0” if it is a text node. The second element is the content of the tag. The content is <br/>a reference to another array. The first element of this array is a reference to a (possibly empty) <br/>hash containing attribute/value pairs. The rest of this array is made up of pair of elements <br/>representing the type and content of the contained nodes. See section 9.2.3 for examples.<br/>
Objects<br/>
The parse method returns a parse tree representing the object. Each node in the tree is a <br/>hash which has been blessed into an object. The object type names are created by append-<br/>ing the type of each tag to the value of the Pkg parameter followed by ::. A text node is <br/>blessed into the class ::Characters. Each node will have a kids attribute which will be a <br/>reference to an array containing each of the node’s children.<br/>
Stream<br/>
This style works in a manner similar to the Subs style. Whenever the parser finds particular <br/>XML objects, it calls various subroutines. These subroutines are all assumed to exist in the <br/>package denoted by the Pkg parameter. The subroutines are called StartDocument, <br/>
StartTag, EndTag, Text, PI, and EndDocument. The only one of these names which <br/>doesn’t make it obvious when the subroutine is called is PI. This is called when the parser <br/>encounters a processing instruction in the document.<br/>
The Handlers parameter is a reference to a hash. The keys of this hash are the<br/>
names of the events that the parser triggers while parsing the document and the val-<br/>ues are references to subroutines which are called when the events are triggered.<br/>The subroutines are assumed to be in the package defined by the Pkg parameter.<br/>Table A.4 lists the various types of handlers. The first parameter to each of these<br/>handlers is a reference to the Expat object which XML::Parser creates to actually<br/>handle the parsing. This object has a number of its own methods which you can use<br/>to gain even more precise control over the parsing process. For details of these, see<br/>the manual page for XML::Parser::Expat.<br/>
Table A.4<br/>
<b>XML::Parser</b> Handlers<br/>
Handler<br/>
When called<br/>
Subroutine parameters<br/>
Init <br/>
Before the parser starts processing the document<br/>
Reference to the Expat object<br/>
Final <br/>
After the parser finishes processing the document<br/>
Reference to the Expat object<br/>
Start <br/>
When the parser finds the start of a tag<br/>
Reference to the Expat object<br/>Name of the tag found<br/>List of name/value pairs for <br/>the attributes<br/>
<hr/>
<a name=272></a><b>252</b><br/>
APPENDIX <br/>
<i><b>Modules reference</b></i><br/>
Table A.4<br/>
<b>XML::Parser</b> Handlers (continued)<br/>
Handler<br/>
When called<br/>
Subroutine parameters<br/>
End <br/>
When the parser finds the end of a tag<br/>
Reference to the Expat Object<br/>
Char <br/>
When the parser finds character data<br/>
Reference to the Expat Object<br/>The character string<br/>
Proc <br/>
When the parser finds a processing instruction<br/>
Reference to the Expat Object<br/>The name of the PI target<br/>The PI data<br/>
Comment <br/>
When the parser finds a comment<br/>
Reference to the Expat Object<br/>The comment data<br/>
CdataStart <br/>
When the parser finds the start of a CDATA section<br/>
Reference to the Expat Object<br/>
CdataEnd <br/>
When the parser finds the end of a CDATA section<br/>
Reference to the Expat Object<br/>
Default<br/>
When the parser finds any data that doesn’t have an  Reference to the Expat Object<br/>assigned handler<br/>
The data string<br/>
Unparsed<br/>
When the parser finds an unparsed entity declaration<br/>
Reference to the Expat Object<br/>Name of the Entity<br/>Base URL to use when resolving the <br/>address<br/>The system ID<br/>The public ID<br/>
Notation<br/>
When the parser finds a notation declaration<br/>
Reference to the Expat Object<br/>Name of the Notation<br/>Base URL to use when resolving the <br/>address<br/>The system ID<br/>The public ID<br/>
ExternEnt<br/>
When the parser finds an external entity declaration<br/>
Reference to the Expat Object.<br/>Base URL to use when resolving the <br/>address<br/>The system ID.<br/>The public ID.<br/>
Entity<br/>
When the parser finds an entity declaration<br/>
Reference to the Expat Object<br/>Name of the Entity<br/>The value of the Entity<br/>The system ID<br/>The public ID<br/>The notation for the entity<br/>
Element<br/>
When the parser finds an element declaration<br/>
Reference to the Expat Object<br/>Name of the Element<br/>The Content Model<br/>
<hr/>
<a name=273></a><i><b>XML::Parser</b></i><br/>
<b>253</b><br/>
Table A.4<br/>
<b>XML::Parser</b> Handlers (continued)<br/>
Handler<br/>
When called<br/>
Subroutine parameters<br/>
Attlist<br/>
When the parser finds an attribute declaration<br/>
Reference to the Expat Object<br/>Name of the Element<br/>Name of the Attribute<br/>The Attribute Type<br/>Default Value<br/>String indicating whether the <br/>attribute is fixed<br/>
Doctype<br/>
When the parser finds a DocType declaration<br/>
Reference to the Expat Object<br/>Name of the Document Type<br/>System ID<br/>Public ID<br/>The Internal Subset<br/>
XMLDecl<br/>
When the parser finds an XML declaration<br/>
Reference to the Expat Object<br/>Version of XML<br/>Document Encoding<br/>String indication whether or not the <br/>DTD is standalone<br/>
Pkg is the name of a package. All handlers are assumed to be in this package and<br/>
all styles which rely on user-defined subroutines also search for them in this pack-<br/>age. If this parameter is not given then the default package name is main.<br/>
This method also takes a number of other optional parameters, all of which are passed<br/>
straight on to the Expat object. For details see the manual page for XML::Parser.<br/>
■<br/>
$parser-&gt;parse($source)<br/>Parses the document. The $source parameter should either be the entire<br/>document in a scalar variable or a reference to an open IO::Handle object.<br/>The return value varies depending on the style chosen.<br/>
■<br/>
$parser-&gt;parse_file($filename)<br/>Opens the given file and parses the contents. The return value varies accord-<br/>ing to the style chosen.<br/>
■<br/>
$parser-&gt;setHandlers(%handlers)<br/>Overrides the current set of handlers with a new set. The parameters are inter-<br/>preted as a hash in exactly the same format as the one passed to new. By includ-<br/>ing an empty string or undef, the associated handler can be switched off.<br/>
<hr/>
<a name=274></a><i>B</i><br/>
<i>Essential Perl</i><br/>
<i>254</i><br/>
<hr/>
<a name=275></a><i><b>Running Perl</b></i><br/>
<b>255</b><br/>
Throughout this book I have assumed that you have a certain level of knowledge of<br/>Perl and have tried to explain everything that I have used beyond that level. In this<br/>appendix, I’ll give a brief overview of the level of Perl that I’ve been aiming at. Note<br/>that this is not intended to be a complete introduction to Perl. For that you would<br/>be better looking at <i>Learning Perl</i> by Randal Schwartz and Tom Christiansen<br/>(O’Reilly); <i>Elements of Programming with Perl</i> by Andrew Johnson (Manning), or<br/><i>Perl: The Programmer’s Companion</i> by Nigel Chapman (Wiley).  <br/>
<i><b>B.1</b></i><br/>
<i><b>Running Perl</b></i><br/>
There are a number of ways to achieve most things in Perl and running Perl scripts<br/>is no exception. In most cases you will write your Perl code using a text editor and<br/>save it to a file. Many people like to give Perl program files the extension .pl, but<br/>this usually isn’t necessary.1 <br/>
Under most modern operating systems the command interpreter works out how<br/>
to run a script by parsing the first line of the script. If the first line looks like<br/>
#!/path/to/script/interpreter<br/>
then the program defined in this line will be called and your program file will be<br/>passed to it as input. In the case of Perl, this means that your Perl program files<br/>should usually start with the line<br/>
#!/usr/bin/perl<br/>
(although the exact path to the Perl interpreter will vary from system to system).<br/>
Having saved your program (and made the file executable if your operating sys-<br/>
tem requires it) you can run it by typing the name of the file on your command line;<br/>e.g., if your script is in a file called myscript.pl you can run it by typing<br/>
myscript.pl<br/>
at the command line.<br/>
An alternative would be to call the Perl interpreter directly, passing it the name of<br/>
your script like this:<br/>
perl myscript.pl<br/>
There are a number of command line options that you can either put on the com-<br/>mand line or on the interpreter line in the program file. The most useful include:<br/>
1 I say “usually” because Windows uses the extension of the file to determine how to run it. Therefore, if<br/>
you’re developing Perl under Windows, you’ll need the .pl extension.<br/>
<hr/>
<a name=276></a><b>256</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
■<br/>
-w<br/>
Asks Perl to notify you when it comes across a number of unsafe pro-<br/>
gramming practices in your program. These include using a variable before it<br/>is initialized and attempting to write to a file handle that is opened for read-<br/>ing. These warnings are usually very useful and there is no good reason not to<br/>use this option for every Perl program that you write.<br/>
■<br/>
-T<br/>
Turns on Perl’s “taint” mode. In this mode all input from an external<br/>
source is untrusted by default. You can make use of such input only by explic-<br/>itly cleaning it first. This is particularly useful if you are writing a CGI script.<br/>For more details see the perlsec manual page.<br/>
■<br/>
-c<br/>
Checks a script for syntax errors without executing it.<br/>
■<br/>
-d<br/>
Runs the script using Perl’s built-in debugger.<br/>
There is another way that you can pass Perl code to the Perl interpreter. This is to<br/>
use the -e command line option. A text string following this option is assumed to<br/>be code to be executed, for example:<br/>
perl -e 'print &#34;Hello World\n&#34;;'<br/>
will print the string “Hello World” to the console.<br/>
It may seem that this feature wouldn’t be very useful as the only scripts that you<br/>
can write like this would be very small; however, Perl has a number of other com-<br/>mand line options that can combine with -e to create surprisingly complex scripts.<br/>Details of these options are given in chapter 3.<br/>
All of the information that you could ever need about running Perl can be found<br/>
in the perlrun manual page.<br/>
<i><b>B.2</b></i><br/>
<i><b>Variables and data types</b></i><br/>
Perl supports a number of different data types. Each data type can be stored in its<br/>own type of variable. Unlike languages such as C or Pascal, Perl variables are not<br/>strongly typed. This means that a variable that contains a number can just as easily<br/>be used as a string without having to carry out any conversions.<br/>
The main data types that you will come across in Perl are scalars, arrays, and<br/>
hashes. More complex data structures can be built using a combination of these<br/>types. The type of a Perl variable can be determined by the symbol that precedes the<br/>variable name. Scalars use $, arrays use @, and hashes use %.<br/>
<i><b>B.2.1</b></i><br/>
<i><b>Scalars</b></i><br/>
A scalar variable holds a single item of data. This data can be either a number or a<br/>string (or a reference, but we’ll come to that later). Here are some examples of<br/>assigning values to a scalar variable:<br/>
<hr/>
<a name=277></a><i><b>Variables and data types</b></i><br/>
<b>257</b><br/>
$text = 'Hello World';<br/>
$count = 100;<br/>
$count = 'one hundred';<br/>
As you can see from the last two examples, the same scalar variable can contain both<br/>text and numbers. If a variable holds a number and you use it in a context where<br/>text is more useful, then Perl automatically makes the translation for you.<br/>
$number = 1;<br/>
$text = &#34;$number ring to rule them all&#34;;<br/>
After running this code, $text would contain the string “1 ring to rule them all”.<br/>This also works the other way around.2<br/>
$number = '100';<br/>
$big_number = $number * 2; # $big_number now contains the value 200.<br/>
Notice that we have used two different types of quotes to delimit strings in the previ-<br/>ous examples. If a string is in double quotes and it contains variable names, then<br/>these variables are replaced by their values in the final string. If the string is in single<br/>quotes then variable expansion does not take place. There are also a number of char-<br/>acter sequences which are expanded to special characters within double quotes. These<br/>include \n for a newline character, \t for a tab, and \x1F for a character whose ASCII<br/>code is 1F in hex. The full set of these escape sequences is in perldoc perldata.<br/>
<i><b>B.2.2</b></i><br/>
<i><b>Arrays</b></i><br/>
An array contains an ordered list of scalar values. Once again the scalar values can be<br/>of any type. Here are some examples of array assignment:<br/>
@empty = ();<br/>
@hobbits = ('Bilbo', 'Frodo', 'Merry');<br/>
@elves = ('Elrond', 'Legolas', 'Galadriel');<br/>
@people = (@hobbits, @elves);<br/>
($council, $fellow, $mirror) = @elves;<br/>
Notice that when assigning two arrays to a third (as in the fourth example above)<br/>the result array is an array consisting of six elements, not an array with two elements<br/>each of which is another array. Remember that the elements of an array can only be<br/>scalars. The final example shows how you can use list assignment to extract data<br/>from an array.<br/>
You can access the individual elements of an array using syntax like this:<br/>
$array[0]<br/>
2 You can always turn a number into a string, but it’s harder to turn most strings into numbers.<br/>
<hr/>
<a name=278></a><b>258</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
You can use this syntax to both get and set the value of an individual array element. <br/>
$hero = $hobbits[0];<br/>
$hobbits[2] = 'Pippin';<br/>
Notice that we use $ rather than @ to denote this value. This is because a single ele-<br/>ment of an array is a scalar value, not an array value.<br/>
If you assign a value to an element outside the current array index range, then<br/>
the array is automatically extended.<br/>
$hobbits[3] = 'Merry';<br/>
$hobbits[100] = 'Sam';<br/>
In that last example, all of the elements between 4 and 99 also magically sprang into<br/>existence, and they all contain the value undef.<br/>
You can use negative index values to access array values from the end of the array.<br/>
$gardener = $hobbits[-1];<br/>
# $gardener now contains 'Sam'<br/>
You can use an <i>array slice</i> to access a number of elements of an array at once. In this<br/>case the result is another array.<br/>
@ring_holders = @hobbits[0, 1];<br/>
You can also use syntax indicating a range of values:<br/>
@ring_holders = @hobbits[0 .. 1];<br/>
or even another array which contains the indexes of the values that you need.<br/>
@index = (0, 1);<br/>
@ring_holders = @hobbits[@index];<br/>
You can combine different types of values within the same assignment.<br/>
@ring_holders = ('Smeagol', @hobbits[0, 1], 'Sam');<br/>
If you assign an array to a scalar value, you will get the number of elements in the array.<br/>
$count = @ring_holders;<br/>
# $count is now 4<br/>
There is a subtle difference between an array and a <i>list</i> (which is the set of values<br/>that an array contains). Notably, assigning a list to a scalar will give you the value of<br/>the rightmost element in the list. This often confuses newcomers to Perl.<br/>
$count = @ring_holders;<br/>
# As before, $count is 4<br/>
$last = ('Bilbo', 'Frodo'); # $last contains 'Frodo'<br/>
You can also get the index of the last element of an array using the syntax:<br/>
$#array<br/>
There are a number of functions that can be used to process a list.<br/>
<hr/>
<a name=279></a><i><b>Variables and data types</b></i><br/>
<b>259</b><br/>
■<br/>
push<i> </i>@array, list—Adds the elements of list to the end of @array.<br/>
■<br/>
pop<i> </i>@array—Removes and returns the last element of @array.<br/>
■<br/>
shift<i> </i>@array—Removes and returns the first element of @array.<br/>
■<br/>
unshift<i> </i>@array, list—Adds the elements of list to the front of @array.<br/>
■<br/>
splice @array, $offset, $length, list—Removes and returns $length<br/>elements from @array starting at element $offset and replaces them with<br/>the elements of list. If list is omitted then the removed elements are sim-<br/>ply deleted. If $length is omitted then everything from $offset to the end<br/>of @array is removed.<br/>
Two other very useful list processing functions are map and grep. map is passed a<br/>
block of code and a list and returns the list created by running the given code on<br/>each element of the list in turn. Within the code block, the element being processed<br/>is stored in $_. For example, to create a list of squares, you could write code like this:<br/>
@squares = map { $_ * $_ } @numbers;<br/>
If @numbers contains the integers from 1 to 10, then @square will end up contain-<br/>ing the squares of those integers from 1 to 100. It doesn’t have to be true that each<br/>iteration only generates one element in the new list; for example, the code<br/>
@squares = map { $_, $_ * $_ } @numbers;<br/>
generates a list wherein each integer is followed by its square.<br/>
grep is also passed a block of code and a list. It executes the block of code for<br/>
each element on the list in turn, and if the code returns a true value, then grep adds<br/>the original element to its return list. The list returned, therefore, contains all the<br/>elements wherein the code evaluated to true. For example, given a list containing<br/>random integers,<br/>
@odds = grep { $_ % 2 } @ints;<br/>
will put all of the odd values into the array @odds.<br/>
<i><b>B.2.3</b></i><br/>
<i><b>Hashes</b></i><br/>
Hashes (or, as they were previously known, associative arrays) provide a simple way to<br/>implement lookup tables in Perl. They associate a value with a text key. You assign<br/>values to a hash in much the same way as you do to an array. Here are some examples:<br/>
%rings = ();<br/>
# Creates an empty hash<br/>
%rings = ('elves', 3, 'dwarves', 7);<br/>
%rings = (elves =&gt; 3, dwarves =&gt; 7); # Another way to do the same thing<br/>
$rings{men} = 9;<br/>
$rings{great} = 1;<br/>
<hr/>
<a name=280></a><b>260</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
Notice that using the arrow operator (=&gt;) has two advantages over the comma. It<br/>makes the assignment easier to understand and it automatically quotes the value to its<br/>left. Also notice that hashes use different brackets to access individual elements and<br/>because, like arrays, each element is a scalar, it is denoted with a $ rather than a %.<br/>
You can access the complete set of keys in a hash using the function keys, which<br/>
returns a list of the hash keys.<br/>
@ring_types = keys %rings; # @ring_types is now ('men', 'great',<br/>
'dwarves', 'elves')<br/>
There is a similar function for values.<br/>
@ring_counts = values %rings; # @ring_counts is now (9, 1, 7, 3)<br/>
Notice that neither keys nor values is guaranteed to return the data in the same<br/>order as it was added to the hash. They are, however, guaranteed to return the<br/>data in the same order (assuming that you haven’t changed the hash between the<br/>two calls). <br/>
There is a third function in this set called each which returns a two-element list<br/>
containing one key from the hash together with its associated value. Subsequent<br/>calls to each will return another key/value pair until all pairs have been returned, at<br/>which point an empty array is returned. This allows you to write code like this:<br/>
while ( ($type, $count) = each %rings) ) {<br/>
print &#34;$count $type ring(s)\n&#34;;<br/>
}<br/>
You can also call each in a scalar context in which case it iterates over the keys in<br/>the hash.<br/>
The most efficient way to get the number of key/value pairs in a hash is to assign<br/>
the return value from either keys or values to a scalar variable.3<br/>
$ring_types = keys %rings;<br/>
# $ring_types is now 4<br/>
You can access parts of a hash using a <i>hash slice</i> which is very similar to the array slice<br/>discussed earlier.<br/>
@minor_rings_types = ('elves', 'dwarves', 'men');<br/>
@minor_rings{@minor_rings_types} = @rings{@minor_rings_types};<br/>
# creates a new hash called %minor rings containing<br/>
#<br/>
elves =&gt; 3<br/>
#<br/>
dwarves =&gt; 7<br/>
#<br/>
men =&gt; 9<br/>
3 Note that this example also demonstrates that you can have variables of different types with the same<br/>
name. The scalar $ring_types in this example has no connection at all with the array @ring_types in the<br/>earlier example.<br/>
<hr/>
<a name=281></a><i><b>Operators</b></i><br/>
<b>261</b><br/>
Note, once again, that a hash slice returns a list and therefore is prefixed with @. The<br/>key list, however, is still delimited with { and }.<br/>
As a hash can be given values using a list, it is possible to use the map function to<br/>
turn a list into a hash. For example, the following code creates a hash where the<br/>keys are numbers and the values are their squares.<br/>
%squares = map { $_, $_ * $_ } @numbers;<br/>
<i><b>B.2.4</b></i><br/>
<i><b>More information</b></i><br/>
For more information about Perl data types, see the perldata manual page.<br/>
<i><b>B.3</b></i><br/>
<i><b>Operators</b></i><br/>
Perl has all of the operators that you will be familiar with from other languages—<br/>and a few more besides. You can get a complete list of all of Perl’s operators in the<br/>perlop manual page. Let’s look at some of the operators in more detail.<br/>
<i><b>B.3.1</b></i><br/>
<i><b>Mathematical operators</b></i><br/>
The operators +, -, *, and / will add, subtract, multiply, and divide their two oper-<br/>ands respectively. % will find the modulus of the two operands (that is the remainder<br/>when integer division is carried out).<br/>
Unary minus (-) reverses the sign of its single operand.<br/>Unary increment (++) and decrement (--) operators will add or subtract one<br/>
from their operands. These operators are available both in prefix and postfix ver-<br/>sions. Both versions increment or decrement the operand, but the prefix versions<br/>return the result after the operation and the postfix versions return the results<br/>before the operation.<br/>
The exponentiation operator (**) raises its left-hand operand to the power given<br/>
by its right operand.<br/>
All of the binary mathematical operators are available in an assignment version.<br/>
For example,<br/>
$x += 5;<br/>
is exactly equivalent to writing<br/>
$x = $x + 5;<br/>
Similar to the mathematical operators, but working instead on strings, the concate-<br/>nation operator (.) joins two strings and the string multiplication operator (x)<br/>returns a string made of its left operand repeated the number of times given by its<br/>right operand. For example,<br/>
<hr/>
<a name=282></a><b>262</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
$y = 'hello' x 3;<br/>
results in $y having the value “hellohellohello”.<br/>
In an array context, if the left operand is a list, then this operator acts as a list rep-<br/>
etition operator. For example,<br/>
@a = (0) x 100;<br/>
makes a list with 100 elements, each of which contains the number 0, and then<br/>assigns it to @a.<br/>
<i><b>B.3.2</b></i><br/>
<i><b>Logical operators</b></i><br/>
Perl distinguishes between logical operators for use on numbers and logical opera-<br/>tors for use on strings. The former set uses the mathematical symbols &lt;, &lt;=, ==, !=,<br/>&gt;=, and &gt; for less than, less than or equal to, equal to, not equal to, greater than or<br/>equal to, and greater than, respectively, whereas the string logical operators use lt,<br/>le, eq, ne, ge, and gt for the same operations. All of these operators return 1 if<br/>their operands satisfy the relationship and 0 if they don’t. In addition, there are two<br/>comparison operators &lt;=&gt; (for numbers) and cmp (for strings) which return –1, 0,<br/>or 1 depending on whether their first operand is less than, equal to, or greater than<br/>their second operand.<br/>
For joining logical comparisons, Perl has the usual set of operators, but once<br/>
again it has two sets. The first set uses &amp;&amp; for conjunction and || for disjunction.<br/>These operators have very high precedence. The second set uses the words and and<br/>or. This set has very low precedence. The difference is best explained with an exam-<br/>ple. When opening a file, it is very common in Perl to write something like this:<br/>
open DATA, 'file.dat' or die &#34;Can't open file\n&#34;;<br/>
Notice that we have omitted the parentheses around the arguments to open.<br/>Because of the low precedence of or, this code is interpreted as if we had written<br/>
open (DATA, 'file.dat') or die &#34;Can't open file\n&#34;;<br/>
which is what we wanted. If we had used the high precedence version of the opera-<br/>tor instead, like this<br/>
open DATA, 'file.dat' || die &#34;Can't open file\n&#34;;<br/>
it would have bound more tightly than the comma that builds up the list of arguments<br/>to open. Our code would, therefore, have been interpreted as though we had written<br/>
open DATA, ('file.dat' || die &#34;Can't open file\n&#34;);<br/>
which doesn’t achieve the correct result.<br/>
<hr/>
<a name=283></a><i><b>Flow of control</b></i><br/>
<b>263</b><br/>
The previous example also demonstrates another feature of Perl’s logical opera-<br/>
tors—they are <i>short-circuiting</i>. That is to say they only execute enough of the terms<br/>to know what the overall result will be. In the case of the open example, if the call<br/>to open is successful, then the left-hand side of the operator is true, which means<br/>that the whole expression is true (as an or operation is true if either of its operands<br/>is true). The right-hand side (the call to die) is therefore not called. If the call to<br/>open fails, then the left-hand side of the operator is false. The right-hand side must<br/>therefore be executed in order to ascertain what the result is. This leads to a very<br/>common idiom in Perl in which you will often see code like<br/>
execute_code() or handle_error();<br/>
Unusually, the logical operators are also available in assignment versions. The “or-<br/>equals” operator is the most commonly used of these. It is used in code like<br/>
$value ||= 'default';<br/>
This can be expanded into<br/>
$value = $value || 'default';<br/>
from which it is obvious that the code sets $value to a default value if it doesn’t<br/>already have a value.<br/>
Perl also has <i>bitwise</i> logical operators for and (&amp;) or (|), exclusive or (^), and nega-<br/>
tion (~). These work on the binary representation of their two operands and, there-<br/>fore, don’t always give intuitively correct answers (for example ~1 isn’t equal to 0).<br/>There are also left (&lt;&lt;) and right (&gt;&gt;) shift operators for manipulating binary num-<br/>bers. One use for these is to quickly multiply or divide numbers by a power of two.<br/>
<i><b>B.4</b></i><br/>
<i><b>Flow of control</b></i><br/>
Perl has all of the standard flow of control constructs that are familiar from other<br/>languages, but many of them have interesting variations.<br/>
<i><b>B.4.1</b></i><br/>
<i><b>Conditional execution</b></i><br/>
The if statement executes a piece of code only if an expression is true.<br/>
if ($location eq 'The Shire') {<br/>
$safety = 1;<br/>
}<br/>
The statement can be extended with an else clause.<br/>
if ($location eq 'The Shire') {<br/>
$safety++;<br/>
} else {<br/>
<hr/>
<a name=284></a><b>264</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
$safety--;<br/>
}<br/>
And further extended with elsif clauses.<br/>
if ($location eq 'The Shire') {<br/>
$safety++;<br/>
} elsif ($location eq 'Mordor') {<br/>
$safety = 0;<br/>
} else {<br/>
$safety--;<br/>
}<br/>
Perl also has an unless statement which is logically opposite the if statement—it<br/>executes unless the condition is true.<br/>
unless ($location eq 'The Shire') {<br/>
$panic = 1;<br/>
}<br/>
Both the if and unless keywords can be used as <i>statement modifiers</i>. This can<br/>often make for more readable code.<br/>
$damage *= 2 if $name eq 'Aragorn';<br/>
$dexterity++ unless $name eq 'Sam';<br/>
<i><b>B.4.2</b></i><br/>
<i><b>Loops</b></i><br/>
Perl has a number of looping constructs to execute a piece of code a number of times.<br/>
<i><b>for loop<br/></b></i>The for loop has the syntax:<br/>
for (initialisation; test; increment) {<br/>
statements;<br/>
}<br/>
For example,<br/>
for ($x = 1; $x &lt;= 10; ++$x) {<br/>
print &#34;$x squared is &#34;, $x * $x, &#34;\n&#34;;<br/>
}<br/>
The loop will execute until the test returns a false value. It is probably true to say<br/>that this loop is very rarely used in Perl, as the foreach loop discussed in the next<br/>section is far more flexible.<br/>
<hr/>
<a name=285></a><i><b>Flow of control</b></i><br/>
<b>265</b><br/>
<i><b>foreach loop<br/></b></i>The foreach loop has the syntax:<br/>
foreach var (list) {<br/>
statements;<br/>
}<br/>
For example, the previous example can be rewritten as:<br/>
foreach my $x (1 .. 10) {<br/>
print &#34;$x squared is &#34;, $x * $x, &#34;\n&#34;;<br/>
}<br/>
which, to many people, is easier to understand as it is less complex. You can even omit<br/>the loop variable, in which case each element in the list in turn is accessible as $_.<br/>
foreach (1 .. 10) {<br/>
print &#34;$_ squared is &#34;, $_ * $_, &#34;\n&#34;;<br/>
}<br/>
This loop will execute until each element of the list has been processed. It is often<br/>used for iterating across the contents of an array like this:<br/>
foreach (@data) {<br/>
process($_);<br/>
}<br/>
<i><b>while loop<br/></b></i>The while loop has the syntax:<br/>
while (condition) {<br/>
statements<br/>
}<br/>
For example,<br/>
while ($data = get_data()) {<br/>
process($data);<br/>
}<br/>
This loop will execute until the condition evaluates to a false value.<br/>
<i><b>Loop control<br/></b></i>There are three keywords which can be used to alter the normal execution of a<br/>loop: next, last, and redo. <br/>
next immediately starts the next iteration of the loop, starting with the evalua-<br/>
tion of any test which controls whether the loop should continue to be executed.<br/>For example, to ignore empty elements of an array you can write code like this:<br/>
<hr/>
<a name=286></a><b>266</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
foreach my $datum (@data) {<br/>
next unless $datum;<br/>
process($datum);<br/>
}<br/>
redo also returns to the start of the loop block, but does not execute any test or<br/>iteration code. Suppose you were prompting the user for ten pieces of data, none of<br/>which could be blank. You could write code like this:<br/>
foreach my $input (1 .. 10) {<br/>
print &#34;\n$input&gt; &#34;;<br/>
$_; = &lt;STDIN&gt;;<br/>
redo unless $_'<br/>
}<br/>
last immediately exits the loop and continues execution on the statement follow-<br/>ing the end of the loop. If you were processing data, but wanted to stop when you<br/>reached a number that was negative, you could write code like this:<br/>
foreach my $datum (@data) {<br/>
last if $datum &lt; 0;<br/>
process($datum);<br/>
}<br/>
All of these keywords act on the innermost enclosing loop by default. If this isn’t what<br/>you want then you can put a label in front of the loop keyword (for, foreach, or<br/>while) and refer to it in the next, redo, or last command. For example, if you were<br/>processing lines and words from a document, you could write something like this:<br/>
LINE:<br/>
foreach my $line (getlines()) {<br/>
WORD:<br/>
foreach $word (getwords($line)) {<br/>
last WORD if $word eq 'next';<br/>
last LINE if $word eq 'end';<br/>
process($word);<br/>
}<br/>
}<br/>
<i><b>B.5</b></i><br/>
<i><b>Subroutines</b></i><br/>
Subroutines are defined using the keyword sub like this:<br/>
sub gollum {<br/>
print &#34;We hatesss it forever!\n&#34;;<br/>
}<br/>
and are called like this:<br/>
<hr/>
<a name=287></a><i><b>Subroutines</b></i><br/>
<b>267</b><br/>
&amp;gollum;<br/>
or like this<br/>
gollum();<br/>
or (if the definition of the subroutine has already been seen by the compiler) like this:<br/>
gollum;<br/>
Within a subroutine, the parameters are available in the special array @_. These<br/>parameters are passed by reference, so changing this array will alter the values of the<br/>variables in the calling code.4 To simulate parameter passing by value, it is usual to<br/>assign the parameters to local variables within the subroutine like this:<br/>
sub example {<br/>
my ($arg1, $arg2, $arg4) = @_;<br/>
# Do stuff with $arg1, $arg2 and $arg3<br/>
}<br/>
Any arrays or hashes that are passed into subroutines this way are flattened into one<br/>array. Therefore if you try to write code like this:<br/>
# Subroutine to print one element of an array<br/>
# N.B. This code doesn't work.<br/>
sub element {<br/>
my (@arr, $x) = @_;<br/>
print $arr[$x];<br/>
}<br/>
my @array = (1 .. 10);<br/>
element(@array, 4);<br/>
it won’t work because, within the subroutine, the assignment to @arr doesn’t know<br/>when to stop pulling elements from @_ and will, therefore, take all of @_, leaving<br/>nothing to go into $x which therefore ends up containing the undef value.<br/>
If you were to pass the parameters the other way round like this:<br/>
# Subroutine to print one element of an array<br/>
# N.B. Better than the previous version.<br/>
sub element {<br/>
my ($x, @arr) = @_;<br/>
print $arr[$x];<br/>
}<br/>
my @array = (1 .. 10);<br/>
element(4, @array);<br/>
4 This isn’t strictly true, but it’s true enough to be a reasonable working hypothesis. For the full gory details<br/>
see perldoc perlsub.<br/>
<hr/>
<a name=288></a><b>268</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
it would work, as the assignment to $x would pull one element off of @_ leaving the<br/>rest to go into @arr. An even better way, however, is to use references, as we’ll see later.<br/>
A subroutine returns the value of the last statement that it executes, although<br/>
you can also use the return function to explicitly return a value from any point in<br/>the subroutine. The return value can be a scalar or a list. Perl even supplies a func-<br/>tion called wantarray which tells you whether your subroutine was called in scalar<br/>or array context so that you can adjust your return value accordingly.<br/>
More information about creating and calling subroutines can be found in the<br/>
perlsub manual page.<br/>
<i><b>B.6</b></i><br/>
<i><b>References</b></i><br/>
References are the key to building complex data structures in Perl and, as such, are<br/>very important for data munging. They work somewhat like pointers in languages<br/>like C, but are more useful. They know, for example, the type of the object that they<br/>are pointing at. A reference is a scalar value and can, therefore, be stored in a stan-<br/>dard scalar variable.<br/>
<i><b>B.6.1</b></i><br/>
<i><b>Creating references</b></i><br/>
You can create a reference to a variable in Perl by putting a backslash character (\)<br/>in front of the variable name. For example:<br/>
$scalar = 'A scalar';<br/>
@array = ('An', 'Array');<br/>
%hash = (type =&gt; 'Hash);<br/>
$scalar_ref = \$scalar;<br/>
$array_ref = \@array;<br/>
$hash_ref = \%hash;<br/>
Sometimes you’d like a reference to an array or a hash, but you don’t wish to go to<br/>the bother of creating a variable. In these cases, you can create an <i>anonymous</i> array<br/>or hash like this:<br/>
$array_ref = ['An', 'Array'];<br/>
$hash_ref = {type =&gt; 'Hash'};<br/>
The references created in this manner are no different than the ones created from<br/>variables, and can be dereferenced in exactly the same ways.<br/>
<hr/>
<a name=289></a><i><b>References</b></i><br/>
<b>269</b><br/>
<i><b>B.6.2</b></i><br/>
<i><b>Using references</b></i><br/>
To get back to the original object that the scalar points at, you simply put the<br/>object’s type specifier character (i.e., $, @, or %) in front of the variable holding the<br/>reference. For example:<br/>
$orig_scalar = $$scalar_ref;<br/>
@orig_array = @$array_ref;<br/>
%orig_hash = %$hash_ref;<br/>
If you have a reference to an array or a hash, you can access the contained elements<br/>using the dereferencing operator (-&gt;). For example:<br/>
$array_element = $array_ref-&gt;[1];<br/>
$hash_element = $hash_ref-&gt;{type};<br/>
To find out what type of object a reference refers to, you can use the ref function.<br/>This function returns a string containing the name of the object type. For example:<br/>
print ref $scalar_ref; # prints 'SCALAR'<br/>
print ref $array_ref;<br/>
# prints 'ARRAY'<br/>
print ref $hash_ref;<br/>
# prints 'HASH'<br/>
<i><b>B.6.3</b></i><br/>
<i><b>References to subroutines</b></i><br/>
You can also take references to subroutines. The syntax is exactly equivalent for<br/>other object types. Remember that the type specifier character for a subroutine is &amp;.<br/>You can therefore do things like this:<br/>
sub my_sub {<br/>
print &#34;I am a subroutine&#34;;<br/>
}<br/>
$sub_ref = \&amp;my_sub;<br/>
&amp;$sub_ref;<br/>
# executes &amp;my_sub<br/>
$sub_ref-&gt;(); # another way to execute my_sub (allowing parameter passing)<br/>
You can use this to create references to anonymous subroutines (i.e., subroutines<br/>without names) like this:<br/>
$sub_ref = sub { print &#34;I'm an anonymous subroutine&#34; };<br/>
Now the only way to execute this subroutine is via the reference.<br/>
<i><b>B.6.4</b></i><br/>
<i><b>Complex data structures using references</b></i><br/>
I said at the start of this section that references were the key to creating complex<br/>data structures in Perl. Let’s take a look at why this is.<br/>
Recall that each element of an array or a hash can only contain scalar values. If<br/>
you tried to create a two-dimensional array with code like this:<br/>
<hr/>
<a name=290></a><b>270</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
# NOTE: This code doesn't work<br/>
@array_2d = ((1, 2, 3), (4, 5, 6), (7, ,8, 9));<br/>
the arrays would all be flattened and you would end up with a one-dimensional<br/>array containing the numbers from one to nine. However, with references we now<br/>have a way to refer to an array using a value which will fit into a scalar variable. We<br/>can, therefore, do something like this:<br/>
@arr1 = (1, 2, 3);<br/>
@arr2 = (4, 5, 6);<br/>
@arr3 = (7, 8, 9);<br/>
@array_2d = (\@arr1, \@arr2, \@arr3);<br/>
or (without the need for intermediate array variables):<br/>
@array_2d = ([1, 2, 3],<br/>
[4, 5, 6],<br/>
[7, 8, 9]);<br/>
Of course, having put our data into a two-dimensional array,5 we need to know<br/>how we get the data back out again. It should be possible to work this out, given<br/>what we already know about arrays and references.<br/>
Suppose we want to access the central element of our 2-D array (the number 5).<br/>
Actually, our array isn’t a 2-D array at all, it is really an array which contains refer-<br/>ences to arrays in its elements. The element $array_2d[1] contains a reference to<br/>an anonymous array which contains the numbers 4, 5, and 6. One way to do it<br/>would, therefore, be to use an intermediate variable like this:<br/>
$row = $array_2d[1];<br/>
@row_arr = @$row;<br/>
$element = $row_arr[1];<br/>
While this will work, Perl gives us ways to write the same thing more efficiently. In<br/>particular, the notation for accessing an object given a reference to it has some<br/>extensions to it. Where previously we have seen syntax like @$arr_ref give us the<br/>array referred to by $arr_ref, there is a more general syntax which looks like:<br/>
@{block}<br/>
in which <i>block</i> is any piece of Perl code that returns a reference to an array (the same<br/>is true, incidentally, of hashes). In our case, we can, therefore, use this to our advan-<br/>tage and use<br/>
@{$array_2d[1]}<br/>
5 Or, at least, something that simulates one rather well.<br/>
<hr/>
<a name=291></a><i><b>References</b></i><br/>
<b>271</b><br/>
to get back the required array. As this is now the array in which we are interested, we<br/>can use standard array syntax to get back our required element, that is we replace the<br/>@ with a $ and put the required index in [ .. ] on the end. Our required element is<br/>therefore given by the expression:<br/>
${$array_2d[1]}[1]<br/>
That does the job, but it looks a bit ugly and, if there were more than one level of<br/>indirection, it would just get worse. Surely there’s another way? Remember when<br/>we were accessing elements of an array using the $arr_ref-&gt;[0] syntax? We can<br/>make use of that. We said that $array_2d[1] gives us a reference to the array that<br/>we need. We can, therefore, use the -&gt; syntax to access the individual elements of<br/>that array. The element that we want is given by:<br/>
$array_2d[1]-&gt;[1];<br/>
which is much simpler. There is one further simplification that we can make. Because<br/>the only way to have multi-dimensional data structures like these is to use references,<br/>Perl knows that any multilevel accesses must involve references. Perl therefore<br/>assumes that there must be a deferencing arrow (-&gt;) between any two successive sets<br/>of array or hash brackets and, if there isn’t one there, it acts as though it were there<br/>anyway. This means that we can further simplify our expression to:<br/>
$array_2d[1][1];<br/>
This makes our structure look a lot like a traditional two-dimensional array in a lan-<br/>guage like C or BASIC.<br/>
In all of the examples of complex data structures we have used arrays that contain<br/>
references to arrays; but it’s just as simple to use arrays that contain hash references,<br/>hashes that contain hash references, or hashes that contain array references (or,<br/>indeed, any even more complex structures). Here are a few examples:<br/>
@hobbits = ({ fname =&gt; 'bilbo',<br/>
lname =&gt; 'baggins' },<br/>
{ fname =&gt; 'frodo',<br/>
lname =&gt; 'baggins' },<br/>
{ fname =&gt; 'Sam',<br/>
lname =&gt; 'Gamgee' });<br/>
foreach (@hobbits) {<br/>
print $_-&gt;{fname}, &#34;\n&#34;;<br/>
}<br/>
%races = ( hobbits =&gt; [ 'Bilbo', 'Frodo', 'Sam'],<br/>
men =&gt; ['Aragorn', 'Boromir', 'Theoden'],<br/>
elves =&gt; ['Elrond', 'Galadriel', 'Legolas'],<br/>
wizards =&gt; ['Gandalf', 'Saruman', 'Radagast'] );<br/>
foreach (keys %races) {<br/>
<hr/>
<a name=292></a><b>272</b><br/>
APPENDIX <br/>
<i><b>Essential Perl</b></i><br/>
print &#34;Here are some $_\n&#34;;<br/>
print &#34;@{$races{$_}}\n\n&#34;;<br/>
}<br/>
<i><b>B.6.5</b></i><br/>
<i><b>More information on references and complex data structures</b></i><br/>
The manual page perlref contains a complete guide to references, but it can<br/>sometimes be a little terse for a beginner. The perlreftut manual page is a kinder,<br/>gentler introduction to references.<br/>
The perllol manual page contains an introduction to using Perl for the pur-<br/>
pose of creating multi-dimensional arrays (or lists of lists—hence the name). The<br/>perldsc manual page is the data structures cookbook and contains information<br/>about building other kinds of data structures. It comes complete with a substantial<br/>number of detailed examples of creating and using such structures.<br/>
<i><b>B.7</b></i><br/>
<i><b>More information on Perl</b></i><br/>
Chapter 12 contains details of other places to obtain useful information about Perl.<br/>In general the best place to start is with the manual pages which come with your<br/>distribution of Perl. Typing perldoc perl on your command line will give you an<br/>overview of the various manual pages supplied and should help you decide which<br/>one to read for more detailed information.<br/>
<hr/>
<a name=293></a><i>index</i><br/>
Symbols <br/>
<a href="dmps.html#282">&lt; operator 262</a><br/>
<a href="dmps.html#182">Aho 162</a><br/>
<a href="dmps.html#282">&lt;= operator 262</a><br/>
<a href="dmps.html#178">alt attribute 158</a><br/>
<a href="dmps.html#82">- operator 62, 261</a><br/>
<a href="dmps.html#60">&lt;=&gt; operator 40, 262</a><br/>
<a href="dmps.html#82">alternate matches 62</a><br/>
<a href="dmps.html#281">-- operator 261</a><br/>
<a href="dmps.html#55">&lt;&gt; operator 35, 84</a><br/>
<a href="dmps.html#81">alternate phrases 61</a><br/>
<a href="dmps.html#282">!= operator 262</a><br/>
<a href="dmps.html#282">== operator 262</a><br/>
<a href="dmps.html#84">anchoring matches 64</a><br/>
<a href="dmps.html#74">$ 54, 102, 126</a><br/>
<a href="dmps.html#87">=~ operator 67</a><br/>
<a href="dmps.html#282">and operator 262</a><br/>
<a href="dmps.html#84">anchoring matches 64, 68</a><br/>
<a href="dmps.html#282">&gt; operator 262</a><br/>
<a href="dmps.html#103">anonymous array 83</a><br/>
<a href="dmps.html#81">metacharacter 61</a><br/>
<a href="dmps.html#282">&gt;= operator 262</a><br/>
<a href="dmps.html#143">Apache 123, 124</a><br/>
<a href="dmps.html#122">$&#34; 102, 103, 109</a><a href="dmps.html#129">, 126</a><br/>
<a href="dmps.html#81">? metacharacter 61, 63, 64</a><br/>
<a href="dmps.html#67">API 47</a><br/>
<a href="dmps.html#87">$&amp; 67</a><br/>
<a href="dmps.html#234">@item array 214</a><br/>
Apple Macintosh<br/>
<a href="dmps.html#122">$, 102, 103</a><br/>
<a href="dmps.html#81">\ 61</a><br/>
<a href="dmps.html#108">carriage return 88</a><br/>
<a href="dmps.html#120">$. 100</a><br/>
<a href="dmps.html#88">\A 68</a><br/>
<a href="dmps.html#42">arrays 22, 257</a><br/>
<a href="dmps.html#75">$/ 55, 126</a><br/>
<a href="dmps.html#84">\B 64</a><br/>
<a href="dmps.html#279">(see also hashes)</a><br/>
<a href="dmps.html#122">controlling output 102</a><br/>
<a href="dmps.html#84">\b 64</a><br/>
<a href="dmps.html#102">array of arrays 82, 85</a><br/>
<a href="dmps.html#105">reading data 85, 97</a><br/>
<a href="dmps.html#82">\D 62</a><br/>
<a href="dmps.html#43">array of hashes 23, 1</a><a href="dmps.html#158">38</a><br/>
<a href="dmps.html#104">record separator 84, 98, 1</a><a href="dmps.html#131">11</a><br/>
<a href="dmps.html#82">\d 62</a><br/>
<a href="dmps.html#280">array slice 260</a><br/>
<a href="dmps.html#133">special values 113</a><br/>
<a href="dmps.html#82">\S 62</a><br/>
<a href="dmps.html#123">array variable 103</a><br/>
<a href="dmps.html#235">$::RD_AUTOACTION 215</a><br/>
<a href="dmps.html#82">\s 62</a><br/>
<a href="dmps.html#279">associative arrays 259</a><br/>
<a href="dmps.html#240">$::RD_HINT 220</a><br/>
<a href="dmps.html#82">\W 62</a><br/>
<a href="dmps.html#87">context 67, 97, </a><a href="dmps.html#117">115</a><br/>
<a href="dmps.html#240">$::RD_TRACE 220</a><br/>
<a href="dmps.html#82">\w 62, 64</a><br/>
<a href="dmps.html#103">example 83, 86</a><br/>
<a href="dmps.html#85">$_ 65, 99, 104, 113, 180</a><br/>
<a href="dmps.html#88">\Z 68</a><br/>
<a href="dmps.html#277">examples of assignment 257</a><br/>
<a href="dmps.html#125">$| 105</a><br/>
<a href="dmps.html#81">^ metacharacter 61, 64, 68</a><br/>
<a href="dmps.html#42">flexibility 22</a><br/>
<a href="dmps.html#87">$‘ 67</a><br/>
<a href="dmps.html#283">^ operator 263</a><br/>
<a href="dmps.html#64">lookup 44</a><br/>
<a href="dmps.html#87">$’ 67</a><br/>
<a href="dmps.html#84">{n,m} 64</a><br/>
<a href="dmps.html#289">reference 269</a><br/>
<a href="dmps.html#83">$1 63, 65, 66, 67</a><a href="dmps.html#87">, 71</a><br/>
<a href="dmps.html#81">| metacharacter 61, 62</a><br/>
<a href="dmps.html#136">slice 116</a><br/>
<a href="dmps.html#60">$a 40, 41</a><br/>
<a href="dmps.html#283">| operator 263</a><br/>
<a href="dmps.html#102">vs. hashes 82</a><br/>
<a href="dmps.html#60">$b 40, 41</a><br/>
<a href="dmps.html#61">|| operator 41, 107, 26</a><a href="dmps.html#282">2</a><br/>
<a href="dmps.html#278">vs. lists 258</a><br/>
<a href="dmps.html#200">%_ 180</a><br/>
<a href="dmps.html#63">||= 43</a><br/>
<a href="dmps.html#280">arrow operator 260</a><br/>
<a href="dmps.html#283">&amp; 263</a><br/>
<a href="dmps.html#283">~ operator 263</a><br/>
<a href="dmps.html#230">article 210</a><br/>
<a href="dmps.html#282">&amp;&amp; operator 262</a><br/>
<a href="dmps.html#29">ASCII 9, 82, 13</a><a href="dmps.html#150">0</a><br/>
<a href="dmps.html#81">* operator 61, 63</a><a href="dmps.html#83">, 64, 261</a><br/>
A<br/>
<a href="dmps.html#159">binary 139</a><br/>
<a href="dmps.html#281">** operator 261</a><br/>
<a href="dmps.html#159">character set description 139</a><br/>
<a href="dmps.html#81">+ metacharacter 61, 63, 64</a><br/>
<a href="dmps.html#74">-a command line option 54</a><br/>
<a href="dmps.html#107">converting to EBCDIC 87</a><br/>
<a href="dmps.html#281">+ operator 261</a><br/>
<a href="dmps.html#163">Aas, Gisle 143</a><br/>
<a href="dmps.html#107">data conversion 87</a><br/>
<a href="dmps.html#281">++ operator 261</a><br/>
<a href="dmps.html#50">access method 30</a><br/>
<a href="dmps.html#155">template options 135</a><br/>
<a href="dmps.html#81">. operator 61, 261</a><br/>
<a href="dmps.html#36">ActivePerl 16, 164</a><br/>
<a href="dmps.html#107">ascii2ebcdic 87</a><br/>
<a href="dmps.html#86">/ operator 66, 261</a><br/>
<a href="dmps.html#36">ActiveState 16, 164</a><br/>
<a href="dmps.html#108">example 88</a><br/>
<i>273</i><br/>
<hr/>
<a name=294></a><b>274</b><br/>
INDEX<br/>
assign <a href="dmps.html#78">58</a><br/>
reading data chunks <a href="dmps.html#160">140</a><br/>
Christiansen, Tom <a href="dmps.html#37">17 </a><a href="dmps.html#75">55 </a><a href="dmps.html#275">255</a><br/>
attributes <a href="dmps.html#44">24 </a><a href="dmps.html#50">30</a><br/>
reading the signature <a href="dmps.html#160">140</a><br/>
chunk data <a href="dmps.html#162">142</a><br/>
AutoCommit <a href="dmps.html#256">236</a><br/>
working with, <a href="dmps.html#159">139</a>±<a href="dmps.html#164">144</a><br/>
chunk footer <a href="dmps.html#162">142</a><br/>
Chopblanks <a href="dmps.html#255">235</a><br/>
binding operator <a href="dmps.html#87">67</a><br/>
closelog <a href="dmps.html#57">37</a><br/>
<a href="dmps.html#259">DECIMAL_DIGITS</a><br/>
binmode <a href="dmps.html#161">141</a><br/>
cmp <a href="dmps.html#61">41 </a><a href="dmps.html#282">262</a><br/>
<a href="dmps.html#259">239, 2</a><a href="dmps.html#260">40</a><br/>
bitwise <a href="dmps.html#283">263</a><br/>
COBOL <a href="dmps.html#148">128</a><br/>
<a href="dmps.html#259">DECIMAL_FILL 239, 240</a><br/>
bless <a href="dmps.html#208">188</a><br/>
code <a href="dmps.html#46">26</a><br/>
<a href="dmps.html#259">DECIMAL_POINT 239, 24</a><a href="dmps.html#260">0</a><br/>
block of Perl <a href="dmps.html#60">40</a><br/>
reuse <a href="dmps.html#36">16</a><br/>
<a href="dmps.html#254">errstr 234</a><br/>
body <a href="dmps.html#25">5 </a><a href="dmps.html#238">218 </a><a href="dmps.html#241">221</a><br/>
colon <a href="dmps.html#84">64 </a><a href="dmps.html#94">74</a><br/>
<a href="dmps.html#259">INT_CURR_SYMBOL</a><br/>
Bowie, David <a href="dmps.html#26">6</a><br/>
data separated by <a href="dmps.html#93">73</a><br/>
<a href="dmps.html#259">239, 2</a><a href="dmps.html#260">40</a><br/>
Bragg, Billy <a href="dmps.html#26">6</a><br/>
column widths <a href="dmps.html#153">133</a><br/>
<a href="dmps.html#254">Kids 234</a><br/>
Bunce, Tim <a href="dmps.html#67">47 </a><a href="dmps.html#75">55</a><br/>
command line options <a href="dmps.html#73">53</a><br/>
<a href="dmps.html#259">KILO_SUFFIX 239, 240</a><br/>
business rules <a href="dmps.html#46">26 </a><a href="dmps.html#49">29 </a><a href="dmps.html#58">38</a><br/>
-a <a href="dmps.html#74">54</a><br/>
<a href="dmps.html#255">LongReadLen 235</a><br/>
encapsulation methods <a href="dmps.html#45">25 </a><a href="dmps.html#46">26</a><br/>
-c <a href="dmps.html#276">256</a><br/>
<a href="dmps.html#255">LongTruncOk 235</a><br/>
reason to encapsulate <a href="dmps.html#46">26</a><br/>
-d <a href="dmps.html#276">256</a><br/>
<a href="dmps.html#259">MEGA_SUFFIX 239, 240</a><br/>
-e <a href="dmps.html#73">53</a><br/>
<a href="dmps.html#259">MON_DECIMAL_POINT</a><br/>
-F <a href="dmps.html#74">54</a><br/>
C<br/>
<a href="dmps.html#259">239, 2</a><a href="dmps.html#260">40</a><br/>
-i <a href="dmps.html#74">54</a><br/>
<a href="dmps.html#259">MON_THOUSANDS_SEP</a><br/>
-M <a href="dmps.html#73">53</a><br/>
C <a href="dmps.html#34">14 </a><a href="dmps.html#35">15 </a><a href="dmps.html#36">16 </a><a href="dmps.html#37">17</a><br/>
<a href="dmps.html#259">239, 2</a><a href="dmps.html#260">40</a><br/>
-n <a href="dmps.html#73">53 </a><a href="dmps.html#74">54</a><br/>
-c command line option <a href="dmps.html#276">256</a><br/>
<a href="dmps.html#258">NAME 238</a><br/>
-p <a href="dmps.html#74">54</a><br/>
C++ <a href="dmps.html#36">16</a><br/>
<a href="dmps.html#259">NEG_FORMAT 239, 240</a><br/>
-T <a href="dmps.html#276">256</a><br/>
caching data<br/>
<a href="dmps.html#258">NULLABLE 238</a><br/>
-w <a href="dmps.html#276">256</a><br/>
currency conversion <a href="dmps.html#126">106</a><br/>
<a href="dmps.html#258">NUM_OF_FIELDS 238</a><br/>
command line scripts <a href="dmps.html#73">53 </a><a href="dmps.html#76">56</a><br/>
Memoize.pm <a href="dmps.html#127">107</a><br/>
<a href="dmps.html#254">PrintError 234</a><br/>
<a href="dmps.html#128">comma-separated files (</a><i>see </i>CSV)<br/>
capturing <a href="dmps.html#83">63 </a><a href="dmps.html#86">66</a><br/>
RaiseError <a href="dmps.html#254">234</a><br/>
comp.lang.perl.misc <a href="dmps.html#63">43</a><br/>
caret <a href="dmps.html#84">64</a><br/>
statement handle <a href="dmps.html#258">238</a><br/>
compiled <a href="dmps.html#36">16</a><br/>
carriage return <a href="dmps.html#82">62 </a><a href="dmps.html#108">88</a><br/>
<a href="dmps.html#258">THOUSANDS_SEP 238, </a><br/>
<i>Compilers: Principles, Techniques </i><br/>
case transformations <a href="dmps.html#80">60</a><br/>
<a href="dmps.html#259">239, 2</a><a href="dmps.html#260">40</a><br/>
<i>and Tools </i><a href="dmps.html#182">162</a><br/>
CD example <a href="dmps.html#24">4 </a><a href="dmps.html#25">5</a><br/>
complex data files <a href="dmps.html#170">150</a><br/>
<a href="dmps.html#258">TYPE 238</a><br/>
adding subrecords <a href="dmps.html#171">151</a><br/>
g modifier <a href="dmps.html#176">156</a><br/>
warn <a href="dmps.html#254">234</a><br/>
complex data files <a href="dmps.html#170">150</a><br/>
HTML <a href="dmps.html#174">154</a><br/>
audit log <a href="dmps.html#56">36 </a><a href="dmps.html#58">38</a><br/>
complex records <a href="dmps.html#131">111±</a><a href="dmps.html#133">113</a><br/>
metadata <a href="dmps.html#171">151</a><br/>
audit trail <a href="dmps.html#56">36 </a><a href="dmps.html#57">37</a><br/>
creating a template <a href="dmps.html#173">153</a><br/>
subrecords <a href="dmps.html#171">151</a><br/>
awk <a href="dmps.html#81">61</a><br/>
data parsing <a href="dmps.html#26">6</a><br/>
XML <a href="dmps.html#174">154</a><br/>
data structure <a href="dmps.html#40">20 </a><a href="dmps.html#43">23±</a><a href="dmps.html#45">25</a><br/>
complex data records<br/>
B<br/>
Data::Dumper <a href="dmps.html#69">49</a><br/>
expanded CD file <a href="dmps.html#172">152</a><br/>
grammar <a href="dmps.html#238">218 </a><a href="dmps.html#239">219</a><br/>
reading, example <a href="dmps.html#172">152</a><br/>
backslash <a href="dmps.html#82">62</a><br/>
hash <a href="dmps.html#41">21 </a><a href="dmps.html#42">22</a><br/>
complex data structures<br/>
bare block <a href="dmps.html#105">85</a><br/>
parsing <a href="dmps.html#237">217</a><br/>
<a href="dmps.html#288">268 </a><a href="dmps.html#292">272</a><br/>
bash <a href="dmps.html#96">76</a><br/>
printing lists <a href="dmps.html#123">103</a>±<a href="dmps.html#124">104</a><br/>
using references <a href="dmps.html#289">269</a><br/>
benchmarking <a href="dmps.html#71">51 </a><a href="dmps.html#72">52 </a><a href="dmps.html#76">56</a><br/>
Schwartzian transform <a href="dmps.html#63">43</a><br/>
complex sorts <a href="dmps.html#61">41</a><br/>
<a href="dmps.html#96">76 </a><a href="dmps.html#142">122</a><br/>
CD-ROM <a href="dmps.html#29">9</a><br/>
Comprehensive Perl Archive <br/>
Benchmark.pm <a href="dmps.html#75">55</a><br/>
censor <a href="dmps.html#97">77</a><br/>
Network <a href="dmps.html#36">16</a><br/>
Bentley, Jon <a href="dmps.html#58">38</a><br/>
census <a href="dmps.html#24">4</a><br/>
computer science <a href="dmps.html#80">60</a><br/>
binary data <a href="dmps.html#34">14 </a><a href="dmps.html#37">17 </a><a href="dmps.html#102">82 </a><a href="dmps.html#170">150</a><br/>
chain extension <a href="dmps.html#55">35</a><br/>
concatenate <a href="dmps.html#71">51 </a><a href="dmps.html#281">261</a><br/>
and $ ⁄ <a href="dmps.html#134">114</a><br/>
channels <a href="dmps.html#214">194</a><br/>
conditional execution <a href="dmps.html#283">263</a><br/>
binmode <a href="dmps.html#161">141</a><br/>
Chapman, Nigel <a href="dmps.html#37">17 </a><a href="dmps.html#275">255</a><br/>
connection string <a href="dmps.html#68">48</a><br/>
definition <a href="dmps.html#33">13</a><br/>
character classes <a href="dmps.html#81">61 </a><a href="dmps.html#82">62 </a><a href="dmps.html#103">83</a><br/>
<a href="dmps.html#108">consonants 62</a><br/>
file formats <a href="dmps.html#159">139</a><br/>
checksum <a href="dmps.html#162">142</a><br/>
<a href="dmps.html#108">context 5</a><br/>
line endings <a href="dmps.html#108">88</a><br/>
China <a href="dmps.html#107">87</a><br/>
control character <a href="dmps.html#109">89</a><br/>
PNG file <a href="dmps.html#160">140</a><br/>
chomp <a href="dmps.html#118">98 </a><a href="dmps.html#119">99 </a><a href="dmps.html#132">112</a><br/>
control of input <a href="dmps.html#104">84</a><br/>
<hr/>
<a name=295></a>INDEX<br/>
<b>275</b><br/>
Convert::EBCDIC <a href="dmps.html#107">87</a><br/>
data conversion <a href="dmps.html#107">87</a><br/>
examples of use, <a href="dmps.html#43">23</a><br/>
example <a href="dmps.html#108">88</a><br/>
ASCII <a href="dmps.html#107">87</a><br/>
munging processes <a href="dmps.html#39">19 </a><a href="dmps.html#42">22</a><br/>
Convert::SciEng <a href="dmps.html#111">91 </a><a href="dmps.html#112">92 </a><a href="dmps.html#114">94</a><br/>
ASCII and EBCDIC <a href="dmps.html#107">87</a><br/>
Parse::RecDescent <a href="dmps.html#238">218</a><br/>
converting number formats <a href="dmps.html#110">90</a><br/>
binary data <a href="dmps.html#108">88</a><br/>
parsing <a href="dmps.html#26">6</a><br/>
converting the character set <a href="dmps.html#107">87</a><br/>
converting the character <br/>
read example <a href="dmps.html#94">74</a><br/>
Conway, Damian <a href="dmps.html#48">28 </a><a href="dmps.html#58">38</a><br/>
set <a href="dmps.html#107">87</a><br/>
reading <a href="dmps.html#102">82</a><br/>
<a href="dmps.html#230">210 </a><a href="dmps.html#244">224</a><br/>
EBCDIC <a href="dmps.html#107">87</a><br/>
simple hash <a href="dmps.html#41">21</a><br/>
cool-talk <a href="dmps.html#96">76</a><br/>
line endings <a href="dmps.html#108">88</a><br/>
transformation <a href="dmps.html#104">84</a><br/>
CPAN <a href="dmps.html#36">16</a><br/>
multibyte characters <a href="dmps.html#107">87</a><br/>
Data::Dumper <a href="dmps.html#69">49 </a><a href="dmps.html#76">56 </a><a href="dmps.html#242">222</a><br/>
ASCII to EBCDIC <br/>
number format <a href="dmps.html#110">90</a><br/>
data_munger <a href="dmps.html#53">33 </a><a href="dmps.html#54">34 </a><a href="dmps.html#55">35</a><br/>
module <a href="dmps.html#107">87</a><br/>
reformatting numbers <a href="dmps.html#111">91</a><br/>
data_reader <a href="dmps.html#53">33 </a><a href="dmps.html#54">34</a><br/>
binary files <a href="dmps.html#163">143</a><br/>
sprintf <a href="dmps.html#111">91</a><br/>
data_writer <a href="dmps.html#53">33 </a><a href="dmps.html#54">34</a><br/>
date modules <a href="dmps.html#140">120 </a><a href="dmps.html#146">126</a><br/>
data file <a href="dmps.html#29">9 </a><a href="dmps.html#149">129</a><br/>
database<br/>
HTML parser <a href="dmps.html#185">165</a><br/>
corruption check <a href="dmps.html#171">151</a><br/>
and CSV <a href="dmps.html#128">108</a><br/>
libwww <a href="dmps.html#184">164</a><br/>
footer <a href="dmps.html#171">151</a><br/>
as a datasource <a href="dmps.html#30">10 </a><a href="dmps.html#67">47</a><br/>
Logfile <a href="dmps.html#144">124</a><br/>
header <a href="dmps.html#170">150</a><br/>
auditing <a href="dmps.html#56">36</a><br/>
Memoize.pm <a href="dmps.html#127">107</a><br/>
parts of <a href="dmps.html#170">150</a><br/>
caching data <a href="dmps.html#126">106</a><br/>
MP3 data <a href="dmps.html#164">144 </a><a href="dmps.html#165">145</a><br/>
sections <a href="dmps.html#238">218</a><br/>
combining data <a href="dmps.html#39">19</a><br/>
parser module <a href="dmps.html#194">174</a><br/>
data filtering <a href="dmps.html#26">6</a><br/>
communicating with <a href="dmps.html#31">11</a><br/>
POD <a href="dmps.html#217">197</a><br/>
data munging <a href="dmps.html#24">4 </a><a href="dmps.html#29">9 </a><a href="dmps.html#37">17</a><br/>
connecting <a href="dmps.html#68">48</a><br/>
reformatting numbers <a href="dmps.html#111">91</a><br/>
and data structures <a href="dmps.html#40">20</a><br/>
data source <a href="dmps.html#29">9</a><br/>
Text::Bastardize module <a href="dmps.html#96">76</a><br/>
audit trail <a href="dmps.html#57">37</a><br/>
design <a href="dmps.html#27">7</a><br/>
Text::CSV_XS <a href="dmps.html#129">109</a><br/>
business rules <a href="dmps.html#45">25</a><br/>
read example <a href="dmps.html#69">49</a><br/>
top-down parsers <a href="dmps.html#230">210</a><br/>
command line scripts <a href="dmps.html#73">53</a><br/>
<a href="dmps.html#67">database driver (<i>se</i></a><i>e </i>DBD)<br/>
XML parser <a href="dmps.html#198">178 </a><a href="dmps.html#228">208</a><br/>
examples <a href="dmps.html#28">8</a><br/>
database handle <a href="dmps.html#69">49</a><br/>
XML parsers <a href="dmps.html#211">191</a><br/>
filter model <a href="dmps.html#53">33</a><br/>
<a href="dmps.html#67">Database Interface (</a><i>see </i>DBI)<br/>
CSV <a href="dmps.html#128">108</a><br/>
importance <a href="dmps.html#27">7</a><br/>
database schema <a href="dmps.html#30">10</a><br/>
anatomy <a href="dmps.html#128">108</a><br/>
processes <a href="dmps.html#39">19 </a><a href="dmps.html#42">22</a><br/>
date<br/>
data records <a href="dmps.html#128">108</a><br/>
producing output <a href="dmps.html#43">23</a><br/>
Date::Calc <a href="dmps.html#140">120</a><br/>
generic read/write <br/>
record-oriented data <a href="dmps.html#118">98</a><br/>
daylight savings time <a href="dmps.html#135">115</a><br/>
routine <a href="dmps.html#130">110</a><br/>
simple hash <a href="dmps.html#41">21</a><br/>
fields <a href="dmps.html#134">114</a><br/>
Text::CSV_XS <a href="dmps.html#129">109</a><br/>
sources of data <a href="dmps.html#32">12</a><br/>
formatting <a href="dmps.html#138">118</a><br/>
currency conversion<br/>
tasks <a href="dmps.html#93">73</a><br/>
functions <a href="dmps.html#134">114</a><br/>
memoize <a href="dmps.html#127">107</a><br/>
things to know <a href="dmps.html#249">229±</a><a href="dmps.html#251">231</a><br/>
international formats <a href="dmps.html#140">120</a><br/>
customer object <a href="dmps.html#49">29</a><br/>
usefulness <a href="dmps.html#248">228</a><br/>
manipulation <a href="dmps.html#137">117 </a><a href="dmps.html#140">120 </a><a href="dmps.html#141">121</a><br/>
Customer.pm <a href="dmps.html#49">29 </a><a href="dmps.html#50">30</a><br/>
data munging beast <a href="dmps.html#21">1</a><br/>
manipulation examples <a href="dmps.html#137">117</a><br/>
Customer_Rules.pm <a href="dmps.html#47">27 </a><a href="dmps.html#48">28</a><br/>
data parsing <a href="dmps.html#26">6</a><br/>
<a href="dmps.html#138">118 </a><a href="dmps.html#141">121</a><br/>
building parsers <a href="dmps.html#229">209</a><br/>
previous Saturday <a href="dmps.html#141">121</a><br/>
D<br/>
complex data formats <a href="dmps.html#167">147</a><br/>
date modules<br/>
HTML <a href="dmps.html#183">163</a><br/>
benchmarking <a href="dmps.html#142">122</a><br/>
-d command line option <a href="dmps.html#276">256</a><br/>
XML <a href="dmps.html#195">175</a><br/>
choosing <a href="dmps.html#142">122</a><br/>
d00dz <a href="dmps.html#96">76</a><br/>
data pipes <a href="dmps.html#29">9 </a><a href="dmps.html#31">11</a><br/>
Date::Calc <a href="dmps.html#146">126</a><br/>
dash <a href="dmps.html#82">62</a><br/>
data processing <a href="dmps.html#27">7</a><br/>
functions <a href="dmps.html#260">240</a><br/>
data<br/>
data recognition <a href="dmps.html#25">5 </a><a href="dmps.html#26">6 </a><a href="dmps.html#36">16</a><br/>
Date::Manip <a href="dmps.html#141">121 </a><a href="dmps.html#146">126</a><br/>
CSV records <a href="dmps.html#129">109</a><br/>
data record <a href="dmps.html#24">4</a><br/>
functions <a href="dmps.html#262">242</a><br/>
exchange <a href="dmps.html#196">176</a><br/>
complex structure <a href="dmps.html#130">110</a><br/>
daylight savings time <a href="dmps.html#135">115</a><br/>
field <a href="dmps.html#24">4</a><br/>
data sink <a href="dmps.html#29">9</a><br/>
DBD <a href="dmps.html#67">47 </a><a href="dmps.html#69">49 </a><a href="dmps.html#75">55</a><br/>
fields <a href="dmps.html#129">109</a><br/>
data source <a href="dmps.html#29">9 </a><a href="dmps.html#39">19</a><br/>
DBD::mysql <a href="dmps.html#68">48</a><br/>
formats <a href="dmps.html#32">12±</a><a href="dmps.html#34">14</a><br/>
data structure<br/>
DBI <a href="dmps.html#31">11 </a><a href="dmps.html#75">55</a><br/>
reading chunks <a href="dmps.html#160">140</a><br/>
building <a href="dmps.html#236">216 </a><a href="dmps.html#237">217</a><br/>
assigning attributes <a href="dmps.html#254">234</a><br/>
transformation <a href="dmps.html#26">6</a><br/>
Data::Dumper <a href="dmps.html#71">51</a><br/>
connect function <a href="dmps.html#67">47</a><br/>
types of, <a href="dmps.html#276">256</a><br/>
designing <a href="dmps.html#40">20 </a><a href="dmps.html#45">25 </a><a href="dmps.html#58">38</a><br/>
functions <a href="dmps.html#104">48 233 235</a><br/>
<hr/>
<a name=296></a><b>276</b><br/>
INDEX<br/>
DBI (continued)<br/>
elsif <a href="dmps.html#284">264</a><br/>
encode field structures <a href="dmps.html#155">135</a><br/>
handle <a href="dmps.html#254">234</a><br/>
emacs <a href="dmps.html#102">82</a><br/>
end-of-record, example <a href="dmps.html#152">132</a><br/>
handle attributes <a href="dmps.html#256">236</a><br/>
email header <a href="dmps.html#84">64</a><br/>
end-of-record marker <a href="dmps.html#152">132</a><br/>
prepare function <a href="dmps.html#69">49</a><br/>
encapsulate <a href="dmps.html#58">38</a><br/>
extracting fields, example<br/>
sample program <a href="dmps.html#68">48</a><br/>
business rules <a href="dmps.html#45">25</a><br/>
<a href="dmps.html#149">129 </a><a href="dmps.html#150">130</a><br/>
DBM <a href="dmps.html#30">10</a><br/>
encryption <a href="dmps.html#97">77</a><br/>
multiple record types<br/>
Debug style <a href="dmps.html#201">181</a><br/>
end <a href="dmps.html#84">64</a><br/>
<a href="dmps.html#151">131 </a><a href="dmps.html#153">133</a><br/>
debugging <a href="dmps.html#69">49</a><br/>
end-of-record marker <a href="dmps.html#152">132</a><br/>
pack <a href="dmps.html#155">135</a><br/>
decimal places <a href="dmps.html#111">91 </a><a href="dmps.html#156">136</a><br/>
English <a href="dmps.html#34">14</a><br/>
printf <a href="dmps.html#156">136</a><br/>
decoupling <a href="dmps.html#39">19 </a><a href="dmps.html#40">20 </a><a href="dmps.html#42">22</a><br/>
epoch <a href="dmps.html#134">114 </a><a href="dmps.html#136">116</a><br/>
reading <a href="dmps.html#148">128</a><br/>
defining record structure <a href="dmps.html#153">133</a><br/>
eq operator <a href="dmps.html#282">262</a><br/>
record description <a href="dmps.html#148">128</a><br/>
field-end markers <a href="dmps.html#154">134</a><br/>
equity research <a href="dmps.html#28">8</a><br/>
record padding <a href="dmps.html#148">128</a><br/>
fixed-width numbers <a href="dmps.html#153">133</a><br/>
escape sequences <a href="dmps.html#82">62</a><br/>
sprintf <a href="dmps.html#156">136</a><br/>
delimited data <a href="dmps.html#121">101</a><br/>
eval <a href="dmps.html#90">70 </a><a href="dmps.html#201">181</a><br/>
sprintf, example <a href="dmps.html#157">137</a><br/>
delimiters <a href="dmps.html#86">66</a><br/>
exchange rates <a href="dmps.html#126">106</a><br/>
template <a href="dmps.html#150">130 </a><a href="dmps.html#151">131</a><br/>
Descartes, Alligator <a href="dmps.html#75">55</a><br/>
Expat <a href="dmps.html#198">178</a><br/>
writing <a href="dmps.html#155">135</a><br/>
digit <a href="dmps.html#82">62</a><br/>
exponential notation <a href="dmps.html#110">90</a><br/>
fixing <a href="dmps.html#111">91</a><br/>
DOCTYPE <a href="dmps.html#214">194</a><br/>
<a href="dmps.html#33">Extensible Mark-up Language </a><br/>
floating point numbers <a href="dmps.html#156">136</a><br/>
<a href="dmps.html#211">Document Object Model </a><br/>
<a href="dmps.html#33">(<i>se</i></a><i>e </i>XML)<br/>
floating points <a href="dmps.html#110">90</a><br/>
<a href="dmps.html#211">(<i>se</i></a><i>e </i>DOM)<br/>
extra data <a href="dmps.html#132">112</a><br/>
floppy disk <a href="dmps.html#29">9</a><br/>
<a href="dmps.html#196">Document Type Definitions </a><br/>
flushed <a href="dmps.html#125">105</a><br/>
<a href="dmps.html#196">(<i>se</i></a><i>e </i>DTD)<br/>
F<br/>
footer <a href="dmps.html#25">5 </a><a href="dmps.html#238">218 </a><a href="dmps.html#241">221</a><br/>
dollar sign <a href="dmps.html#84">64</a><br/>
foreach <a href="dmps.html#133">113</a><br/>
DOM <a href="dmps.html#211">191</a><br/>
-F command line option <a href="dmps.html#74">54</a><br/>
form feed <a href="dmps.html#82">62</a><br/>
domain specific constraints <a href="dmps.html#45">25</a><br/>
fatal exception <a href="dmps.html#201">181</a><br/>
format description <a href="dmps.html#156">136</a><br/>
Dominus, Mark-Jason <a href="dmps.html#127">107</a><br/>
fetchrow_array <a href="dmps.html#69">49</a><br/>
format specifier <a href="dmps.html#157">137</a><br/>
<a href="dmps.html#248">228 </a><a href="dmps.html#249">229</a><br/>
field separator <a href="dmps.html#132">112</a><br/>
format_bytes<br/>
DOS <a href="dmps.html#102">82</a><br/>
field-end markers <a href="dmps.html#154">134</a><br/>
example <a href="dmps.html#113">93</a><br/>
binary/text files <a href="dmps.html#161">141</a><br/>
fields <a href="dmps.html#123">103 </a><a href="dmps.html#132">112</a><br/>
format_negative<br/>
carriage return/line feed <a href="dmps.html#108">88</a><br/>
extracting <a href="dmps.html#120">100 </a><a href="dmps.html#150">130</a><br/>
example <a href="dmps.html#113">93 </a><a href="dmps.html#114">94</a><br/>
dot character <a href="dmps.html#82">62</a><br/>
web access log <a href="dmps.html#143">123</a><br/>
format_number<br/>
double quotes <a href="dmps.html#124">104</a><br/>
file handle <a href="dmps.html#120">100</a><br/>
example <a href="dmps.html#113">93</a><br/>
DTD<br/>
no end-of-record marker <a href="dmps.html#152">132</a><br/>
format_picture<br/>
setting handlers <a href="dmps.html#209">189</a><br/>
output <a href="dmps.html#124">104 </a><a href="dmps.html#125">105</a><br/>
example <a href="dmps.html#113">93</a><br/>
specialized parsers <a href="dmps.html#213">193</a><br/>
reading data <a href="dmps.html#117">97</a><br/>
free beer <a href="dmps.html#35">15</a><br/>
valid documents <a href="dmps.html#197">178</a><br/>
writing fixed-width data <a href="dmps.html#156">136</a><br/>
Free Software Foundation <a href="dmps.html#35">15</a><br/>
dump <a href="dmps.html#192">172</a><br/>
file input operator <a href="dmps.html#117">97 </a><a href="dmps.html#118">98 </a><a href="dmps.html#119">99</a><br/>
free speech <a href="dmps.html#35">15</a><br/>
Dumper <a href="dmps.html#70">50 </a><a href="dmps.html#71">51</a><br/>
file open <a href="dmps.html#35">15</a><br/>
Friedl, Jeffrey <a href="dmps.html#98">78</a><br/>
file pointer <a href="dmps.html#152">132</a><br/>
FTP <a href="dmps.html#29">9</a><br/>
E<br/>
file transfer methods <a href="dmps.html#29">9</a><br/>
fun <a href="dmps.html#37">17</a><br/>
<a href="dmps.html#29">File Transfer Protocol (<i>se</i></a><i>e </i>FTP)<br/>
functions <a href="dmps.html#46">26</a><br/>
-e command line option <a href="dmps.html#73">53</a><br/>
file transfers <a href="dmps.html#30">10</a><br/>
Add_Delta_Days <a href="dmps.html#261">242</a><br/>
e modifier <a href="dmps.html#90">70 </a><a href="dmps.html#92">72</a><br/>
filename <a href="dmps.html#56">36</a><br/>
available_drivers <a href="dmps.html#253">233</a><br/>
EBCDIC<br/>
filtering <a href="dmps.html#24">4 </a><a href="dmps.html#37">17</a><br/>
bind_col <a href="dmps.html#257">237</a><br/>
coverting to ASCII <a href="dmps.html#107">87</a><br/>
filter model <a href="dmps.html#31">11 </a><a href="dmps.html#52">32 </a><a href="dmps.html#55">35</a><br/>
bind_columns <a href="dmps.html#258">238</a><br/>
data conversion <a href="dmps.html#107">87</a><br/>
line end conversion <a href="dmps.html#109">89</a><br/>
bind_param <a href="dmps.html#256">236</a><br/>
ebcdic2ascii <a href="dmps.html#107">87</a><br/>
financial models <a href="dmps.html#28">8</a><br/>
bind_param_inout <a href="dmps.html#256">236</a><br/>
Eckstein, Robert <a href="dmps.html#196">177</a><br/>
finite state machine <a href="dmps.html#180">160</a><br/>
called from DBI <a href="dmps.html#253">233</a><br/>
<i>Effective Perl Programming </i><a href="dmps.html#75">55</a><br/>
fixed-width data <a href="dmps.html#121">101 </a><a href="dmps.html#148">128±</a><a href="dmps.html#159">139</a><br/>
called via statement <br/>
<i>Elements of Programming with </i><br/>
data item <a href="dmps.html#148">128</a><br/>
handle <a href="dmps.html#256">236</a><br/>
<i>Perl </i><a href="dmps.html#37">17 </a><a href="dmps.html#275">255</a><br/>
defining record structure <a href="dmps.html#153">133</a><br/>
check_date <a href="dmps.html#261">241</a><br/>
<hr/>
<a name=297></a>INDEX<br/>
<b>277</b><br/>
<a href="dmps.html#46">functions (continued)</a><br/>
parse <a href="dmps.html#265">245</a><br/>
syntax errors <a href="dmps.html#240">220</a><br/>
chomp <a href="dmps.html#118">98 </a><a href="dmps.html#119">99 </a><a href="dmps.html#132">112</a><br/>
parse_file <a href="dmps.html#265">245</a><br/>
Windows INI <a href="dmps.html#233">213</a><br/>
commit <a href="dmps.html#256">236</a><br/>
ParseDate <a href="dmps.html#142">122 </a><a href="dmps.html#143">123</a><br/>
graphics files <a href="dmps.html#159">139</a><br/>
connect <a href="dmps.html#68">48 </a><a href="dmps.html#253">233</a><br/>
ParseDateString <a href="dmps.html#262">242</a><br/>
<a href="dmps.html#159">Graphics Interchange Format </a><br/>
data_sources <a href="dmps.html#253">233</a><br/>
ParseDelta <a href="dmps.html#263">243</a><br/>
<a href="dmps.html#159">(<i>se</i></a><i>e </i>GIF)<br/>
Date_Cmp <a href="dmps.html#263">243</a><br/>
ParseRecur <a href="dmps.html#263">243</a><br/>
graphs <a href="dmps.html#27">7</a><br/>
Date_DayOfWeek <a href="dmps.html#264">244</a><br/>
prepare <a href="dmps.html#69">49</a><br/>
greedy, definition <a href="dmps.html#176">156</a><br/>
Date_DayOfYear <a href="dmps.html#264">244</a><br/>
print <a href="dmps.html#123">103 </a><a href="dmps.html#135">115</a><br/>
grep <a href="dmps.html#81">61</a><br/>
Date_DaysInMonth <a href="dmps.html#264">244</a><br/>
printf <a href="dmps.html#155">135</a><br/>
group <a href="dmps.html#83">63</a><br/>
Date_DaysInYear <a href="dmps.html#264">244</a><br/>
read <a href="dmps.html#152">132</a><br/>
group of characters <a href="dmps.html#81">61</a><br/>
Date_DaySuffix <a href="dmps.html#264">244</a><br/>
ref <a href="dmps.html#289">269</a><br/>
grouping <a href="dmps.html#83">63</a><br/>
Date_GetPrev <a href="dmps.html#263">243</a><br/>
return <a href="dmps.html#288">268</a><br/>
gt operator <a href="dmps.html#282">262</a><br/>
Date_LeapYear <a href="dmps.html#264">244</a><br/>
rollback <a href="dmps.html#256">236</a><br/>
Guttman, Uri <a href="dmps.html#66">46</a><br/>
Date_to_Text <a href="dmps.html#262">242</a><br/>
seek <a href="dmps.html#152">132</a><br/>
Guttman-Rosler transform <a href="dmps.html#66">46</a><br/>
DateCalc <a href="dmps.html#263">243</a><br/>
select <a href="dmps.html#124">104</a><br/>
Day_of_Week <a href="dmps.html#261">241</a><br/>
selectall_arrayref <a href="dmps.html#255">235</a><br/>
H<br/>
Day_of_Year <a href="dmps.html#261">241</a><br/>
selectrow_array <a href="dmps.html#255">235</a><br/>
Days_in_Month <a href="dmps.html#260">240</a><br/>
sprintf <a href="dmps.html#155">135 </a><a href="dmps.html#158">138</a><br/>
Hall, Joseph <a href="dmps.html#62">42 </a><a href="dmps.html#75">55</a><br/>
Days_in_Year <a href="dmps.html#260">240</a><br/>
strftime <a href="dmps.html#138">118</a><br/>
handler <a href="dmps.html#185">165</a><br/>
Decode_Month <a href="dmps.html#262">242</a><br/>
strict_comment <a href="dmps.html#265">245</a><br/>
Handlers <a href="dmps.html#209">189</a><br/>
Delta_Days <a href="dmps.html#261">241</a><br/>
strict_names <a href="dmps.html#266">246</a><br/>
hash <a href="dmps.html#42">22 </a><a href="dmps.html#106">86</a><br/>
Delta_DHMS <a href="dmps.html#261">241</a><br/>
substr <a href="dmps.html#149">129 </a><a href="dmps.html#152">132</a><br/>
hash lookup <a href="dmps.html#64">44</a><br/>
do <a href="dmps.html#255">235</a><br/>
System_Clock <a href="dmps.html#262">242</a><br/>
hashes <a href="dmps.html#279">259</a><br/>
each <a href="dmps.html#280">260</a><br/>
time <a href="dmps.html#136">116</a><br/>
accessing values <a href="dmps.html#280">260</a><br/>
Easter_Sunday <a href="dmps.html#262">242</a><br/>
timelocal <a href="dmps.html#136">116</a><br/>
errstr <a href="dmps.html#254">234</a><br/>
converting from a list <a href="dmps.html#281">261</a><br/>
trace <a href="dmps.html#254">234</a><br/>
execute <a href="dmps.html#257">237</a><br/>
hash slice <a href="dmps.html#280">260</a><br/>
UnixDate <a href="dmps.html#263">243</a><br/>
fetch <a href="dmps.html#257">237</a><br/>
reference <a href="dmps.html#289">269</a><br/>
unpack <a href="dmps.html#150">130 </a><a href="dmps.html#152">132 </a><a href="dmps.html#153">133 </a><a href="dmps.html#154">134</a><br/>
fetchall_arrayref <a href="dmps.html#257">237</a><br/>
syntax <a href="dmps.html#280">260</a><br/>
values <a href="dmps.html#280">260</a><br/>
fetchrow_array <a href="dmps.html#257">237</a><br/>
header <a href="dmps.html#24">4 </a><a href="dmps.html#238">218</a><br/>
Week_Number <a href="dmps.html#261">241</a><br/>
fetchrow_arrayref <a href="dmps.html#257">237</a><br/>
HTML tags <a href="dmps.html#191">171</a><br/>
xml_mode <a href="dmps.html#266">246</a><br/>
fetchrow_hashref <a href="dmps.html#257">237</a><br/>
processing <a href="dmps.html#25">5</a><br/>
finish <a href="dmps.html#257">237</a><br/>
processing, example of, <a href="dmps.html#173">153</a><br/>
get <a href="dmps.html#264">244</a><br/>
G<br/>
rule <a href="dmps.html#241">221</a><br/>
get_rate <a href="dmps.html#127">107</a><br/>
hierarchical <a href="dmps.html#37">17</a><br/>
getprint <a href="dmps.html#264">245</a><br/>
g modifier <a href="dmps.html#89">69 </a><a href="dmps.html#91">71 </a><a href="dmps.html#105">85 </a><a href="dmps.html#176">156</a><br/>
hierarchical data <a href="dmps.html#33">13</a><br/>
getstore <a href="dmps.html#265">245</a><br/>
gcc <a href="dmps.html#35">15</a><br/>
Hietaniemi, Jarkko <a href="dmps.html#75">55</a><br/>
gmtime <a href="dmps.html#135">115</a><br/>
ge operator <a href="dmps.html#282">262</a><br/>
Horatio <a href="dmps.html#78">58</a><br/>
handler <a href="dmps.html#266">246</a><br/>
general principles <a href="dmps.html#39">19</a><br/>
HTML <a href="dmps.html#32">12 </a><a href="dmps.html#33">13 </a><a href="dmps.html#193">173</a><br/>
head <a href="dmps.html#264">244</a><br/>
get <a href="dmps.html#184">164</a><br/>
converting from XML <a href="dmps.html#217">197</a><br/>
keys <a href="dmps.html#280">260</a><br/>
get_next_cust_no <a href="dmps.html#47">27</a><br/>
entities <a href="dmps.html#187">167</a><br/>
leap_year <a href="dmps.html#261">241</a><br/>
get_rate <a href="dmps.html#127">107</a><br/>
extracting &lt;h1&gt; elements <a href="dmps.html#189">169</a><br/>
localtime <a href="dmps.html#135">115 </a><a href="dmps.html#136">116</a><br/>
Getopt::Std <a href="dmps.html#223">203</a><br/>
extracting from the web <a href="dmps.html#184">164</a><br/>
map <a href="dmps.html#281">261</a><br/>
getprint <a href="dmps.html#184">164</a><br/>
listing header tags <a href="dmps.html#190">170</a><br/>
memoize <a href="dmps.html#127">107</a><br/>
getstore <a href="dmps.html#184">164 </a><a href="dmps.html#192">172</a><br/>
listing specific links <a href="dmps.html#188">168</a><br/>
mirror <a href="dmps.html#265">245</a><br/>
getting Perl <a href="dmps.html#35">15</a><br/>
parsing <a href="dmps.html#174">154</a><br/>
Monday_of_Week <a href="dmps.html#261">241</a><br/>
GIF <a href="dmps.html#159">139 </a><a href="dmps.html#163">143</a><br/>
parsing example <a href="dmps.html#185">165 </a><a href="dmps.html#191">171</a><br/>
new <a href="dmps.html#265">245</a><br/>
creating <a href="dmps.html#160">140</a><br/>
<a href="dmps.html#192">172</a><br/>
Nth_Weekday_of_Month_Year<br/>
gmtime <a href="dmps.html#135">115</a><br/>
parsing links <a href="dmps.html#188">168</a><br/>
<a href="dmps.html#261">241</a><br/>
GNU <a href="dmps.html#35">15</a><br/>
prebuilt parsers <a href="dmps.html#187">167</a><br/>
open <a href="dmps.html#117">97</a><br/>
grammar <a href="dmps.html#231">211 </a><a href="dmps.html#234">214 </a><a href="dmps.html#235">215</a><br/>
removing tags <a href="dmps.html#174">154 </a><a href="dmps.html#175">155</a><br/>
pack <a href="dmps.html#155">135</a><br/>
debugging <a href="dmps.html#240">220</a><br/>
tag <a href="dmps.html#185">165</a><br/>
<hr/>
<a name=298></a><b>278</b><br/>
INDEX<br/>
HTML (continued)<br/>
J<br/>
foreach <a href="dmps.html#285">265</a><br/>
tag attributes <a href="dmps.html#177">157</a><br/>
last <a href="dmps.html#285">265</a><br/>
testing the parser <a href="dmps.html#186">166</a><br/>
jaded <a href="dmps.html#37">17</a><br/>
next <a href="dmps.html#285">265</a><br/>
HTML::Element <a href="dmps.html#191">171 </a><a href="dmps.html#192">172</a><br/>
Japan <a href="dmps.html#107">87</a><br/>
redo <a href="dmps.html#285">265</a><br/>
HTML::LinkExtor <a href="dmps.html#187">167 </a><a href="dmps.html#188">168 </a><a href="dmps.html#189">169</a><br/>
Jargon File <a href="dmps.html#24">4</a><br/>
while <a href="dmps.html#285">265</a><br/>
functions <a href="dmps.html#267">247</a><br/>
Johnson, Andrew <a href="dmps.html#37">17 </a><a href="dmps.html#275">255</a><br/>
Lotus <a href="dmps.html#159">139</a><br/>
HTML::Parser <a href="dmps.html#174">154 </a><a href="dmps.html#181">161</a><br/>
JPG <a href="dmps.html#163">143</a><br/>
Loukides, Mike <a href="dmps.html#58">38</a><br/>
<a href="dmps.html#185">165 </a><a href="dmps.html#194">174</a><br/>
lower case <a href="dmps.html#80">60</a><br/>
functions <a href="dmps.html#265">245</a><br/>
K<br/>
lp <a href="dmps.html#95">75</a><br/>
handlers <a href="dmps.html#266">246</a><br/>
lvalue <a href="dmps.html#78">58</a><br/>
HTML::TokeParser <a href="dmps.html#189">169 </a><a href="dmps.html#193">173</a><br/>
k3wl <a href="dmps.html#96">76</a><br/>
LWP <a href="dmps.html#192">172 </a><a href="dmps.html#194">174</a><br/>
functions <a href="dmps.html#268">248</a><br/>
Kernigan, Brian <a href="dmps.html#58">38</a><br/>
getting HTML from the <br/>
HTML::TreeBuilder <a href="dmps.html#191">171</a><br/>
keyboard <a href="dmps.html#51">31</a><br/>
WWW <a href="dmps.html#184">164</a><br/>
functions <a href="dmps.html#269">249</a><br/>
mailing list <a href="dmps.html#194">174</a><br/>
HTTP <a href="dmps.html#32">12</a><br/>
L<br/>
LWP::Simple <a href="dmps.html#184">164 </a><a href="dmps.html#193">173</a><br/>
extracting data WWW <a href="dmps.html#184">164</a><br/>
functions <a href="dmps.html#264">244</a><br/>
hyperreductionist English <a href="dmps.html#96">76</a><br/>
label <a href="dmps.html#74">54</a><br/>
<a href="dmps.html#33">Hypertext Mark-up Language </a><br/>
lc <a href="dmps.html#80">60</a><br/>
M<br/>
<a href="dmps.html#33">(<i>se</i></a><i>e </i>HTML)<br/>
lcfirst <a href="dmps.html#80">60<br/></a>le operator <a href="dmps.html#282">262</a><br/>
-M command line option <a href="dmps.html#73">53</a><br/>
I<br/>
league table <a href="dmps.html#24">4</a><br/>
m modifier <a href="dmps.html#85">65 </a><a href="dmps.html#86">66 </a><a href="dmps.html#88">68 </a><a href="dmps.html#89">69</a><br/>
leaning toothpick syndrome <a href="dmps.html#86">66</a><br/>
m⁄⁄ <a href="dmps.html#85">65 </a><a href="dmps.html#98">78</a><br/>
-i <a href="dmps.html#74">54</a><br/>
<i>Learning Perl </i><a href="dmps.html#37">17 </a><a href="dmps.html#275">255</a><br/>
Macdonald, John <a href="dmps.html#75">55</a><br/>
-i command line option <a href="dmps.html#74">54</a><br/>
left align <a href="dmps.html#111">91</a><br/>
make <a href="dmps.html#35">15</a><br/>
i modifier <a href="dmps.html#88">68 </a><a href="dmps.html#89">69</a><br/>
lexer <a href="dmps.html#180">160</a><br/>
map <a href="dmps.html#64">44</a><br/>
I/O<br/>
lexical variable <a href="dmps.html#94">74</a><br/>
<i>Mastering Algorithms with </i><br/>
chaining <a href="dmps.html#55">35</a><br/>
<a href="dmps.html#184">Library for WWW Programming </a><br/>
<i>Perl </i><a href="dmps.html#75">55</a><br/>
independence <a href="dmps.html#53">33 </a><a href="dmps.html#58">38</a><br/>
<a href="dmps.html#184">(<i>se</i></a><i>e</i> LWP)<br/>
<i>Mastering Regular </i><br/>
pipes <a href="dmps.html#52">32</a><br/>
line end conversion <a href="dmps.html#109">89</a><br/>
<i>Expressions </i><a href="dmps.html#98">78</a><br/>
redirection <a href="dmps.html#51">31 </a><a href="dmps.html#52">32</a><br/>
line endings <a href="dmps.html#108">88</a><br/>
match modifiers <a href="dmps.html#85">65 </a><a href="dmps.html#88">68</a><br/>
IBM<br/>
line feed <a href="dmps.html#82">62 </a><a href="dmps.html#108">88</a><br/>
match operator <a href="dmps.html#88">68</a><br/>
data conversion <a href="dmps.html#107">87</a><br/>
linguistics <a href="dmps.html#34">14</a><br/>
matching alternatives <a href="dmps.html#82">62</a><br/>
if <a href="dmps.html#34">14 </a><a href="dmps.html#283">263 </a><a href="dmps.html#284">264</a><br/>
links, HTML <a href="dmps.html#187">167</a><br/>
memoize <a href="dmps.html#127">107</a><br/>
Image::Info <a href="dmps.html#163">143 </a><a href="dmps.html#165">145</a><br/>
Linux<br/>
Memoize.pm <a href="dmps.html#127">107</a><br/>
index <a href="dmps.html#98">78</a><br/>
line feed <a href="dmps.html#108">88</a><br/>
metacharacters <a href="dmps.html#81">61</a><br/>
Information Systems <a href="dmps.html#27">7</a><br/>
list<br/>
metadata <a href="dmps.html#153">133 </a><a href="dmps.html#155">135 </a><a href="dmps.html#170">150</a><br/>
Information Technology <a href="dmps.html#27">7</a><br/>
separator variable <a href="dmps.html#123">103</a><br/>
definition <a href="dmps.html#171">151</a><br/>
input <a href="dmps.html#39">19</a><br/>
vs. arrays <a href="dmps.html#278">258</a><br/>
methods<br/>
record separator <a href="dmps.html#75">55 </a><a href="dmps.html#122">102</a><br/>
list functions <a href="dmps.html#279">259</a><br/>
format_bytes <a href="dmps.html#260">240</a><br/>
record separator example<br/>
listing particular users <a href="dmps.html#96">76</a><br/>
format_negative <a href="dmps.html#260">240</a><br/>
<a href="dmps.html#131">111 </a><a href="dmps.html#133">113</a><br/>
listing users <a href="dmps.html#95">75</a><br/>
format_number <a href="dmps.html#259">239</a><br/>
record separator, reading <a href="dmps.html#117">97</a><br/>
load_products <a href="dmps.html#55">35</a><br/>
format_picture <a href="dmps.html#260">240</a><br/>
routine <a href="dmps.html#40">20</a><br/>
locale <a href="dmps.html#80">60</a><br/>
format_price <a href="dmps.html#260">240</a><br/>
integers <a href="dmps.html#110">90 </a><a href="dmps.html#156">136</a><br/>
localtime <a href="dmps.html#135">115 </a><a href="dmps.html#138">118 </a><a href="dmps.html#142">122</a><br/>
round <a href="dmps.html#259">239</a><br/>
international date formats <a href="dmps.html#140">120</a><br/>
Logfile <a href="dmps.html#144">124 </a><a href="dmps.html#145">125</a><br/>
unformat_number <a href="dmps.html#260">240</a><br/>
Internet <a href="dmps.html#32">12</a><br/>
logic <a href="dmps.html#45">25</a><br/>
Microsoft <a href="dmps.html#159">139</a><br/>
interpolate <a href="dmps.html#71">51</a><br/>
logical operators <a href="dmps.html#283">263</a><br/>
Access <a href="dmps.html#30">10</a><br/>
interpreted <a href="dmps.html#36">16</a><br/>
bitwise <a href="dmps.html#283">263</a><br/>
Excel <a href="dmps.html#159">139</a><br/>
interstices <a href="dmps.html#28">8 </a><a href="dmps.html#248">228</a><br/>
loops <a href="dmps.html#284">264</a><br/>
Windows <a href="dmps.html#51">31</a><br/>
IP addresses <a href="dmps.html#66">46</a><br/>
control of, <a href="dmps.html#285">265</a><br/>
Word <a href="dmps.html#81">61</a><br/>
is_valid_sales_ref <a href="dmps.html#48">28</a><br/>
for <a href="dmps.html#284">264</a><br/>
MIME <a href="dmps.html#29">9</a><br/>
<hr/>
<a name=299></a>INDEX<br/>
<b>279</b><br/>
modifiers <a href="dmps.html#91">71</a><br/>
metacharacter <a href="dmps.html#82">62</a><br/>
field separator <a href="dmps.html#122">102 </a><a href="dmps.html#123">103</a><br/>
g <a href="dmps.html#105">85</a><br/>
output records <a href="dmps.html#122">102</a><br/>
file handle <a href="dmps.html#125">105</a><br/>
m <a href="dmps.html#88">68</a><br/>
record-oriented data <a href="dmps.html#117">97</a><br/>
list separator <a href="dmps.html#122">102</a><br/>
o <a href="dmps.html#110">90</a><br/>
NFS <a href="dmps.html#29">9</a><br/>
record separator <a href="dmps.html#74">54 </a><a href="dmps.html#122">102</a><br/>
s <a href="dmps.html#88">68</a><br/>
node <a href="dmps.html#204">184</a><br/>
routine <a href="dmps.html#39">19 </a><a href="dmps.html#40">20</a><br/>
x <a href="dmps.html#88">68</a><br/>
noncolon <a href="dmps.html#84">64</a><br/>
modules<br/>
nondigit <a href="dmps.html#82">62</a><br/>
P<br/>
business rules <a href="dmps.html#46">26 </a><a href="dmps.html#47">27 </a><a href="dmps.html#58">38</a><br/>
nongreedy <a href="dmps.html#176">156</a><br/>
convert::SciEng <a href="dmps.html#111">91</a><br/>
nonspace character <a href="dmps.html#82">62</a><br/>
-p <a href="dmps.html#74">54</a><br/>
Data::Calc <a href="dmps.html#260">240</a><br/>
nonvowel <a href="dmps.html#82">62</a><br/>
-p command line option <a href="dmps.html#74">54</a><br/>
Date::Manip <a href="dmps.html#262">242</a><br/>
nonword character <a href="dmps.html#82">62</a><br/>
pack <a href="dmps.html#155">135 </a><a href="dmps.html#161">141 </a><a href="dmps.html#164">144</a><br/>
HTML:: Element <a href="dmps.html#269">249</a><br/>
normalization <a href="dmps.html#27">7</a><br/>
packed-default sort <a href="dmps.html#66">46</a><br/>
HTML::Element <a href="dmps.html#191">171</a><br/>
Notepad <a href="dmps.html#102">82</a><br/>
padding <a href="dmps.html#148">128</a><br/>
HTML::LinkExtor <a href="dmps.html#187">167 </a><a href="dmps.html#267">247</a><br/>
noun_phrase <a href="dmps.html#230">210</a><br/>
paragraph mode <a href="dmps.html#104">84 </a><a href="dmps.html#133">113</a><br/>
HTML::Parser <a href="dmps.html#174">154 </a><a href="dmps.html#267">247</a><br/>
Number::Format <a href="dmps.html#111">91 </a><a href="dmps.html#112">92 </a><a href="dmps.html#114">94</a><br/>
parameter passing <a href="dmps.html#287">267</a><br/>
HTML::TokeParser <a href="dmps.html#189">169 </a><a href="dmps.html#268">248</a><br/>
attributes <a href="dmps.html#258">238</a><br/>
parameters <a href="dmps.html#78">58</a><br/>
HTML::TreeBuilder <a href="dmps.html#191">171 </a><a href="dmps.html#269">249</a><br/>
example <a href="dmps.html#113">93 </a><a href="dmps.html#114">94</a><br/>
parentheses <a href="dmps.html#83">63 </a><a href="dmps.html#85">65</a><br/>
Image::Info <a href="dmps.html#163">143</a><br/>
methods <a href="dmps.html#259">239</a><br/>
parse tree <a href="dmps.html#192">172</a><br/>
LWP <a href="dmps.html#184">164</a><br/>
numerical abbreviations <a href="dmps.html#97">77</a><br/>
LWP::Simple <a href="dmps.html#184">164 </a><a href="dmps.html#264">244</a><br/>
Parse::RecDescent <a href="dmps.html#173">153 </a><a href="dmps.html#182">162</a><br/>
numerically <a href="dmps.html#60">40</a><br/>
MPEG::MP3Info <a href="dmps.html#164">144</a><br/>
<a href="dmps.html#230">210 </a><a href="dmps.html#236">216</a><br/>
Number::Format <a href="dmps.html#111">91 </a><a href="dmps.html#258">238</a><br/>
$::RD_AUTOACTION <a href="dmps.html#235">215</a><br/>
Parse::RecDescent <a href="dmps.html#173">153 </a><a href="dmps.html#182">162</a><br/>
O<br/>
$::RD_HINT <a href="dmps.html#240">220</a><br/>
Parse::Yapp <a href="dmps.html#182">162</a><br/>
$::RD_TRACE <a href="dmps.html#240">220</a><br/>
POSIX <a href="dmps.html#138">118</a><br/>
o modifier <a href="dmps.html#90">70 </a><a href="dmps.html#110">90</a><br/>
autotrees <a href="">223</a><br/>
Time::Local <a href="dmps.html#136">116</a><br/>
O’Reilly, Tim <a href="dmps.html#58">38</a><br/>
dynamic rules <a href="dmps.html#244">224</a><br/>
XML::DOM <a href="dmps.html#211">191</a><br/>
object <a href="dmps.html#46">26 </a><a href="dmps.html#58">38 </a><a href="dmps.html#230">210</a><br/>
error handling <a href="dmps.html#244">224</a><br/>
XML::Parser <a href="dmps.html#174">154 </a><a href="dmps.html#181">161</a><br/>
object class <a href="dmps.html#48">28</a><br/>
example <a href="dmps.html#237">217</a><br/>
<a href="dmps.html#198">178 </a><a href="dmps.html#270">250</a><br/>
<i>Object Oriented Perl </i><a href="dmps.html#48">28 </a><a href="dmps.html#58">38</a><br/>
incremental parsing <a href="dmps.html#244">224</a><br/>
monitor <a href="dmps.html#51">31</a><br/>
Object style<br/>
look-ahead rules <a href="">223</a><br/>
MP3 files <a href="dmps.html#163">143</a><br/>
vs. Tree <a href="dmps.html#208">188</a><br/>
precompiling parsers <a href="dmps.html#244">224</a><br/>
ID3 data <a href="dmps.html#164">144</a><br/>
<a href="dmps.html#48">object-oriented programming </a><br/>
subrule argument <a href="dmps.html#244">224</a><br/>
MPEG::MP3Info <a href="dmps.html#164">144 </a><a href="dmps.html#165">145</a><br/>
<a href="dmps.html#48">(<i>se</i></a><i>e </i>OOP)<br/>
Parse::Yapp <a href="dmps.html#182">162</a><br/>
multibyte characters <a href="dmps.html#107">87</a><br/>
objects <a href="dmps.html#58">38</a><br/>
parse_file <a href="dmps.html#185">165 </a><a href="dmps.html#192">172</a><br/>
multiple record types <a href="dmps.html#151">131</a><br/>
Objects style <a href="dmps.html#206">186</a><br/>
ParseDate <a href="dmps.html#142">122 </a><a href="dmps.html#143">123</a><br/>
munge <a href="dmps.html#24">4</a><br/>
OOP <a href="dmps.html#48">28</a><br/>
parsefile <a href="dmps.html#204">184 </a><a href="dmps.html#212">192 </a><a href="dmps.html#216">196</a><br/>
munging <a href="dmps.html#39">19</a><br/>
open function <a href="dmps.html#117">97</a><br/>
parser actions <a href="dmps.html#237">217</a><br/>
My Netscape <a href="dmps.html#213">193</a><br/>
Open Source <a href="dmps.html#160">140</a><br/>
parsers <a href="dmps.html#174">154</a><br/>
MySQL <a href="dmps.html#68">48</a><br/>
openlog <a href="dmps.html#57">37</a><br/>
adding actions <a href="dmps.html#240">220</a><br/>
operators <a href="dmps.html#104">84</a><br/>
building your own <a href="dmps.html#229">209</a><br/>
N<br/>
concatenation <a href="dmps.html#281">261</a><br/>
checking output <a href="dmps.html#242">222</a><br/>
logical <a href="dmps.html#282">262</a><br/>
HTML <a href="dmps.html#174">154</a><br/>
-n command line option <a href="dmps.html#73">53 </a><a href="dmps.html#74">54</a><br/>
mathematical <a href="dmps.html#281">261</a><br/>
HTML::Element <a href="dmps.html#191">171</a><br/>
Named Pipe <a href="dmps.html#31">11</a><br/>
string multiplication <a href="dmps.html#281">261</a><br/>
HTML::LinkExtor <a href="dmps.html#187">167</a><br/>
Nandor, Chris <a href="dmps.html#164">144 </a><a href="dmps.html#213">193</a><br/>
optional <a href="dmps.html#81">61</a><br/>
HTML::Parser <a href="dmps.html#185">165</a><br/>
natural code <a href="dmps.html#248">228</a><br/>
or operator <a href="dmps.html#282">262</a><br/>
HTML::TokeParser <a href="dmps.html#189">169</a><br/>
natural numbers <a href="dmps.html#110">90</a><br/>
Oracle <a href="dmps.html#30">10 </a><a href="dmps.html#67">47</a><br/>
HTML::TreeBuilder <a href="dmps.html#191">171</a><br/>
ne operator <a href="dmps.html#282">262</a><br/>
oraperl <a href="dmps.html#67">47</a><br/>
Parse::RecDescent <a href="dmps.html#173">153 </a><a href="dmps.html#230">210</a><br/>
<a href="dmps.html#29">Network File System (<i>se</i></a><i>e </i>NFS)<br/>
Orcish Manoeuvre <a href="dmps.html#62">42 </a><a href="dmps.html#75">55 </a><a href="dmps.html#127">107</a><br/>
Parse::Yapp <a href="dmps.html#182">162</a><br/>
newline character <a href="dmps.html#133">113 </a><a href="dmps.html#277">257</a><br/>
Orwant, Jon <a href="dmps.html#37">17 </a><a href="dmps.html#75">55</a><br/>
XML::DOM <a href="dmps.html#211">191</a><br/>
as field separator <a href="dmps.html#132">112</a><br/>
output <a href="dmps.html#39">19 </a><a href="dmps.html#51">31</a><br/>
XML::Parser <a href="dmps.html#198">178</a><br/>
input control <a href="dmps.html#104">84</a><br/>
buffer <a href="dmps.html#125">105</a><br/>
X<a href="dmps.html#29">ML::RSS 193</a><br/>
<hr/>
<a name=300></a><b>280</b><br/>
INDEX<br/>
parsing <a href="dmps.html#24">4 </a><a href="dmps.html#37">17</a><br/>
default variable <a href="dmps.html#119">99</a><br/>
Pike, Rob <a href="dmps.html#58">38</a><br/>
<a href="dmps.html#167">(<i>se</i></a><i>e also</i> data parsing)<br/>
end-of-record marker <a href="dmps.html#152">132</a><br/>
pipe separated files <a href="dmps.html#128">108</a><br/>
actions <a href="dmps.html#234">214</a><br/>
fixed-width data <a href="dmps.html#150">130</a><br/>
<a href="dmps.html#217">plain old documentation </a><br/>
bottom-up <a href="dmps.html#180">160</a><br/>
flow of control <a href="dmps.html#283">263</a><br/>
<a href="dmps.html#217">(<i>se</i></a><i>e </i> POD)<br/>
building a data structure <a href="dmps.html#236">216</a><br/>
getting HTML from the <br/>
plain text <a href="dmps.html#32">12 </a><a href="dmps.html#217">197</a><br/>
definition <a href="dmps.html#178">158</a><br/>
WWW <a href="dmps.html#184">164</a><br/>
PNG files <a href="dmps.html#160">140 </a><a href="dmps.html#163">143</a><br/>
example, simple English <br/>
handling dates <a href="dmps.html#134">114</a><br/>
IHDR chunk <a href="dmps.html#162">142</a><br/>
sentences <a href="dmps.html#230">210</a><br/>
HTML parsing <a href="dmps.html#177">157</a><br/>
reading <a href="dmps.html#160">140</a><br/>
failures <a href="dmps.html#200">180</a><br/>
idioms <a href="dmps.html#60">40</a><br/>
signature <a href="dmps.html#161">141</a><br/>
HTML <a href="dmps.html#177">157 </a><a href="dmps.html#178">158 </a><a href="dmps.html#185">165</a><br/>
input record separator <a href="dmps.html#132">112</a><br/>
testing the reader <a href="dmps.html#163">143</a><br/>
<a href="dmps.html#187"><i>s</i></a><i>ee also </i>+70/<br/>
international date formats <a href="dmps.html#140">120</a><br/>
POD <a href="dmps.html#217">197</a><br/>
HTML, example <a href="dmps.html#191">171</a><br/>
interpreter <a href="dmps.html#68">48 </a><a href="dmps.html#275">255 </a><a href="dmps.html#276">256</a><br/>
<a href="dmps.html#288">pointers (<i>se</i></a><i>e </i>references)<br/>
HTML, prebuilt parsers <a href="dmps.html#187">167</a><br/>
line ends <a href="dmps.html#109">89</a><br/>
pop <a href="dmps.html#279">259</a><br/>
jargon <a href="dmps.html#179">159</a><br/>
local time <a href="dmps.html#135">115</a><br/>
port number <a href="dmps.html#32">12</a><br/>
LL parser <a href="dmps.html#181">161</a><br/>
loops <a href="dmps.html#284">264</a><br/>
<a href="dmps.html#160">Portable Network Graphics </a><br/>
LR parser <a href="dmps.html#180">160</a><br/>
multibyte characters <a href="dmps.html#107">87</a><br/>
<a href="dmps.html#160">(<i>se</i></a><i>e </i>PNG files)<br/>
parser object, creating <a href="dmps.html#231">211</a><br/>
opening a file <a href="dmps.html#282">262</a><br/>
positive integers <a href="dmps.html#110">90</a><br/>
production <a href="dmps.html#179">159</a><br/>
operators <a href="dmps.html#281">261</a><br/>
positive lookahead <a href="dmps.html#85">65</a><br/>
regular expressions <a href="dmps.html#234">214</a><br/>
output file handles <a href="dmps.html#125">105</a><br/>
POSIX <a href="dmps.html#138">118</a><br/>
RSS file, example <a href="dmps.html#216">196</a><br/>
parsers <a href="dmps.html#181">161 </a><a href="dmps.html#182">162</a><br/>
POSIX::strftime <a href="dmps.html#140">120 </a><a href="dmps.html#146">126</a><br/>
structured data <a href="dmps.html#177">157</a><br/>
record-oriented data <a href="dmps.html#117">97 </a><a href="dmps.html#118">98</a><br/>
postfix <a href="dmps.html#111">91</a><br/>
subrules <a href="dmps.html#179">159</a><br/>
references <a href="dmps.html#288">268</a><br/>
prebuilt parsers <a href="dmps.html#181">161</a><br/>
terminal <a href="dmps.html#179">159</a><br/>
references and complex data <br/>
print <a href="dmps.html#78">58 </a><a href="dmps.html#135">115</a><br/>
testing for HTML <a href="dmps.html#186">166</a><br/>
structures <a href="dmps.html#289">269</a><br/>
lists of items <a href="dmps.html#123">103</a><br/>
tokens <a href="dmps.html#179">159</a><br/>
regular expressions <a href="dmps.html#81">61 </a><a href="dmps.html#85">65</a><br/>
record-oriented data <a href="dmps.html#122">102</a><br/>
top-down <a href="dmps.html#181">161</a><br/>
running <a href="dmps.html#275">255</a><br/>
to different file handles <a href="dmps.html#124">104</a><br/>
Windows INI <a href="dmps.html#232">212</a><br/>
sorting <a href="dmps.html#60">40</a><br/>
printf <a href="dmps.html#155">135 </a><a href="dmps.html#164">144</a><br/>
XML <a href="dmps.html#198">178 </a><a href="dmps.html#207">187 </a><a href="dmps.html#209">189</a><br/>
string handling <a href="dmps.html#78">58</a><br/>
producing different document <br/>
<a href="dmps.html#196"><i>se</i></a><i>e also </i>;0/<br/>
subroutines <a href="dmps.html#286">266</a><br/>
formats <a href="dmps.html#217">197</a><br/>
password <a href="dmps.html#68">48</a><br/>
production <a href="dmps.html#179">159</a><br/>
pattern matching <a href="">58 </a><a href="dmps.html#80">60</a><br/>
substrings <a href="dmps.html#79">59</a><br/>
program input <a href="dmps.html#51">31</a><br/>
payroll <a href="dmps.html#24">4 </a><a href="dmps.html#27">7</a><br/>
variables <a href="dmps.html#276">256</a><br/>
programmers <a href="dmps.html#37">17</a><br/>
Peek, Jerry <a href="dmps.html#58">38</a><br/>
web access logs <a href="dmps.html#144">124</a><br/>
<i>Programming Pearls </i><a href="dmps.html#58">38</a><br/>
performance <a href="dmps.html#96">76</a><br/>
why use <a href="dmps.html#248">228</a><br/>
<i>Programming Perl </i><a href="dmps.html#37">17</a><br/>
Perl <a href="dmps.html#28">8 </a><a href="dmps.html#34">14±</a><a href="dmps.html#36">16 </a><a href="dmps.html#37">17</a><br/>
writing objects <a href="dmps.html#58">38</a><br/>
<i>Programming the Perl DBI </i><a href="dmps.html#75">55</a><br/>
arrays <a href="dmps.html#102">82 </a><a href="dmps.html#149">129</a><br/>
writing separate records <a href="dmps.html#122">102</a><br/>
<i>Programming Web Graphics with </i><br/>
benchmarking date <br/>
XML parsers <a href="dmps.html#198">178</a><br/>
<i>Perl &amp; GNU Software </i><a href="dmps.html#160">140</a><br/>
modules <a href="dmps.html#142">122</a><br/>
Perl Mongers <a href="dmps.html#249">229</a><br/>
pronoun <a href="dmps.html#230">210</a><br/>
building parsers <a href="dmps.html#230">210</a><br/>
Perl Monks <a href="dmps.html#249">229</a><br/>
pseudocode <a href="dmps.html#39">19</a><br/>
command line options <a href="dmps.html#275">255 </a><a href="dmps.html#276">256</a><br/>
<i>Perl: The Programmer’s </i><br/>
punctuation <a href="dmps.html#82">62 </a><a href="dmps.html#86">66</a><br/>
command line scripts <a href="dmps.html#73">53</a><br/>
<i>Companion </i><a href="dmps.html#37">17 </a><a href="dmps.html#275">255</a><br/>
push <a href="dmps.html#279">259</a><br/>
community <a href="dmps.html#249">229</a><br/>
perldata <a href="dmps.html#281">261</a><br/>
complex data structures <a href="dmps.html#288">268</a><br/>
perldoc <a href="dmps.html#37">17 </a><a href="dmps.html#75">55</a><br/>
complex record structure <a href="dmps.html#131">111</a><br/>
perlfunc <a href="dmps.html#146">126 </a><a href="dmps.html#161">141 </a><a href="dmps.html#164">144</a><br/>
Q<br/>
conditional execution <a href="dmps.html#283">263</a><br/>
perlre <a href="dmps.html#81">61 </a><a href="dmps.html#97">77</a><br/>
data munging advantages <a href="dmps.html#36">16</a><br/>
perlrun <a href="dmps.html#276">256</a><br/>
quantifying matches <a href="dmps.html#83">63</a><br/>
data structure <a href="dmps.html#36">16</a><br/>
perlunicode <a href="dmps.html#114">94</a><br/>
Quicksort <a href="dmps.html#62">42</a><br/>
data types <a href="dmps.html#276">256</a><br/>
perlvar <a href="dmps.html#114">94 </a><a href="dmps.html#146">126</a><br/>
date and time manipulation <a href="dmps.html#137">117</a><br/>
perltoot <a href="dmps.html#48">28</a><br/>
R<br/>
daylight savings time <a href="dmps.html#135">115</a><br/>
phrase matching <a href="dmps.html#81">61</a><br/>
dealing with complex <br/>
phrases <a href="dmps.html#81">61</a><br/>
RDBMS <a href="dmps.html#30">10 </a><a href="dmps.html#31">11</a><br/>
records <a href="dmps.html#130">110</a><br/>
Pig Latin <a href="dmps.html#96">76</a><br/>
read <a href="dmps.html#152">132 </a><a href="dmps.html#164">144</a><br/>
<hr/>
<a name=301></a>INDEX<br/>
<b>281</b><br/>
reading /etc/passwd <a href="dmps.html#94">74</a><br/>
relational database management <br/>
slurp mode <a href="dmps.html#133">113</a><br/>
recognition <a href="dmps.html#24">4 </a><a href="dmps.html#37">17</a><br/>
system (<i>see </i><a href="dmps.html#30">RDBMS)</a><br/>
sorting <a href="dmps.html#60">40±</a><a href="dmps.html#67">47</a><br/>
recognizing numbers <a href="dmps.html#110">90</a><br/>
repeated <a href="dmps.html#81">61</a><br/>
and the Schwartzian <br/>
record <a href="dmps.html#121">101 </a><a href="dmps.html#123">103 </a><a href="dmps.html#130">110 </a><a href="dmps.html#173">153</a><br/>
replacement string <a href="dmps.html#90">70 </a><a href="dmps.html#91">71</a><br/>
transform <a href="dmps.html#65">45</a><br/>
record based <a href="dmps.html#93">73</a><br/>
requirements <a href="dmps.html#41">21</a><br/>
code <a href="dmps.html#64">44</a><br/>
record-oriented data <a href="dmps.html#33">13 </a><a href="dmps.html#37">17</a><br/>
<a href="dmps.html#213">rich site summary (<i>se</i></a><i>e </i>RSS)<br/>
Orcish Manoeuvre <a href="dmps.html#62">42</a><br/>
<a href="dmps.html#116">96</a>±<a href="dmps.html#146">126</a><br/>
right align <a href="dmps.html#111">91</a><br/>
packed-default <a href="dmps.html#66">46</a><br/>
caching <a href="dmps.html#125">105</a><br/>
root <a href="dmps.html#95">75</a><br/>
sort function <a href="dmps.html#60">40</a><br/>
CD data file <a href="dmps.html#117">97</a><br/>
Rosler, Larry <a href="dmps.html#66">46</a><br/>
sort key <a href="dmps.html#64">44</a><br/>
complex records <a href="dmps.html#130">110</a><br/>
rot13 <a href="dmps.html#97">77</a><br/>
source data <a href="dmps.html#25">5 </a><a href="dmps.html#37">17 </a><a href="dmps.html#56">36</a><br/>
CSV <a href="dmps.html#128">108 (</a><i>see also </i>CSV)<br/>
round <a href="dmps.html#113">93</a><br/>
space <a href="dmps.html#82">62 </a><a href="dmps.html#84">64</a><br/>
current record number <a href="dmps.html#120">100</a><br/>
example <a href="dmps.html#113">93</a><br/>
SPICE <a href="dmps.html#111">91</a><br/>
date fields <a href="dmps.html#134">114</a><br/>
RSS<br/>
splice <a href="dmps.html#205">185 </a><a href="dmps.html#279">259</a><br/>
different file handles <a href="dmps.html#124">104</a><br/>
creating with XML::RSS <a href="dmps.html#215">195</a><br/>
split <a href="dmps.html#103">83 </a><a href="dmps.html#121">101 </a><a href="dmps.html#132">112 </a><a href="dmps.html#133">113</a><br/>
extracting data fields <a href="dmps.html#120">100</a><br/>
definition <a href="dmps.html#213">193</a><br/>
spreadsheets <a href="dmps.html#27">7 </a><a href="dmps.html#128">108</a><br/>
print lists of items <a href="dmps.html#122">102</a><br/>
multiple channels <a href="dmps.html#214">194</a><br/>
sprintf <a href="dmps.html#71">51 </a><a href="dmps.html#112">92 </a><a href="dmps.html#155">135 </a><a href="dmps.html#158">138 </a><a href="dmps.html#164">144</a><br/>
processing simple <br/>
parsing <a href="dmps.html#216">196</a><br/>
SQL <a href="dmps.html#31">11 </a><a href="dmps.html#69">49</a><br/>
structures <a href="dmps.html#120">100</a><br/>
sample file <a href="dmps.html#213">193</a><br/>
square brackets <a href="dmps.html#82">62</a><br/>
reading <a href="dmps.html#117">97</a><br/>
rule matching <a href="dmps.html#235">215</a><br/>
squares <a href="dmps.html#90">70</a><br/>
reading a record at a time <a href="dmps.html#118">98</a><br/>
Standardized General Mark-up <br/>
splitting into fields <a href="dmps.html#122">102</a><br/>
Language (<i>see<a href="dmps.html#33"> </i>SGML)</a><br/>
S<br/>
web access logs <a href="dmps.html#143">123</a><br/>
start <a href="dmps.html#84">64</a><br/>
writing separate records <a href="dmps.html#122">102</a><br/>
statement modifiers <a href="dmps.html#284">264</a><br/>
s modifier <a href="dmps.html#88">68 </a><a href="dmps.html#89">69</a><br/>
statistics <a href="dmps.html#106">86</a><br/>
writing simple structures <a href="dmps.html#122">102</a><br/>
s/// <a href="dmps.html#89">69 </a><a href="dmps.html#98">78</a><br/>
STDOUT <a href="dmps.html#124">104 </a><a href="dmps.html#125">105</a><br/>
redirection <a href="dmps.html#51">31 </a><a href="dmps.html#52">32</a><br/>
save_cust_record <a href="dmps.html#47">27 </a><a href="dmps.html#48">28</a><br/>
Stream style <a href="dmps.html#201">181 </a><a href="dmps.html#202">182</a><br/>
references <a href="dmps.html#276">256 </a><a href="dmps.html#292">272</a><br/>
scalars <a href="dmps.html#135">115 </a><a href="dmps.html#276">256</a><br/>
stream-based <a href="dmps.html#202">182</a><br/>
complex data structures <a href="dmps.html#289">269</a><br/>
array element <a href="dmps.html#280">260</a><br/>
strftime <a href="dmps.html#138">118</a><br/>
creating <a href="dmps.html#288">268</a><br/>
context <a href="dmps.html#117">97</a><br/>
strings <a href="dmps.html#78">58 </a><a href="dmps.html#79">59 </a><a href="dmps.html#80">60</a><br/>
to subroutines <a href="dmps.html#289">269</a><br/>
variable <a href="dmps.html#104">84</a><br/>
finding within strings <a href="dmps.html#79">59</a><br/>
using <a href="dmps.html#289">269</a><br/>
Schwartz, Randal <a href="dmps.html#37">17 </a><a href="dmps.html#63">43 </a><a href="dmps.html#75">55 </a><a href="dmps.html#275">255</a><br/>
index <a href="dmps.html#79">59</a><br/>
reformatting numbers<br/>
Schwartzian transform <a href="dmps.html#63">43 </a><a href="dmps.html#65">45 </a><a href="dmps.html#75">55</a><br/>
matching <a href="dmps.html#85">65</a><br/>
CPAN modules <a href="dmps.html#111">91</a><br/>
variation <a href="dmps.html#66">46</a><br/>
replacement <a href="dmps.html#89">69</a><br/>
sprintf <a href="dmps.html#111">91</a><br/>
scope <a href="dmps.html#105">85</a><br/>
rindex <a href="dmps.html#79">59</a><br/>
regular expressions <a href="">58 </a><a href="dmps.html#80">60±</a><a href="dmps.html#97">77</a><br/>
sed <a href="dmps.html#81">61</a><br/>
structured data <a href="dmps.html#37">17 </a><a href="dmps.html#177">157</a><br/>
and $⁄ <a href="dmps.html#134">114</a><br/>
seek <a href="dmps.html#152">132</a><br/>
Structured Query Language <br/>
complex <a href="dmps.html#85">65</a><br/>
select <a href="dmps.html#124">104</a><br/>
(<i>see<a href="dmps.html#31"> </i>SQL)</a><br/>
definition <a href="dmps.html#80">60</a><br/>
sentence <a href="dmps.html#230">210 </a><a href="dmps.html#232">212</a><br/>
Style <a href="dmps.html#199">179</a><br/>
delimiter <a href="dmps.html#86">66</a><br/>
separated data <a href="dmps.html#121">101</a><br/>
sub <a href="dmps.html#286">266</a><br/>
extracting fixed-width <br/>
separating parsing <a href="dmps.html#42">22</a><br/>
subject <a href="dmps.html#230">210</a><br/>
data <a href="dmps.html#149">129</a><br/>
setHandlers <a href="dmps.html#209">189</a><br/>
subrecords <a href="dmps.html#171">151</a><br/>
greedy <a href="dmps.html#176">156</a><br/>
Sethi <a href="dmps.html#182">162</a><br/>
subroutines <a href="dmps.html#60">40</a><br/>
limitations <a href="dmps.html#177">157</a><br/>
setlogmask <a href="dmps.html#57">37</a><br/>
reference to <a href="dmps.html#289">269</a><br/>
matching numbers <a href="dmps.html#110">90</a><br/>
SGML <a href="dmps.html#33">13</a><br/>
subrules <a href="dmps.html#179">159</a><br/>
metacharacters <a href="dmps.html#81">61</a><br/>
shift <a href="dmps.html#205">185 </a><a href="dmps.html#279">259</a><br/>
optional, list of <a href="dmps.html#233">213</a><br/>
nongreedy <a href="dmps.html#176">156</a><br/>
short-circuiting <a href="dmps.html#61">41 </a><a href="dmps.html#127">107 </a><a href="dmps.html#283">263</a><br/>
repeating, list of <a href="dmps.html#233">213</a><br/>
parsing <a href="dmps.html#234">214</a><br/>
SI <a href="dmps.html#111">91</a><br/>
suffixes <a href="dmps.html#233">213</a><br/>
strings within strings <a href="dmps.html#80">60</a><br/>
signature <a href="dmps.html#160">140</a><br/>
Subs style <a href="dmps.html#202">182</a><br/>
syntax <a href="dmps.html#81">61</a><br/>
simple sorts <a href="dmps.html#60">40</a><br/>
substitution modifiers <a href="dmps.html#89">69</a><br/>
text replacement example <a href="dmps.html#105">85</a><br/>
sinks <a href="dmps.html#37">17 </a><a href="dmps.html#56">36</a><br/>
substr <a href="dmps.html#78">58 </a><a href="dmps.html#98">78 </a><a href="dmps.html#149">129 </a><a href="dmps.html#152">132</a><br/>
text transformation <a href="dmps.html#104">84</a><br/>
slash <a href="dmps.html#81">61</a><br/>
substrings <a href="dmps.html#78">58 </a><a href="dmps.html#79">59</a><br/>
using <a href="dmps.html#85">65</a><br/>
Slashdot <a href="dmps.html#213">193</a><br/>
succe<a href="dmps.html#164">ssor state 160</a><br/>
<hr/>
<a name=302></a><b>282</b><br/>
INDEX<br/>
Sybase <a href="dmps.html#67">47</a><br/>
formatting <a href="dmps.html#138">118</a><br/>
fortune <a href="dmps.html#131">111</a><br/>
Sybase Adaptive Server <br/>
functions <a href="dmps.html#134">114</a><br/>
I/O redirection character <br/>
Anywhere <a href="dmps.html#30">10</a><br/>
manipulation <a href="dmps.html#137">117 </a><a href="dmps.html#140">120 </a><a href="dmps.html#141">121</a><br/>
strings <a href="dmps.html#52">32</a><br/>
Sybase Adaptive Server <br/>
Time::Local <a href="dmps.html#136">116</a><br/>
line feed <a href="dmps.html#108">88</a><br/>
Enterprise <a href="dmps.html#30">10</a><br/>
timelocal <a href="dmps.html#136">116</a><br/>
POSIX <a href="dmps.html#138">118</a><br/>
sybperl <a href="dmps.html#67">47</a><br/>
timethese <a href="dmps.html#71">51 </a><a href="dmps.html#72">52</a><br/>
system logs <a href="dmps.html#57">37</a><br/>
syntactic sugar <a href="dmps.html#119">99</a><br/>
toascii <a href="dmps.html#107">87</a><br/>
tools <a href="dmps.html#81">61</a><br/>
synthetic code <a href="dmps.html#248">228</a><br/>
toebcdic <a href="dmps.html#107">87</a><br/>
using system logs <a href="dmps.html#57">37</a><br/>
Sys::Syslog <a href="dmps.html#57">37</a><br/>
tokens <a href="dmps.html#189">169</a><br/>
UNIX filter model <a href="dmps.html#55">35 </a><a href="dmps.html#58">38</a><br/>
syslog <a href="dmps.html#57">37</a><br/>
definition <a href="dmps.html#179">159</a><br/>
Schwartzian transform <a href="dmps.html#65">45</a><br/>
System <a href="dmps.html#262">242</a><br/>
Torkington, Nathan <a href="dmps.html#75">55</a><br/>
translations <a href="dmps.html#55">35 </a><a href="dmps.html#93">73</a><br/>
transaction-level locking <a href="dmps.html#47">27</a><br/>
<i>UNIX Power Tools </i><a href="dmps.html#58">38</a><br/>
T<br/>
transferring data <a href="dmps.html#27">7</a><br/>
unless <a href="dmps.html#34">14 </a><a href="dmps.html#284">264</a><br/>
transformation <a href="dmps.html#24">4 </a><a href="dmps.html#36">16 </a><a href="dmps.html#37">17</a><br/>
unpack <a href="dmps.html#164">144</a><br/>
-T command line option <a href="dmps.html#276">256</a><br/>
HTML output <a href="dmps.html#226">206</a><br/>
by column widths <a href="dmps.html#153">133</a><br/>
tab <a href="dmps.html#82">62 </a><a href="dmps.html#277">257</a><br/>
POD output <a href="dmps.html#225">205</a><br/>
example <a href="dmps.html#154">134 </a><a href="dmps.html#161">141 </a><a href="dmps.html#173">153</a><br/>
tab character <a href="dmps.html#123">103</a><br/>
text output <a href="dmps.html#227">207</a><br/>
fixed-width data <a href="dmps.html#150">130 </a><a href="dmps.html#151">131</a><br/>
tables <a href="dmps.html#27">7</a><br/>
XML <a href="dmps.html#218">198</a><br/>
no end-of-record marker <a href="dmps.html#152">132</a><br/>
tab-separated data <a href="dmps.html#121">101 </a><a href="dmps.html#128">108</a><br/>
transforming data <a href="dmps.html#56">36</a><br/>
unshift <a href="dmps.html#279">259</a><br/>
tag <a href="dmps.html#188">168</a><br/>
translate <a href="dmps.html#92">72</a><br/>
unstructured data <a href="dmps.html#32">12 </a><a href="dmps.html#37">17 </a><a href="dmps.html#102">82</a><br/>
tape <a href="dmps.html#29">9</a><br/>
translate_products <a href="dmps.html#55">35</a><br/>
upper case <a href="dmps.html#80">60</a><br/>
TCP/IP <a href="dmps.html#32">12</a><br/>
translating data <a href="dmps.html#105">85</a><br/>
use locale <a href="dmps.html#80">60</a><br/>
TCP/IP Socket <a href="dmps.html#32">12</a><br/>
caching <a href="dmps.html#125">105</a><br/>
username <a href="dmps.html#68">48</a><br/>
telephone book <a href="dmps.html#61">41</a><br/>
currency rates <a href="dmps.html#126">106</a><br/>
UTF-8 format <a href="dmps.html#107">87</a><br/>
templates <a href="dmps.html#150">130 </a><a href="dmps.html#151">131 </a><a href="dmps.html#155">135</a><br/>
English to American <a href="dmps.html#90">70</a><br/>
utf8 module <a href="dmps.html#107">87 </a><a href="dmps.html#114">94</a><br/>
terminals <a href="dmps.html#179">159 </a><a href="dmps.html#231">211</a><br/>
example <a href="dmps.html#92">72</a><br/>
text <a href="dmps.html#37">17</a><br/>
Tree style <a href="dmps.html#202">182</a><br/>
V<br/>
editor <a href="dmps.html#108">88</a><br/>
example <a href="dmps.html#203">183 </a><a href="dmps.html#205">185 </a><a href="dmps.html#224">204</a><br/>
file <a href="dmps.html#161">141</a><br/>
vs. Objects style <a href="dmps.html#206">186 </a><a href="dmps.html#208">188</a><br/>
valid vs. well-formed <a href="dmps.html#197">177</a><br/>
formats <a href="dmps.html#24">4</a><br/>
two-digit year <a href="dmps.html#136">116</a><br/>
verb <a href="dmps.html#230">210</a><br/>
matching <a href="dmps.html#98">78</a><br/>
vertical bar <a href="dmps.html#82">62</a><br/>
replacement <a href="dmps.html#104">84</a><br/>
U<br/>
vi <a href="dmps.html#81">61 </a><a href="dmps.html#102">82</a><br/>
statistics <a href="dmps.html#105">85 </a><a href="dmps.html#106">86</a><br/>
vowel <a href="dmps.html#82">62</a><br/>
substitution <a href="dmps.html#90">70 </a><a href="dmps.html#98">78</a><br/>
uc <a href="dmps.html#80">60 </a><a href="dmps.html#98">78</a><br/>
transformation <a href="dmps.html#104">84</a><br/>
ucfirst <a href="dmps.html#80">60</a><br/>
Text::Bastardize <a href="dmps.html#96">76</a><br/>
Ullman <a href="dmps.html#182">162</a><br/>
W<br/>
Text::CSV <a href="dmps.html#129">109 </a><a href="dmps.html#130">110</a><br/>
unfixing <a href="dmps.html#111">91</a><br/>
Text::CSV_XS <a href="dmps.html#129">109</a><br/>
unformat_number<br/>
-w command line option <a href="dmps.html#276">256</a><br/>
Text::Wrap <a href="dmps.html#223">203</a><br/>
example <a href="dmps.html#113">93</a><br/>
Wall, Larry <a href="dmps.html#34">14 </a><a href="dmps.html#37">17</a><br/>
<i>The Art of Compiler Design </i><a href="dmps.html#182">162</a><br/>
Unicode <a href="dmps.html#107">87</a><br/>
Wallace, Shawn P. <a href="dmps.html#160">140</a><br/>
The Dragon Book <a href="dmps.html#182">162</a><br/>
Unicode::Map8 <a href="dmps.html#107">87</a><br/>
war3z <a href="dmps.html#96">76</a><br/>
“The man of descent” <a href="dmps.html#244">224</a><br/>
Unicode::String <a href="dmps.html#107">87</a><br/>
web access log<br/>
<i>The Perl Cookbook </i><a href="dmps.html#75">55</a><br/>
Unisys <a href="dmps.html#159">139</a><br/>
date <a href="dmps.html#144">124</a><br/>
<i>The Perl Journal </i><a href="dmps.html#128">108 </a><a href="dmps.html#244">224 </a><a href="dmps.html#249">229</a><br/>
UNIX <a href="dmps.html#31">11 </a><a href="dmps.html#34">14 </a><a href="dmps.html#36">16 </a><a href="dmps.html#53">33</a><br/>
HTTP request <a href="dmps.html#144">124</a><br/>
<i>The Practice of Programming </i><a href="dmps.html#58">38</a><br/>
ASCII text files <a href="dmps.html#102">82</a><br/>
IP address <a href="dmps.html#143">123</a><br/>
<i>The UNIX Programming </i><br/>
binary/text files <a href="dmps.html#161">141</a><br/>
response code <a href="dmps.html#144">124</a><br/>
<i>Environment </i><a href="dmps.html#58">38</a><br/>
data files <a href="dmps.html#29">9</a><br/>
time <a href="dmps.html#144">124</a><br/>
TIFF <a href="dmps.html#163">143</a><br/>
data pipes <a href="dmps.html#31">11</a><br/>
URL <a href="dmps.html#144">124</a><br/>
time <a href="dmps.html#136">116</a><br/>
databases <a href="dmps.html#30">10</a><br/>
web server <a href="dmps.html#32">12 </a><a href="dmps.html#143">123</a><br/>
(<i>see also<a href="dmps.html#136"> </i>date)</a><br/>
epoch <a href="dmps.html#134">114</a><br/>
while <a href="dmps.html#133">113</a><br/>
Date::Calc <a href="dmps.html#140">120</a><br/>
filter model overview <a href="dmps.html#51">31</a><br/>
$_variable <a href="dmps.html#119">99</a><br/>
daylight savings time <a href="dmps.html#135">115</a><br/>
<a href="dmps.html#51"><i>se</i></a><i>e also </i>81,; ILOWHU PRGHO<br/>
reading a PNG f<a href="dmps.html#180">ile 141</a><br/>
<hr/>
<a name=303></a>INDEX<br/>
<b>283</b><br/>
white space <a href="dmps.html#82">62 </a><a href="dmps.html#95">75 </a><a href="dmps.html#103">83 </a><a href="dmps.html#133">113</a><br/>
X<br/>
<i>XML Pocket Reference </i><a href="dmps.html#196">177</a><br/>
Windows <a href="dmps.html#36">16</a><br/>
XML::DOM <a href="dmps.html#211">191 </a><a href="dmps.html#212">192</a><br/>
ASCII text files <a href="dmps.html#102">82</a><br/>
x modifier <a href="dmps.html#88">68 </a><a href="dmps.html#89">69</a><br/>
XML::Parser <a href="dmps.html#174">154 </a><a href="dmps.html#181">161</a><br/>
binary/text files <a href="dmps.html#161">141</a><br/>
x operator <a href="dmps.html#281">261</a><br/>
CPAN alternatives <a href="dmps.html#211">191</a><br/>
carriage return/line feed <a href="dmps.html#108">88</a><br/>
XML <a href="dmps.html#28">8 </a><a href="dmps.html#33">13 </a><a href="dmps.html#174">154</a><br/>
Debug style <a href="dmps.html#201">181</a><br/>
data files <a href="dmps.html#29">9</a><br/>
introduction <a href="dmps.html#196">176</a><br/>
example <a href="dmps.html#198">178 </a><a href="dmps.html#223">203</a><br/>
databases <a href="dmps.html#30">10</a><br/>
parsers <a href="dmps.html#198">178</a><br/>
functions <a href="dmps.html#270">250</a><br/>
I/O redirection <a href="dmps.html#52">32</a><br/>
parsing failures <a href="dmps.html#200">180</a><br/>
RSS file <a href="dmps.html#216">196</a><br/>
INI file grammar <a href="dmps.html#233">213</a><br/>
parsing input <a href="dmps.html#223">203</a><br/>
Stream style <a href="dmps.html#208">188</a><br/>
INI file parsing <a href="dmps.html#232">212</a><br/>
parsing using handlers <a href="dmps.html#209">189</a><br/>
XML::RSS <a href="dmps.html#213">193</a><br/>
word boundaries <a href="dmps.html#84">64</a><br/>
parsing, example <a href="dmps.html#198">178 </a><a href="dmps.html#211">191</a><br/>
word character <a href="dmps.html#82">62</a><br/>
parsing, Objects style <a href="dmps.html#207">187</a><br/>
creating a file <a href="dmps.html#215">195</a><br/>
World Wide Web Consortium <br/>
sample file <a href="dmps.html#197">177</a><br/>
(W3C) <a href="dmps.html#211">191</a><br/>
tag <a href="dmps.html#199">179</a><br/>
Y<br/>
writing separate records <a href="dmps.html#122">102</a><br/>
transformation script <a href="dmps.html#218">198±</a><a href="dmps.html#225">205<br/></a>Unicode <a href="dmps.html#107">87</a><br/>
Yahoo! <a href="dmps.html#197">177<br/></a>Yorick <a href="dmps.html#78">58</a><br/>
<hr/>
<a name=304></a>Purchase of <i>Data Munging with Perl</i> includes free author online support. <br/>For more information on this feature, please refer to page xvi.<br/>
<hr/>
<a name="outline"></a><h1>Document Outline</h1>
<ul>
<li><a href="dmps.html#5">contents</a></li>
<li><a href="dmps.html#11">foreword</a></li>
<li><a href="dmps.html#13">preface</a>
<ul>
<li><a href="dmps.html#14">Intended audience</a></li>
<li><a href="dmps.html#14">About this book</a></li>
<li><a href="dmps.html#15">Typographical conventions</a></li>
<li><a href="dmps.html#16">Source code downloads</a></li>
<li><a href="dmps.html#16">Author Online</a></li>
<li><a href="dmps.html#17">Acknowledgments</a></li>
</ul>
</li>
<li><a href="dmps.html#19">about the cover illustration</a></li>
<li><a href="dmps.html#21">Foundations</a>
<ul>
<li><a href="dmps.html#23">Data, data munging, and Perl</a>
<ul>
<li><a href="dmps.html#24">1.1 What is data munging?</a>
<ul>
<li><a href="dmps.html#24">1.1.1 Data munging processes</a></li>
<li><a href="dmps.html#25">1.1.2 Data recognition</a></li>
<li><a href="dmps.html#26">1.1.3 Data parsing</a></li>
<li><a href="dmps.html#26">1.1.4 Data filtering</a></li>
<li><a href="dmps.html#26">1.1.5 Data transformation</a></li>
</ul>
</li>
<li><a href="dmps.html#27">1.2 Why is data munging important?</a>
<ul>
<li><a href="dmps.html#27">1.2.1 Accessing corporate data repositories</a></li>
<li><a href="dmps.html#27">1.2.2 Transferring data between multiple systems</a></li>
<li><a href="dmps.html#28">1.2.3 Real-world data munging examples</a></li>
</ul>
</li>
<li><a href="dmps.html#29">1.3 Where does data come from? Where does it go?</a>
<ul>
<li><a href="dmps.html#29">1.3.1 Data files</a></li>
<li><a href="dmps.html#30">1.3.2 Databases</a></li>
<li><a href="dmps.html#31">1.3.3 Data pipes</a></li>
<li><a href="dmps.html#31">1.3.4 Other sources/sinks</a></li>
</ul>
</li>
<li><a href="dmps.html#32">1.4 What forms does data take?</a>
<ul>
<li><a href="dmps.html#32">1.4.1 Unstructured data</a></li>
<li><a href="dmps.html#33">1.4.2 Record-oriented data</a></li>
<li><a href="dmps.html#33">1.4.3 Hierarchical data</a></li>
<li><a href="dmps.html#33">1.4.4 Binary data</a></li>
</ul>
</li>
<li><a href="dmps.html#34">1.5 What is Perl?</a>
<ul>
<li><a href="dmps.html#35">1.5.1 Getting Perl</a></li>
</ul>
</li>
<li><a href="dmps.html#36">1.6 Why is Perl good for data munging?</a></li>
<li><a href="dmps.html#37">1.7 Further information</a></li>
<li><a href="dmps.html#37">1.8 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#38">General munging practices</a>
<ul>
<li><a href="dmps.html#39">2.1 Decouple input, munging, and output processes</a></li>
<li><a href="dmps.html#40">2.2 Design data structures carefully</a>
<ul>
<li><a href="dmps.html#40">2.2.1 Example: the CD file revisited</a></li>
</ul>
</li>
<li><a href="dmps.html#45">2.3 Encapsulate business rules</a>
<ul>
<li><a href="dmps.html#46">2.3.1 Reasons to encapsulate business rules</a></li>
<li><a href="dmps.html#46">2.3.2 Ways to encapsulate business rules</a></li>
<li><a href="dmps.html#47">2.3.3 Simple module</a></li>
<li><a href="dmps.html#48">2.3.4 Object class</a></li>
</ul>
</li>
<li><a href="dmps.html#51">2.4 Use UNIX “filter” model</a>
<ul>
<li><a href="dmps.html#51">2.4.1 Overview of the filter model</a></li>
<li><a href="dmps.html#52">2.4.2 Advantages of the filter model</a></li>
</ul>
</li>
<li><a href="dmps.html#56">2.5 Write audit trails</a>
<ul>
<li><a href="dmps.html#56">2.5.1 What to write to an audit trail</a></li>
<li><a href="dmps.html#57">2.5.2 Sample audit trail</a></li>
<li><a href="dmps.html#57">2.5.3 Using the UNIX system logs</a></li>
</ul>
</li>
<li><a href="dmps.html#58">2.6 Further information</a></li>
<li><a href="dmps.html#58">2.7 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#59">Useful Perl idioms</a>
<ul>
<li><a href="dmps.html#60">3.1 Sorting</a>
<ul>
<li><a href="dmps.html#60">3.1.1 Simple sorts</a></li>
<li><a href="dmps.html#61">3.1.2 Complex sorts</a></li>
<li><a href="dmps.html#62">3.1.3 The Orcish Manoeuvre</a></li>
<li><a href="dmps.html#63">3.1.4 Schwartzian transform</a></li>
<li><a href="dmps.html#66">3.1.5 The Guttman-Rosler transform</a></li>
<li><a href="dmps.html#66">3.1.6 Choosing a sort technique</a></li>
</ul>
</li>
<li><a href="dmps.html#67">3.2 Database Interface (DBI)</a>
<ul>
<li><a href="dmps.html#67">3.2.1 Sample DBI program</a></li>
</ul>
</li>
<li><a href="dmps.html#69">3.3 Data::Dumper</a></li>
<li><a href="dmps.html#71">3.4 Benchmarking</a></li>
<li><a href="dmps.html#73">3.5 Command line scripts</a></li>
<li><a href="dmps.html#75">3.6 Further information</a></li>
<li><a href="dmps.html#76">3.7 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#77">Pattern matching</a>
<ul>
<li><a href="dmps.html#78">4.1 String handling functions</a>
<ul>
<li><a href="dmps.html#78">4.1.1 Substrings</a></li>
<li><a href="dmps.html#79">4.1.2 Finding strings within strings (index and rindex)</a></li>
<li><a href="dmps.html#80">4.1.3 Case transformations</a></li>
</ul>
</li>
<li><a href="dmps.html#80">4.2 Regular expressions</a>
<ul>
<li><a href="dmps.html#80">4.2.1 What are regular expressions?</a></li>
<li><a href="dmps.html#81">4.2.2 Regular expression syntax</a></li>
<li><a href="dmps.html#85">4.2.3 Using regular expressions</a></li>
<li><a href="dmps.html#90">4.2.4 Example: translating from English to American</a></li>
<li><a href="dmps.html#93">4.2.5 More examples: /etc/passwd</a></li>
<li><a href="dmps.html#96">4.2.6 Taking it to extremes</a></li>
</ul>
</li>
<li><a href="dmps.html#97">4.3 Further information</a></li>
<li><a href="dmps.html#98">4.4 Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="dmps.html#99">Data munging</a>
<ul>
<li><a href="dmps.html#101">Unstructured data</a>
<ul>
<li><a href="dmps.html#102">5.1 ASCII text files</a>
<ul>
<li><a href="dmps.html#102">5.1.1 Reading the file</a></li>
<li><a href="dmps.html#104">5.1.2 Text transformations</a></li>
<li><a href="dmps.html#105">5.1.3 Text statistics</a></li>
</ul>
</li>
<li><a href="dmps.html#107">5.2 Data conversions</a>
<ul>
<li><a href="dmps.html#107">5.2.1 Converting the character set</a></li>
<li><a href="dmps.html#108">5.2.2 Converting line endings</a></li>
<li><a href="dmps.html#110">5.2.3 Converting number formats</a></li>
</ul>
</li>
<li><a href="dmps.html#114">5.3 Further information</a></li>
<li><a href="dmps.html#115">5.4 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#116">Record-oriented data</a>
<ul>
<li><a href="dmps.html#117">6.1 Simple record-oriented data</a>
<ul>
<li><a href="dmps.html#117">6.1.1 Reading simple record-oriented data</a></li>
<li><a href="dmps.html#120">6.1.2 Processing simple record-oriented data</a></li>
<li><a href="dmps.html#122">6.1.3 Writing simple record-oriented data</a></li>
<li><a href="dmps.html#125">6.1.4 Caching data</a></li>
</ul>
</li>
<li><a href="dmps.html#128">6.2 Comma-separated files</a>
<ul>
<li><a href="dmps.html#128">6.2.1 Anatomy of CSV data</a></li>
<li><a href="dmps.html#129">6.2.2 Text::CSV_XS</a></li>
</ul>
</li>
<li><a href="dmps.html#130">6.3 Complex records</a>
<ul>
<li><a href="dmps.html#131">6.3.1 Example: a different CD file</a></li>
<li><a href="dmps.html#133">6.3.2 Special values for $/</a></li>
</ul>
</li>
<li><a href="dmps.html#134">6.4 Special problems with date fields</a>
<ul>
<li><a href="dmps.html#134">6.4.1 Built-in Perl date functions</a></li>
<li><a href="dmps.html#140">6.4.2 Date::Calc</a></li>
<li><a href="dmps.html#141">6.4.3 Date::Manip</a></li>
<li><a href="dmps.html#142">6.4.4 Choosing between date modules</a></li>
</ul>
</li>
<li><a href="dmps.html#143">6.5 Extended example: web access logs</a></li>
<li><a href="dmps.html#146">6.6 Further information</a></li>
<li><a href="dmps.html#146">6.7 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#147">Fixed-width and binary data</a>
<ul>
<li><a href="dmps.html#148">7.1 Fixed-width data</a>
<ul>
<li><a href="dmps.html#148">7.1.1 Reading fixed-width data</a></li>
<li><a href="dmps.html#155">7.1.2 Writing fixed-width data</a></li>
</ul>
</li>
<li><a href="dmps.html#159">7.2 Binary data</a>
<ul>
<li><a href="dmps.html#160">7.2.1 Reading PNG files</a></li>
<li><a href="dmps.html#163">7.2.2 Reading and writing MP3 files</a></li>
</ul>
</li>
<li><a href="dmps.html#164">7.3 Further information</a></li>
<li><a href="dmps.html#165">7.4 Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="dmps.html#167">Simple data parsing</a>
<ul>
<li><a href="dmps.html#169">Complex data formats</a>
<ul>
<li><a href="dmps.html#170">8.1 Complex data files</a>
<ul>
<li><a href="dmps.html#170">8.1.1 Example: metadata in the CD file</a></li>
<li><a href="dmps.html#172">8.1.2 Example: reading the expanded CD file</a></li>
</ul>
</li>
<li><a href="dmps.html#174">8.2 How not to parse HTML</a>
<ul>
<li><a href="dmps.html#174">8.2.1 Removing tags from HTML</a></li>
<li><a href="dmps.html#177">8.2.2 Limitations of regular expressions</a></li>
</ul>
</li>
<li><a href="dmps.html#178">8.3 Parsers</a>
<ul>
<li><a href="dmps.html#178">8.3.1 An introduction to parsers</a></li>
<li><a href="dmps.html#181">8.3.2 Parsers in Perl</a></li>
</ul>
</li>
<li><a href="dmps.html#182">8.4 Further information</a></li>
<li><a href="dmps.html#182">8.5 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#183">HTML</a>
<ul>
<li><a href="dmps.html#184">9.1 Extracting HTML data from the World Wide Web</a></li>
<li><a href="dmps.html#185">9.2 Parsing HTML</a>
<ul>
<li><a href="dmps.html#185">9.2.1 Example: simple HTML parsing</a></li>
</ul>
</li>
<li><a href="dmps.html#187">9.3 Prebuilt HTML parsers</a>
<ul>
<li><a href="dmps.html#187">9.3.1 HTML::LinkExtor</a></li>
<li><a href="dmps.html#189">9.3.2 HTML::TokeParser</a></li>
<li><a href="dmps.html#191">9.3.3 HTML::TreeBuilder and HTML::Element</a></li>
</ul>
</li>
<li><a href="dmps.html#192">9.4 Extended example: getting weather forecasts</a></li>
<li><a href="dmps.html#194">9.5 Further information</a></li>
<li><a href="dmps.html#194">9.6 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#195">XML</a>
<ul>
<li><a href="dmps.html#196">10.1 XML overview</a>
<ul>
<li><a href="dmps.html#196">10.1.1 What’s wrong with HTML?</a></li>
<li><a href="dmps.html#196">10.1.2 What is XML?</a></li>
</ul>
</li>
<li><a href="dmps.html#198">10.2 Parsing XML with XML::Parser</a>
<ul>
<li><a href="dmps.html#198">10.2.1 Example: parsing weather.xml</a></li>
<li><a href="dmps.html#199">10.2.2 Using XML::Parser</a></li>
<li><a href="dmps.html#201">10.2.3 Other XML::Parser styles</a></li>
<li><a href="dmps.html#208">10.2.4 XML::Parser handlers</a></li>
</ul>
</li>
<li><a href="dmps.html#211">10.3 XML::DOM</a>
<ul>
<li><a href="dmps.html#211">10.3.1 Example: parsing XML using XML::DOM</a></li>
</ul>
</li>
<li><a href="dmps.html#213">10.4 Specialized parsers—XML::RSS</a>
<ul>
<li><a href="dmps.html#213">10.4.1 What is RSS?</a></li>
<li><a href="dmps.html#213">10.4.2 A sample RSS file</a></li>
<li><a href="dmps.html#215">10.4.3 Example: creating an RSS file with XML::RSS</a></li>
<li><a href="dmps.html#216">10.4.4 Example: parsing an RSS file with XML::RSS</a></li>
</ul>
</li>
<li><a href="dmps.html#217">10.5 Producing different document formats</a>
<ul>
<li><a href="dmps.html#217">10.5.1 Sample XML input file</a></li>
<li><a href="dmps.html#218">10.5.2 XML document transformation script</a></li>
<li><a href="dmps.html#225">10.5.3 Using the XML document transformation script</a></li>
</ul>
</li>
<li><a href="dmps.html#228">10.6 Further information</a></li>
<li><a href="dmps.html#228">10.7 Summary</a></li>
</ul>
</li>
<li><a href="dmps.html#229">Building your own parsers</a>
<ul>
<li><a href="dmps.html#230">11.1 Introduction to Parse::RecDescent</a>
<ul>
<li><a href="dmps.html#230">11.1.1 Example: parsing simple English sentences</a></li>
</ul>
</li>
<li><a href="dmps.html#232">11.2 Returning parsed data</a>
<ul>
<li><a href="dmps.html#232">11.2.1 Example: parsing a Windows INI file</a></li>
<li><a href="dmps.html#233">11.2.2 Understanding the INI file grammar</a></li>
<li><a href="dmps.html#234">11.2.3 Parser actions and the @item array</a></li>
<li><a href="dmps.html#234">11.2.4 Example: displaying the contents of @item</a></li>
<li><a href="dmps.html#236">11.2.5 Returning a data structure</a></li>
</ul>
</li>
<li><a href="dmps.html#237">11.3 Another example: the CD data file</a>
<ul>
<li><a href="dmps.html#238">11.3.1 Understanding the CD grammar</a></li>
<li><a href="dmps.html#239">11.3.2 Testing the CD file grammar</a></li>
<li><a href="dmps.html#240">11.3.3 Adding parser actions</a></li>
</ul>
</li>
<li><a href="dmps.html#243">11.4 Other features of Parse::RecDescent</a></li>
<li><a href="dmps.html#244">11.5 Further information</a></li>
<li><a href="dmps.html#244">11.6 Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="dmps.html#245">The big picture</a>
<ul>
<li><a href="dmps.html#247">Looking back— and ahead</a>
<ul>
<li><a href="dmps.html#248">12.1 The usefulness of things</a>
<ul>
<li><a href="dmps.html#248">12.1.1 The usefulness of data munging</a></li>
<li><a href="dmps.html#248">12.1.2 The usefulness of Perl</a></li>
<li><a href="dmps.html#249">12.1.3 The usefulness of the Perl community</a></li>
</ul>
</li>
<li><a href="dmps.html#249">12.2 Things to know</a>
<ul>
<li><a href="dmps.html#249">12.2.1 Know your data</a></li>
<li><a href="dmps.html#250">12.2.2 Know your tools</a></li>
<li><a href="dmps.html#250">12.2.3 Know where to go for more information</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="dmps.html#252">Modules reference</a>
<ul>
<li><a href="dmps.html#253">A.1 DBI</a>
<ul>
<li><a href="dmps.html#253">A.1.1 Functions called on the DBI class</a></li>
<li><a href="dmps.html#254">A.1.2 Attributes of the DBI class</a></li>
<li><a href="dmps.html#254">A.1.3 Functions called on any DBI handle</a></li>
<li><a href="dmps.html#254">A.1.4 Attributes of any DBI handle</a></li>
<li><a href="dmps.html#255">A.1.5 Functions called on a database handle</a></li>
<li><a href="dmps.html#256">A.1.6 Database handle attributes</a></li>
<li><a href="dmps.html#256">A.1.7 Functions called on a statement handle</a></li>
<li><a href="dmps.html#258">A.1.8 Statement handle attributes</a></li>
</ul>
</li>
<li><a href="dmps.html#258">A.2 Number::Format</a>
<ul>
<li><a href="dmps.html#258">A.2.1 Attributes</a></li>
<li><a href="dmps.html#259">A.2.2 Methods</a></li>
</ul>
</li>
<li><a href="dmps.html#260">A.3 Date::Calc</a></li>
<li><a href="dmps.html#262">A.4 Date::Manip</a></li>
<li><a href="dmps.html#264">A.5 LWP::Simple</a></li>
<li><a href="dmps.html#265">A.6 HTML::Parser</a>
<ul>
<li><a href="dmps.html#266">A.6.1 Handlers</a></li>
</ul>
</li>
<li><a href="dmps.html#267">A.7 HTML::LinkExtor</a></li>
<li><a href="dmps.html#268">A.8 HTML::TokeParser</a></li>
<li><a href="dmps.html#269">A.9 HTML::TreeBuilder</a></li>
<li><a href="dmps.html#270">A.10 XML::Parser</a></li>
</ul>
</li>
<li><a href="dmps.html#274">Essential Perl</a>
<ul>
<li><a href="dmps.html#275">B.1 Running Perl</a></li>
<li><a href="dmps.html#276">B.2 Variables and data types</a>
<ul>
<li><a href="dmps.html#276">B.2.1 Scalars</a></li>
<li><a href="dmps.html#277">B.2.2 Arrays</a></li>
<li><a href="dmps.html#279">B.2.3 Hashes</a></li>
<li><a href="dmps.html#281">B.2.4 More information</a></li>
</ul>
</li>
<li><a href="dmps.html#281">B.3 Operators</a>
<ul>
<li><a href="dmps.html#281">B.3.1 Mathematical operators</a></li>
<li><a href="dmps.html#282">B.3.2 Logical operators</a></li>
</ul>
</li>
<li><a href="dmps.html#283">B.4 Flow of control</a>
<ul>
<li><a href="dmps.html#283">B.4.1 Conditional execution</a></li>
<li><a href="dmps.html#284">B.4.2 Loops</a></li>
</ul>
</li>
<li><a href="dmps.html#286">B.5 Subroutines</a></li>
<li><a href="dmps.html#288">B.6 References</a>
<ul>
<li><a href="dmps.html#288">B.6.1 Creating references</a></li>
<li><a href="dmps.html#289">B.6.2 Using references</a></li>
<li><a href="dmps.html#289">B.6.3 References to subroutines</a></li>
<li><a href="dmps.html#289">B.6.4 Complex data structures using references</a></li>
<li><a href="dmps.html#292">B.6.5 More information on references and complex data structures</a></li>
</ul>
</li>
<li><a href="dmps.html#292">B.7 More information on Perl</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="dmps.html#293">index</a></li>
</ul>
<hr/>
</body>
</html>
